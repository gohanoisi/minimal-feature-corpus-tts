{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleTTS2 モデル学習\n",
    "\n",
    "各データセット(phone_min4, feat_top10, full100)に対して、ゼロからStyleTTS2モデルを学習します。\n",
    "\n",
    "## 実行前の確認\n",
    "\n",
    "1. **Cell 1-4を実行**: 環境とファイルの確認\n",
    "   - PyTorch/transformersのバージョン確認\n",
    "   - 必要なファイル（Utils/, Data/, Configs/）の存在確認\n",
    "   - OOD_texts.txtの確認\n",
    "\n",
    "2. **Colab環境の場合**: \n",
    "   - StyleTTS2リポジトリがクローンされていること\n",
    "   - データセットと設定ファイルが準備されていること\n",
    "   - `01_prepare_datasets.ipynb`と`02_generate_configs.ipynb`を実行済みであること\n",
    "\n",
    "## 学習プロセス\n",
    "\n",
    "1. **Stage 1 (train_first.py)**: 事前学習ステージ\n",
    "   - エポック数: 80\n",
    "   - Mixed precision (fp16) を使用\n",
    "   - accelerate launch で実行\n",
    "\n",
    "2. **Stage 2 (train_second.py)**: ジョイント学習ステージ\n",
    "   - エポック数: 40\n",
    "   - Stage 1のモデルをロードして継続学習\n",
    "\n",
    "## 実行方法\n",
    "\n",
    "**方法1: ノートブックから実行（推奨）**\n",
    "- Cell 14で`RUN_STAGE1 = True`に設定して実行\n",
    "- Stage 1完了後、`RUN_STAGE2 = True`に設定して実行\n",
    "\n",
    "**方法2: ターミナルから実行**\n",
    "- Cell 10で表示されるコマンドをターミナルで実行\n",
    "\n",
    "## 注意事項\n",
    "\n",
    "- 学習には長時間かかります（数時間〜数日）\n",
    "- Colabの場合は、セッションがタイムアウトしないよう注意してください\n",
    "- ブラウザを閉じると学習が中断されます\n",
    "- TensorBoardで学習の進捗を確認できます\n",
    "- VRAMエラーが発生した場合は、設定ファイルのbatch_sizeやmax_lenを削減してください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorchとtransformersのバージョン確認とアップグレード\n",
    "# !pip install --upgrade torch>=2.6.0 torchaudio transformers>=4.40.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu128\n",
      "transformers version: 4.57.3\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4070 Ti\n",
      "CUDA version: 12.8\n",
      "✓ PyTorch 2.9.1+cu128 は2.6以上です。\n",
      "\n",
      "------------------------------------------------------------\n",
      "accelerate設定の確認\n",
      "------------------------------------------------------------\n",
      "⚠️ accelerate configの確認に失敗しました\n",
      "必要に応じて以下を実行してください:\n",
      "  accelerate config\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import subprocess\n",
    "\n",
    "torch_version = torch.__version__\n",
    "transformers_version = transformers.__version__\n",
    "\n",
    "print(f\"PyTorch version: {torch_version}\")\n",
    "print(f\"transformers version: {transformers_version}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# バージョンチェック\n",
    "torch_major, torch_minor = map(int, torch_version.split(\".\")[:2])\n",
    "is_torch_ok = torch_major > 2 or (torch_major == 2 and torch_minor >= 6)\n",
    "\n",
    "if not is_torch_ok:\n",
    "    print(f\"⚠️ 警告: PyTorch {torch_version} は2.6未満です。アップグレードが必要です。\")\n",
    "else:\n",
    "    print(f\"✓ PyTorch {torch_version} は2.6以上です。\")\n",
    "\n",
    "# accelerate設定の確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"accelerate設定の確認\")\n",
    "print(\"-\"*60)\n",
    "try:\n",
    "    result = subprocess.run([\"accelerate\", \"config\", \"--config_file\", \"default\"], \n",
    "                          capture_output=True, text=True, timeout=5)\n",
    "    if \"Inferred\" in result.stdout or \"default\" in result.stdout.lower():\n",
    "        print(\"✓ accelerate設定が存在します\")\n",
    "    else:\n",
    "        print(\"⚠️ accelerate設定を確認できませんでした\")\n",
    "        print(\"必要に応じて以下を実行してください:\")\n",
    "        print(\"  accelerate config\")\n",
    "except:\n",
    "    print(\"⚠️ accelerate configの確認に失敗しました\")\n",
    "    print(\"必要に応じて以下を実行してください:\")\n",
    "    print(\"  accelerate config\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "StyleTTS2 モデル学習\n",
      "============================================================\n",
      "\n",
      "プロジェクトルート: /mnt/e/dev/minimal-feature-corpus-tts\n",
      "StyleTTS2ディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "データセット: ['phone_min4', 'feat_top10', 'full100']\n",
      "\n",
      "⚠️ 注意: 学習には長時間かかる可能性があります\n",
      "TensorBoardで進捗を確認できます: tensorboard --logdir /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# プロジェクトルートを取得\n",
    "# notebooks/styletts2/ から実行される場合: 2階層上がる\n",
    "# notebooks/ から実行される場合: 1階層上がる\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"styletts2\":\n",
    "    PROJECT_ROOT = current_dir.parent.parent  # notebooks/styletts2 -> notebooks -> project_root\n",
    "elif current_dir.name == \"notebooks\":\n",
    "    PROJECT_ROOT = current_dir.parent  # notebooks -> project_root\n",
    "else:\n",
    "    PROJECT_ROOT = current_dir  # プロジェクトルートから直接実行\n",
    "STYLETTS2_DIR = PROJECT_ROOT / \"StyleTTS2\"\n",
    "\n",
    "# StyleTTS2をパスに追加\n",
    "if STYLETTS2_DIR.exists() and str(STYLETTS2_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(STYLETTS2_DIR))\n",
    "\n",
    "# データセット名のリスト\n",
    "DATASETS = [\"phone_min4\", \"feat_top10\", \"full100\"]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"StyleTTS2 モデル学習\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nプロジェクトルート: {PROJECT_ROOT}\")\n",
    "print(f\"StyleTTS2ディレクトリ: {STYLETTS2_DIR}\")\n",
    "print(f\"データセット: {DATASETS}\")\n",
    "print(f\"\\n⚠️ 注意: 学習には長時間かかる可能性があります\")\n",
    "print(f\"TensorBoardで進捗を確認できます: tensorboard --logdir {STYLETTS2_DIR}/Models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "必要なファイルの存在確認\n",
      "============================================================\n",
      "✓ F0モデル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/JDC/bst.t7\n",
      "    サイズ: 21,029,926 bytes\n",
      "✓ ASR設定: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/ASR/config.yml\n",
      "    サイズ: 481 bytes\n",
      "✓ ASRモデル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/ASR/epoch_00080.pth\n",
      "    サイズ: 94,552,811 bytes\n",
      "✓ PLBERTディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT\n",
      "    ファイル数: 4\n",
      "✓ OODテキスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/OOD_texts.txt\n",
      "    サイズ: 31,758,898 bytes\n",
      "\n",
      "------------------------------------------------------------\n",
      "データセットの確認\n",
      "------------------------------------------------------------\n",
      "\n",
      "phone_min4:\n",
      "✓ データディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_phone_min4\n",
      "    ファイル数: 3\n",
      "✓ 訓練データリスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_phone_min4/train_list.txt\n",
      "    サイズ: 1,693 bytes\n",
      "✓ 検証データリスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_phone_min4/val_list.txt\n",
      "    サイズ: 911 bytes\n",
      "✓ 音声ファイルディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_phone_min4/wavs\n",
      "    ファイル数: 4\n",
      "    音声ファイル数: 4\n",
      "\n",
      "feat_top10:\n",
      "✓ データディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_feat_top10\n",
      "    ファイル数: 3\n",
      "✓ 訓練データリスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_feat_top10/train_list.txt\n",
      "    サイズ: 4,048 bytes\n",
      "✓ 検証データリスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_feat_top10/val_list.txt\n",
      "    サイズ: 540 bytes\n",
      "✓ 音声ファイルディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_feat_top10/wavs\n",
      "    ファイル数: 10\n",
      "    音声ファイル数: 10\n",
      "\n",
      "full100:\n",
      "✓ データディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_full100\n",
      "    ファイル数: 3\n",
      "✓ 訓練データリスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_full100/train_list.txt\n",
      "    サイズ: 47,612 bytes\n",
      "✓ 検証データリスト: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_full100/val_list.txt\n",
      "    サイズ: 4,828 bytes\n",
      "✓ 音声ファイルディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_full100/wavs\n",
      "    ファイル数: 100\n",
      "    音声ファイル数: 100\n",
      "\n",
      "------------------------------------------------------------\n",
      "設定ファイルの確認\n",
      "------------------------------------------------------------\n",
      "✓ phone_min4設定ファイル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Configs/config_jvs002_phone_min4.yml\n",
      "    サイズ: 2,148 bytes\n",
      "✓ feat_top10設定ファイル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Configs/config_jvs002_feat_top10.yml\n",
      "    サイズ: 2,034 bytes\n",
      "✓ full100設定ファイル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Configs/config_jvs002_full100.yml\n",
      "    サイズ: 2,022 bytes\n",
      "\n",
      "------------------------------------------------------------\n",
      "OOD_texts.txtの確認\n",
      "------------------------------------------------------------\n",
      "✓ OOD_texts.txt: 141434行\n",
      "  最初の3行の例:\n",
      "    1: LibriTTS/train-clean-360/3072/155948/3072_155948_000007_000011.wav|ʌv kˈoːɹs bˈɑ\n",
      "    2: LibriTTS/train-clean-360/1046/133225/1046_133225_000040_000000.wav|ðə pˈeɪɪŋ tˈɛ\n",
      "    3: LibriTTS/train-clean-360/5660/101892/5660_101892_000007_000001.wav|æz fɔːɹ hˈɪlk\n",
      "  ⚠️ 警告: OOD_texts.txtに日本語テキストが含まれていない可能性があります\n",
      "    日本語データセットの場合、日本語テキストを含めることを推奨します\n",
      "\n",
      "------------------------------------------------------------\n",
      "Colab環境でのファイル準備\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "✓ すべての必要なファイルが存在します\n",
      "\n",
      "次のステップ:\n",
      "  1. Cell 14で学習を実行するか、ターミナルからコマンドを実行\n",
      "  2. 学習の進捗をTensorBoardで確認\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 必要なファイルの存在確認\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"必要なファイルの存在確認\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def check_file(path, description):\n",
    "    \"\"\"ファイルの存在を確認\"\"\"\n",
    "    exists = path.exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {description}: {path}\")\n",
    "    if exists:\n",
    "        if path.is_file():\n",
    "            size = path.stat().st_size\n",
    "            print(f\"    サイズ: {size:,} bytes\")\n",
    "        elif path.is_dir():\n",
    "            files = list(path.glob(\"*\"))\n",
    "            print(f\"    ファイル数: {len(files)}\")\n",
    "    return exists\n",
    "\n",
    "# StyleTTS2の必要なファイルを確認\n",
    "required_files = {\n",
    "    \"F0モデル\": STYLETTS2_DIR / \"Utils\" / \"JDC\" / \"bst.t7\",\n",
    "    \"ASR設定\": STYLETTS2_DIR / \"Utils\" / \"ASR\" / \"config.yml\",\n",
    "    \"ASRモデル\": STYLETTS2_DIR / \"Utils\" / \"ASR\" / \"epoch_00080.pth\",\n",
    "    \"PLBERTディレクトリ\": STYLETTS2_DIR / \"Utils\" / \"PLBERT\",\n",
    "    \"OODテキスト\": STYLETTS2_DIR / \"Data\" / \"OOD_texts.txt\",\n",
    "}\n",
    "\n",
    "all_files_exist = True\n",
    "for desc, path in required_files.items():\n",
    "    if not check_file(path, desc):\n",
    "        all_files_exist = False\n",
    "\n",
    "# データセットの確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"データセットの確認\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    data_dir = STYLETTS2_DIR / \"Data\" / f\"jvs002_{dataset_name}\"\n",
    "    train_list = data_dir / \"train_list.txt\"\n",
    "    val_list = data_dir / \"val_list.txt\"\n",
    "    wavs_dir = data_dir / \"wavs\"\n",
    "    \n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    check_file(data_dir, \"データディレクトリ\")\n",
    "    check_file(train_list, \"訓練データリスト\")\n",
    "    check_file(val_list, \"検証データリスト\")\n",
    "    check_file(wavs_dir, \"音声ファイルディレクトリ\")\n",
    "    \n",
    "    if wavs_dir.exists():\n",
    "        wav_files = list(wavs_dir.glob(\"*.wav\"))\n",
    "        print(f\"    音声ファイル数: {len(wav_files)}\")\n",
    "\n",
    "# 設定ファイルの確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"設定ファイルの確認\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    config_path = STYLETTS2_DIR / \"Configs\" / f\"config_jvs002_{dataset_name}.yml\"\n",
    "    check_file(config_path, f\"{dataset_name}設定ファイル\")\n",
    "\n",
    "# OOD_texts.txtの内容確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"OOD_texts.txtの確認\")\n",
    "print(\"-\"*60)\n",
    "ood_path = STYLETTS2_DIR / \"Data\" / \"OOD_texts.txt\"\n",
    "if ood_path.exists():\n",
    "    with open(ood_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"✓ OOD_texts.txt: {len(lines)}行\")\n",
    "    if len(lines) > 0:\n",
    "        print(f\"  最初の3行の例:\")\n",
    "        for i, line in enumerate(lines[:3], 1):\n",
    "            print(f\"    {i}: {line.strip()[:80]}\")\n",
    "    # 日本語データセット用に、日本語テキストが含まれているか確認\n",
    "    has_japanese = any(any('\\u3040' <= c <= '\\u309F' or '\\u30A0' <= c <= '\\u30FF' or '\\u4E00' <= c <= '\\u9FAF' for c in line) for line in lines[:100])\n",
    "    if not has_japanese and len(lines) > 0:\n",
    "        print(\"  ⚠️ 警告: OOD_texts.txtに日本語テキストが含まれていない可能性があります\")\n",
    "        print(\"    日本語データセットの場合、日本語テキストを含めることを推奨します\")\n",
    "else:\n",
    "    print(\"✗ OOD_texts.txtが見つかりません\")\n",
    "    print(\"  形式: text|anything (1行1テキスト)\")\n",
    "    print(\"  例: これはテストテキストです|dummy\")\n",
    "\n",
    "# Colab環境でのファイル準備確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Colab環境でのファイル準備\")\n",
    "print(\"-\"*60)\n",
    "is_colab = str(STYLETTS2_DIR).startswith(\"/content\")\n",
    "if is_colab:\n",
    "    print(\"⚠️ Colab環境が検出されました\")\n",
    "    print(\"\\nColabでファイルを準備する方法:\")\n",
    "    print(\"  1. Google Driveにプロジェクトをマウント\")\n",
    "    print(\"  2. または、GitHubからクローン:\")\n",
    "    print(f\"     !git clone https://github.com/yl4579/StyleTTS2.git {STYLETTS2_DIR}\")\n",
    "    print(\"  3. データセットと設定ファイルをアップロード\")\n",
    "    print(\"\\n必要なファイル:\")\n",
    "    print(\"  - StyleTTS2/Utils/ (ASR, JDC, PLBERT)\")\n",
    "    print(\"  - StyleTTS2/Data/ (データセットとOOD_texts.txt)\")\n",
    "    print(\"  - StyleTTS2/Configs/ (設定ファイル)\")\n",
    "\n",
    "# まとめ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_files_exist:\n",
    "    print(\"✓ すべての必要なファイルが存在します\")\n",
    "    print(\"\\n次のステップ:\")\n",
    "    print(\"  1. Cell 14で学習を実行するか、ターミナルからコマンドを実行\")\n",
    "    print(\"  2. 学習の進捗をTensorBoardで確認\")\n",
    "else:\n",
    "    print(\"✗ 一部のファイルが不足しています\")\n",
    "    print(\"\\n不足しているファイルを準備してください:\")\n",
    "    missing_items = []\n",
    "    if not (STYLETTS2_DIR / \"Utils\" / \"JDC\" / \"bst.t7\").exists():\n",
    "        missing_items.append(\"Utils/JDC/bst.t7 (F0モデル)\")\n",
    "    if not (STYLETTS2_DIR / \"Utils\" / \"ASR\" / \"config.yml\").exists():\n",
    "        missing_items.append(\"Utils/ASR/ (ASRモデル)\")\n",
    "    if not (STYLETTS2_DIR / \"Utils\" / \"PLBERT\").exists():\n",
    "        missing_items.append(\"Utils/PLBERT/ (PLBERT)\")\n",
    "    if not (STYLETTS2_DIR / \"Data\" / \"OOD_texts.txt\").exists():\n",
    "        missing_items.append(\"Data/OOD_texts.txt\")\n",
    "    \n",
    "    for item in missing_items:\n",
    "        print(f\"  - {item}\")\n",
    "    \n",
    "    if is_colab:\n",
    "        print(\"\\nColabでの準備方法:\")\n",
    "        print(\"  1. StyleTTS2リポジトリをクローン（Utils/が含まれます）\")\n",
    "        print(\"  2. データセットと設定ファイルを01_prepare_datasets.ipynbと02_generate_configs.ipynbで準備\")\n",
    "        print(\"  3. OOD_texts.txtを準備（日本語テキスト推奨）\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "StyleTTS2 モデル学習\n",
      "============================================================\n",
      "\n",
      "プロジェクトルート: /mnt/e/dev/minimal-feature-corpus-tts\n",
      "StyleTTS2ディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "データセット: ['phone_min4', 'feat_top10', 'full100']\n",
      "\n",
      "⚠️ 注意: 学習には長時間かかる可能性があります\n",
      "TensorBoardで進捗を確認できます: tensorboard --logdir /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# プロジェクトルートを取得\n",
    "# プロジェクトルートを取得\n",
    "# notebooks/styletts2/ から実行される場合: 2階層上がる\n",
    "# notebooks/ から実行される場合: 1階層上がる\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"styletts2\":\n",
    "    PROJECT_ROOT = current_dir.parent.parent  # notebooks/styletts2 -> notebooks -> project_root\n",
    "elif current_dir.name == \"notebooks\":\n",
    "    PROJECT_ROOT = current_dir.parent  # notebooks -> project_root\n",
    "else:\n",
    "    PROJECT_ROOT = current_dir  # プロジェクトルートから直接実行\n",
    "STYLETTS2_DIR = PROJECT_ROOT / \"StyleTTS2\"\n",
    "\n",
    "# StyleTTS2をパスに追加\n",
    "if STYLETTS2_DIR.exists() and str(STYLETTS2_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(STYLETTS2_DIR))\n",
    "\n",
    "# データセット名のリスト\n",
    "DATASETS = [\"phone_min4\", \"feat_top10\", \"full100\"]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"StyleTTS2 モデル学習\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nプロジェクトルート: {PROJECT_ROOT}\")\n",
    "print(f\"StyleTTS2ディレクトリ: {STYLETTS2_DIR}\")\n",
    "print(f\"データセット: {DATASETS}\")\n",
    "print(f\"\\n⚠️ 注意: 学習には長時間かかる可能性があります\")\n",
    "print(f\"TensorBoardで進捗を確認できます: tensorboard --logdir {STYLETTS2_DIR}/Models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "設定ファイルとデータセットの確認\n",
      "------------------------------------------------------------\n",
      "\n",
      "phone_min4:\n",
      "  設定ファイル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Configs/config_jvs002_phone_min4.yml (存在)\n",
      "  データディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_phone_min4 (存在)\n",
      "    訓練データ: 3エントリ\n",
      "    検証データ: 1エントリ\n",
      "    音声ファイル: 4ファイル\n",
      "\n",
      "feat_top10:\n",
      "  設定ファイル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Configs/config_jvs002_feat_top10.yml (存在)\n",
      "  データディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_feat_top10 (存在)\n",
      "    訓練データ: 9エントリ\n",
      "    検証データ: 1エントリ\n",
      "    音声ファイル: 10ファイル\n",
      "\n",
      "full100:\n",
      "  設定ファイル: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Configs/config_jvs002_full100.yml (存在)\n",
      "  データディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Data/jvs002_full100 (存在)\n",
      "    訓練データ: 90エントリ\n",
      "    検証データ: 10エントリ\n",
      "    音声ファイル: 100ファイル\n"
     ]
    }
   ],
   "source": [
    "# 設定ファイルとデータセットの確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"設定ファイルとデータセットの確認\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    config_path = STYLETTS2_DIR / \"Configs\" / f\"config_jvs002_{dataset_name}.yml\"\n",
    "    data_dir = STYLETTS2_DIR / \"Data\" / f\"jvs002_{dataset_name}\"\n",
    "    \n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    print(f\"  設定ファイル: {config_path} ({'存在' if config_path.exists() else '不存在'})\")\n",
    "    print(f\"  データディレクトリ: {data_dir} ({'存在' if data_dir.exists() else '不存在'})\")\n",
    "    \n",
    "    if data_dir.exists():\n",
    "        train_list = data_dir / \"train_list.txt\"\n",
    "        val_list = data_dir / \"val_list.txt\"\n",
    "        wavs_dir = data_dir / \"wavs\"\n",
    "        \n",
    "        train_count = len(open(train_list).readlines()) if train_list.exists() else 0\n",
    "        val_count = len(open(val_list).readlines()) if val_list.exists() else 0\n",
    "        wav_count = len(list(wavs_dir.glob(\"*.wav\"))) if wavs_dir.exists() else 0\n",
    "        \n",
    "        print(f\"    訓練データ: {train_count}エントリ\")\n",
    "        print(f\"    検証データ: {val_count}エントリ\")\n",
    "        print(f\"    音声ファイル: {wav_count}ファイル\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 1学習コマンド生成関数を定義しました\n"
     ]
    }
   ],
   "source": [
    "# Stage 1学習コマンド生成関数\n",
    "def generate_stage1_command(dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Stage 1学習のコマンドを生成\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: データセット名\n",
    "        \n",
    "    Returns:\n",
    "        学習コマンド文字列\n",
    "    \"\"\"\n",
    "    config_path = STYLETTS2_DIR / \"Configs\" / f\"config_jvs002_{dataset_name}.yml\"\n",
    "    \n",
    "    # 相対パスに変換（StyleTTS2ディレクトリから見たパス）\n",
    "    config_rel_path = config_path.relative_to(STYLETTS2_DIR)\n",
    "    config_rel_path_str = str(config_rel_path).replace('\\\\', '/')  # Windows対応\n",
    "    \n",
    "    cmd = f\"accelerate launch --mixed_precision=fp16 train_first.py -p {config_rel_path_str}\"\n",
    "    \n",
    "    return cmd\n",
    "\n",
    "print(\"✓ Stage 1学習コマンド生成関数を定義しました\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 2学習コマンド生成関数を定義しました\n"
     ]
    }
   ],
   "source": [
    "# Stage 2学習コマンド生成関数\n",
    "def generate_stage2_command(dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Stage 2学習のコマンドを生成\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: データセット名\n",
    "        \n",
    "    Returns:\n",
    "        学習コマンド文字列\n",
    "    \"\"\"\n",
    "    config_path = STYLETTS2_DIR / \"Configs\" / f\"config_jvs002_{dataset_name}.yml\"\n",
    "    \n",
    "    # 相対パスに変換（StyleTTS2ディレクトリから見たパス）\n",
    "    config_rel_path = config_path.relative_to(STYLETTS2_DIR)\n",
    "    config_rel_path_str = str(config_rel_path).replace('\\\\', '/')  # Windows対応\n",
    "    \n",
    "    cmd = f\"python train_second.py -p {config_rel_path_str}\"\n",
    "    \n",
    "    return cmd\n",
    "\n",
    "print(\"✓ Stage 2学習コマンド生成関数を定義しました\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コマンドの表示\n",
    "\n",
    "以下のコマンドをStyleTTS2ディレクトリで実行してください。各データセットごとに実行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "学習コマンド（参考）\n",
      "============================================================\n",
      "\n",
      "以下のコマンドをStyleTTS2ディレクトリで実行してください。\n",
      "各データセットごとに実行します。\n",
      "\n",
      "⚠️ 注意:\n",
      "  - 学習には長時間かかります（数時間〜数日）\n",
      "  - Colabの場合は、セッションがタイムアウトしないよう注意してください\n",
      "  - 進捗はTensorBoardで確認できます\n",
      "\n",
      "============================================================\n",
      "データセット: phone_min4\n",
      "============================================================\n",
      "\n",
      "【Stage 1学習】\n",
      "cd /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "accelerate launch --mixed_precision=fp16 train_first.py -p Configs/config_jvs002_phone_min4.yml\n",
      "\n",
      "  または、このノートブックのCell 14で実行:\n",
      "    dataset_name = \"phone_min4\"\n",
      "    RUN_STAGE1 = True\n",
      "    run_stage1_training(dataset_name, execute=True)\n",
      "\n",
      "【Stage 2学習】 (Stage 1完了後)\n",
      "cd /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "python train_second.py -p Configs/config_jvs002_phone_min4.yml\n",
      "\n",
      "  または、このノートブックのCell 14で実行:\n",
      "    dataset_name = \"phone_min4\"\n",
      "    RUN_STAGE2 = True\n",
      "    run_stage2_training(dataset_name, execute=True)\n",
      "\n",
      "学習ログとチェックポイントは以下に保存されます:\n",
      "  /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4\n",
      "  - ログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4/train.log\n",
      "  - TensorBoard: tensorboard --logdir /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4\n",
      "\n",
      "============================================================\n",
      "データセット: feat_top10\n",
      "============================================================\n",
      "\n",
      "【Stage 1学習】\n",
      "cd /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "accelerate launch --mixed_precision=fp16 train_first.py -p Configs/config_jvs002_feat_top10.yml\n",
      "\n",
      "  または、このノートブックのCell 14で実行:\n",
      "    dataset_name = \"feat_top10\"\n",
      "    RUN_STAGE1 = True\n",
      "    run_stage1_training(dataset_name, execute=True)\n",
      "\n",
      "【Stage 2学習】 (Stage 1完了後)\n",
      "cd /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "python train_second.py -p Configs/config_jvs002_feat_top10.yml\n",
      "\n",
      "  または、このノートブックのCell 14で実行:\n",
      "    dataset_name = \"feat_top10\"\n",
      "    RUN_STAGE2 = True\n",
      "    run_stage2_training(dataset_name, execute=True)\n",
      "\n",
      "学習ログとチェックポイントは以下に保存されます:\n",
      "  /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_feat_top10\n",
      "  - ログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_feat_top10/train.log\n",
      "  - TensorBoard: tensorboard --logdir /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_feat_top10\n",
      "\n",
      "============================================================\n",
      "データセット: full100\n",
      "============================================================\n",
      "\n",
      "【Stage 1学習】\n",
      "cd /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "accelerate launch --mixed_precision=fp16 train_first.py -p Configs/config_jvs002_full100.yml\n",
      "\n",
      "  または、このノートブックのCell 14で実行:\n",
      "    dataset_name = \"full100\"\n",
      "    RUN_STAGE1 = True\n",
      "    run_stage1_training(dataset_name, execute=True)\n",
      "\n",
      "【Stage 2学習】 (Stage 1完了後)\n",
      "cd /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "python train_second.py -p Configs/config_jvs002_full100.yml\n",
      "\n",
      "  または、このノートブックのCell 14で実行:\n",
      "    dataset_name = \"full100\"\n",
      "    RUN_STAGE2 = True\n",
      "    run_stage2_training(dataset_name, execute=True)\n",
      "\n",
      "学習ログとチェックポイントは以下に保存されます:\n",
      "  /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_full100\n",
      "  - ログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_full100/train.log\n",
      "  - TensorBoard: tensorboard --logdir /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_full100\n"
     ]
    }
   ],
   "source": [
    "# 学習コマンドの表示\n",
    "print(\"=\"*60)\n",
    "print(\"学習コマンド（参考）\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n以下のコマンドをStyleTTS2ディレクトリで実行してください。\")\n",
    "print(\"各データセットごとに実行します。\")\n",
    "print(\"\\n⚠️ 注意:\")\n",
    "print(\"  - 学習には長時間かかります（数時間〜数日）\")\n",
    "print(\"  - Colabの場合は、セッションがタイムアウトしないよう注意してください\")\n",
    "print(\"  - 進捗はTensorBoardで確認できます\")\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"データセット: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\n【Stage 1学習】\")\n",
    "    print(f\"cd {STYLETTS2_DIR}\")\n",
    "    stage1_cmd = generate_stage1_command(dataset_name)\n",
    "    print(f\"{stage1_cmd}\")\n",
    "    print(f\"\\n  または、このノートブックのCell 14で実行:\")\n",
    "    print(f\"    dataset_name = \\\"{dataset_name}\\\"\")\n",
    "    print(f\"    RUN_STAGE1 = True\")\n",
    "    print(f\"    run_stage1_training(dataset_name, execute=True)\")\n",
    "    \n",
    "    print(f\"\\n【Stage 2学習】 (Stage 1完了後)\")\n",
    "    print(f\"cd {STYLETTS2_DIR}\")\n",
    "    stage2_cmd = generate_stage2_command(dataset_name)\n",
    "    print(f\"{stage2_cmd}\")\n",
    "    print(f\"\\n  または、このノートブックのCell 14で実行:\")\n",
    "    print(f\"    dataset_name = \\\"{dataset_name}\\\"\")\n",
    "    print(f\"    RUN_STAGE2 = True\")\n",
    "    print(f\"    run_stage2_training(dataset_name, execute=True)\")\n",
    "    \n",
    "    print(f\"\\n学習ログとチェックポイントは以下に保存されます:\")\n",
    "    print(f\"  {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}'}\")\n",
    "    print(f\"  - ログ: {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}' / 'train.log'}\")\n",
    "    print(f\"  - TensorBoard: tensorboard --logdir {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プログラム実行による学習（オプション）\n",
    "\n",
    "以下のセルでプログラムから直接学習を実行することもできます。ただし、Jupyter Notebookで長時間実行する場合、ブラウザを閉じると中断される可能性があるため、コマンドライン実行を推奨します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 1学習実行関数を定義しました\n"
     ]
    }
   ],
   "source": [
    "# Stage 1学習実行関数\n",
    "def run_stage1_training(dataset_name: str, execute: bool = False):\n",
    "    \"\"\"\n",
    "    Stage 1学習を実行\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: データセット名\n",
    "        execute: Trueの場合、実際に実行する。Falseの場合、コマンドのみ表示\n",
    "    \"\"\"\n",
    "    config_path = STYLETTS2_DIR / \"Configs\" / f\"config_jvs002_{dataset_name}.yml\"\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        print(f\"✗ 設定ファイルが見つかりません: {config_path}\")\n",
    "        return\n",
    "    \n",
    "    # 相対パスに変換（StyleTTS2ディレクトリから見たパス）\n",
    "    config_rel_path = config_path.relative_to(STYLETTS2_DIR)\n",
    "    config_rel_path_str = str(config_rel_path).replace('\\\\', '/')\n",
    "    \n",
    "    # #region agent log\n",
    "    import json\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    log_path = \"/mnt/e/dev/minimal-feature-corpus-tts/.cursor/debug.log\"\n",
    "    def log_debug(location, message, data, hypothesis_id):\n",
    "        try:\n",
    "            with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps({\n",
    "                    \"sessionId\": \"debug-session\",\n",
    "                    \"runId\": \"run1\",\n",
    "                    \"hypothesisId\": hypothesis_id,\n",
    "                    \"location\": location,\n",
    "                    \"message\": message,\n",
    "                    \"data\": data,\n",
    "                    \"timestamp\": int(datetime.now().timestamp() * 1000)\n",
    "                }, ensure_ascii=False) + \"\\n\")\n",
    "        except: pass\n",
    "    # #endregion\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:814\", \"Checking accelerate command availability\", {\"cmd\": \"accelerate\"}, \"A\")\n",
    "    # #endregion\n",
    "    \n",
    "    # accelerateコマンドの検出を試行\n",
    "    accelerate_cmd = None\n",
    "    accelerate_paths = []\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:820\", \"Testing accelerate detection methods\", {\"method\": \"which\"}, \"A\")\n",
    "    # #endregion\n",
    "    \n",
    "    # 方法1: which accelerate\n",
    "    try:\n",
    "        result = subprocess.run([\"which\", \"accelerate\"], capture_output=True, text=True, timeout=2)\n",
    "        if result.returncode == 0 and result.stdout.strip():\n",
    "            accelerate_cmd = result.stdout.strip()\n",
    "            accelerate_paths.append((\"which\", accelerate_cmd))\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:828\", \"accelerate found via which\", {\"path\": accelerate_cmd}, \"A\")\n",
    "            # #endregion\n",
    "    except Exception as e:\n",
    "        # #region agent log\n",
    "        log_debug(\"03_train_models.ipynb:832\", \"which accelerate failed\", {\"error\": str(e)}, \"A\")\n",
    "        # #endregion\n",
    "        pass\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:836\", \"Testing python -m accelerate\", {\"method\": \"python -m\"}, \"B\")\n",
    "    # #endregion\n",
    "    \n",
    "    # 方法2: python -m accelerate\n",
    "    if not accelerate_cmd:\n",
    "        try:\n",
    "            result = subprocess.run([\"python\", \"-m\", \"accelerate\", \"--version\"], capture_output=True, text=True, timeout=2)\n",
    "            if result.returncode == 0:\n",
    "                accelerate_cmd = \"python\"\n",
    "                accelerate_paths.append((\"python -m\", \"python -m accelerate\"))\n",
    "                # #region agent log\n",
    "                log_debug(\"03_train_models.ipynb:844\", \"accelerate found via python -m\", {\"method\": \"python -m\"}, \"B\")\n",
    "                # #endregion\n",
    "        except Exception as e:\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:848\", \"python -m accelerate failed\", {\"error\": str(e)}, \"B\")\n",
    "            # #endregion\n",
    "            pass\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:852\", \"Testing python3 -m accelerate\", {\"method\": \"python3 -m\"}, \"C\")\n",
    "    # #endregion\n",
    "    \n",
    "    # 方法3: python3 -m accelerate\n",
    "    if not accelerate_cmd:\n",
    "        try:\n",
    "            result = subprocess.run([\"python3\", \"-m\", \"accelerate\", \"--version\"], capture_output=True, text=True, timeout=2)\n",
    "            if result.returncode == 0:\n",
    "                accelerate_cmd = \"python3\"\n",
    "                accelerate_paths.append((\"python3 -m\", \"python3 -m accelerate\"))\n",
    "                # #region agent log\n",
    "                log_debug(\"03_train_models.ipynb:860\", \"accelerate found via python3 -m\", {\"method\": \"python3 -m\"}, \"C\")\n",
    "                # #endregion\n",
    "        except Exception as e:\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:864\", \"python3 -m accelerate failed\", {\"error\": str(e)}, \"C\")\n",
    "            # #endregion\n",
    "            pass\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:868\", \"Testing pip list for accelerate\", {\"method\": \"pip list\"}, \"D\")\n",
    "    # #endregion\n",
    "    \n",
    "    # 方法4: pip listで確認\n",
    "    try:\n",
    "        result = subprocess.run([\"pip\", \"list\"], capture_output=True, text=True, timeout=5)\n",
    "        has_accelerate = \"accelerate\" in result.stdout.lower()\n",
    "        # #region agent log\n",
    "        log_debug(\"03_train_models.ipynb:875\", \"pip list result\", {\"has_accelerate\": has_accelerate, \"stdout_preview\": result.stdout[:200]}, \"D\")\n",
    "        # #endregion\n",
    "    except Exception as e:\n",
    "        # #region agent log\n",
    "        log_debug(\"03_train_models.ipynb:879\", \"pip list failed\", {\"error\": str(e)}, \"D\")\n",
    "        # #endregion\n",
    "        has_accelerate = False\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:883\", \"Checking sys.executable\", {\"executable\": sys.executable}, \"E\")\n",
    "    # #endregion\n",
    "    \n",
    "    # 方法5: sys.executableのbinディレクトリからaccelerateを探す\n",
    "    if not accelerate_cmd:\n",
    "        try:\n",
    "            import pathlib\n",
    "            bin_dir = pathlib.Path(sys.executable).parent\n",
    "            accelerate_path = bin_dir / \"accelerate\"\n",
    "            if accelerate_path.exists() and accelerate_path.is_file():\n",
    "                accelerate_cmd = str(accelerate_path)\n",
    "                accelerate_paths.append((\"sys.executable bin\", accelerate_cmd))\n",
    "                # #region agent log\n",
    "                log_debug(\"03_train_models.ipynb:891\", \"accelerate found in bin directory\", {\"path\": accelerate_cmd}, \"E\")\n",
    "                # #endregion\n",
    "        except Exception as e:\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:895\", \"bin directory search failed\", {\"error\": str(e), \"executable\": sys.executable}, \"E\")\n",
    "            # #endregion\n",
    "            pass\n",
    "    \n",
    "    # 方法6: sys.executable -m accelerate（フォールバック）\n",
    "    if not accelerate_cmd:\n",
    "        try:\n",
    "            # accelerateコマンドの存在確認（--versionは使えないので、代わりにhelpを使用）\n",
    "            result = subprocess.run([sys.executable, \"-m\", \"accelerate\", \"launch\", \"--help\"], capture_output=True, text=True, timeout=2)\n",
    "            if result.returncode == 0 or \"accelerate\" in result.stderr.lower() or \"accelerate\" in result.stdout.lower():\n",
    "                accelerate_cmd = sys.executable\n",
    "                accelerate_paths.append((\"sys.executable -m\", f\"{sys.executable} -m accelerate\"))\n",
    "                # #region agent log\n",
    "                log_debug(\"03_train_models.ipynb:905\", \"accelerate found via sys.executable -m\", {\"executable\": sys.executable}, \"E\")\n",
    "                # #endregion\n",
    "        except Exception as e:\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:909\", \"sys.executable -m accelerate failed\", {\"error\": str(e), \"executable\": sys.executable}, \"E\")\n",
    "            # #endregion\n",
    "            pass\n",
    "    \n",
    "    # #region agent log\n",
    "    log_debug(\"03_train_models.ipynb:899\", \"Final accelerate command decision\", {\"accelerate_cmd\": accelerate_cmd, \"paths_tried\": accelerate_paths}, \"ALL\")\n",
    "    # #endregion\n",
    "    \n",
    "    # コマンドを構築\n",
    "    if accelerate_cmd == \"python\" or accelerate_cmd == \"python3\" or (accelerate_cmd and accelerate_cmd.endswith(\"python\")):\n",
    "        # python -m accelerate を使用\n",
    "        cmd = [accelerate_cmd, \"-m\", \"accelerate\", \"launch\", \"--mixed_precision=fp16\", \"train_first.py\", \"-p\", config_rel_path_str]\n",
    "    elif accelerate_cmd and (accelerate_cmd.endswith(\"accelerate\") or \"/accelerate\" in accelerate_cmd):\n",
    "        # 直接パスを使用（binディレクトリから見つかった場合）\n",
    "        cmd = [accelerate_cmd, \"launch\", \"--mixed_precision=fp16\", \"train_first.py\", \"-p\", config_rel_path_str]\n",
    "    elif accelerate_cmd:\n",
    "        # sys.executable -m accelerate を使用\n",
    "        cmd = [accelerate_cmd, \"-m\", \"accelerate\", \"launch\", \"--mixed_precision=fp16\", \"train_first.py\", \"-p\", config_rel_path_str]\n",
    "    else:\n",
    "        # デフォルト（エラーになる可能性がある）\n",
    "        cmd = [\"accelerate\", \"launch\", \"--mixed_precision=fp16\", \"train_first.py\", \"-p\", config_rel_path_str]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Stage 1学習開始: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"コマンド: {' '.join(cmd)}\")\n",
    "    print(f\"作業ディレクトリ: {STYLETTS2_DIR}\")\n",
    "    if accelerate_cmd:\n",
    "        print(f\"✓ accelerateコマンド検出: {accelerate_cmd}\")\n",
    "    else:\n",
    "        print(f\"⚠️ accelerateコマンドが見つかりませんでした\")\n",
    "        print(f\"  試行した方法: {[p[0] for p in accelerate_paths]}\")\n",
    "    print(f\"\\n⚠️ 注意: 学習には長時間かかります（数時間〜数日）\")\n",
    "    print(f\"進捗は以下で確認できます:\")\n",
    "    print(f\"  - ログ: {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}' / 'train.log'}\")\n",
    "    print(f\"  - TensorBoard: tensorboard --logdir {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}'}\")\n",
    "    \n",
    "    if execute:\n",
    "        print(f\"\\n学習を開始します...\")\n",
    "        print(f\"⚠️ 長時間実行されるため、ブラウザを閉じないでください\")\n",
    "        print(f\"⚠️ Colabの場合は、セッションがタイムアウトしないよう注意してください\\n\")\n",
    "        \n",
    "        # #region agent log\n",
    "        log_debug(\"03_train_models.ipynb:925\", \"About to execute subprocess.Popen\", {\"cmd\": cmd, \"cwd\": str(STYLETTS2_DIR)}, \"ALL\")\n",
    "        # #endregion\n",
    "        \n",
    "        try:\n",
    "            # リアルタイム出力のために、stdout/stderrを直接表示\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                cwd=str(STYLETTS2_DIR),\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                bufsize=1,\n",
    "                universal_newlines=True\n",
    "            )\n",
    "            \n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:938\", \"subprocess.Popen created\", {\"pid\": process.pid}, \"ALL\")\n",
    "            # #endregion\n",
    "            \n",
    "            # リアルタイムで出力を表示\n",
    "            if process.stdout:\n",
    "                for line in process.stdout:\n",
    "                    print(line, end='')\n",
    "            \n",
    "            process.wait()\n",
    "            \n",
    "            if process.returncode == 0:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"✓ Stage 1学習完了: {dataset_name}\")\n",
    "                print(f\"{'='*60}\")\n",
    "            else:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"✗ Stage 1学習に失敗: {dataset_name} (終了コード: {process.returncode})\")\n",
    "                print(f\"{'='*60}\")\n",
    "                print(f\"\\nエラーログを確認してください:\")\n",
    "                log_path = STYLETTS2_DIR / \"Models\" / f\"jvs002_{dataset_name}\" / \"train.log\"\n",
    "                if log_path.exists():\n",
    "                    print(f\"  {log_path}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n⚠️ 学習が中断されました\")\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:950\", \"KeyboardInterrupt caught\", {}, \"ALL\")\n",
    "            # #endregion\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ エラー: {e}\")\n",
    "            # #region agent log\n",
    "            log_debug(\"03_train_models.ipynb:954\", \"Exception caught in subprocess.Popen\", {\"error\": str(e), \"error_type\": type(e).__name__}, \"ALL\")\n",
    "            # #endregion\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"\\n⚠️ execute=Falseのため、実際には実行しません。\")\n",
    "        print(\"実行する場合は、execute=Trueを指定してください。\")\n",
    "        print(\"\\nまたは、以下のコマンドをターミナルで実行してください:\")\n",
    "        print(f\"  cd {STYLETTS2_DIR}\")\n",
    "        print(f\"  {' '.join(cmd)}\")\n",
    "\n",
    "print(\"✓ Stage 1学習実行関数を定義しました\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 2学習実行関数を定義しました\n"
     ]
    }
   ],
   "source": [
    "# Stage 2学習実行関数\n",
    "def run_stage2_training(dataset_name: str, execute: bool = False):\n",
    "    \"\"\"\n",
    "    Stage 2学習を実行\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: データセット名\n",
    "        execute: Trueの場合、実際に実行する。Falseの場合、コマンドのみ表示\n",
    "    \"\"\"\n",
    "    config_path = STYLETTS2_DIR / \"Configs\" / f\"config_jvs002_{dataset_name}.yml\"\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        print(f\"✗ 設定ファイルが見つかりません: {config_path}\")\n",
    "        return\n",
    "    \n",
    "    # Stage 1のチェックポイントを確認\n",
    "    model_dir = STYLETTS2_DIR / \"Models\" / f\"jvs002_{dataset_name}\"\n",
    "    stage1_checkpoints = list(model_dir.glob(\"epoch_1st_*.pth\")) if model_dir.exists() else []\n",
    "    if not stage1_checkpoints and execute:\n",
    "        print(f\"⚠️ 警告: Stage 1のチェックポイントが見つかりません\")\n",
    "        print(f\"  Stage 1を先に実行してください\")\n",
    "        print(f\"  確認先: {model_dir}\")\n",
    "        return\n",
    "    \n",
    "    # 相対パスに変換（StyleTTS2ディレクトリから見たパス）\n",
    "    config_rel_path = config_path.relative_to(STYLETTS2_DIR)\n",
    "    config_rel_path_str = str(config_rel_path).replace('\\\\', '/')\n",
    "    \n",
    "    cmd = [\"python\", \"train_second.py\", \"-p\", config_rel_path_str]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Stage 2学習開始: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"コマンド: {' '.join(cmd)}\")\n",
    "    print(f\"作業ディレクトリ: {STYLETTS2_DIR}\")\n",
    "    if stage1_checkpoints:\n",
    "        latest_checkpoint = sorted(stage1_checkpoints)[-1]\n",
    "        print(f\"最新のStage 1チェックポイント: {latest_checkpoint.name}\")\n",
    "    print(f\"\\n⚠️ 注意: 学習には長時間かかります（数時間〜数日）\")\n",
    "    print(f\"進捗は以下で確認できます:\")\n",
    "    print(f\"  - ログ: {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}' / 'train.log'}\")\n",
    "    print(f\"  - TensorBoard: tensorboard --logdir {STYLETTS2_DIR / 'Models' / f'jvs002_{dataset_name}'}\")\n",
    "    \n",
    "    if execute:\n",
    "        print(f\"\\n学習を開始します...\")\n",
    "        print(f\"⚠️ 長時間実行されるため、ブラウザを閉じないでください\")\n",
    "        print(f\"⚠️ Colabの場合は、セッションがタイムアウトしないよう注意してください\\n\")\n",
    "        \n",
    "        try:\n",
    "            # リアルタイム出力のために、stdout/stderrを直接表示\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                cwd=str(STYLETTS2_DIR),\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                bufsize=1,\n",
    "                universal_newlines=True\n",
    "            )\n",
    "            \n",
    "            # リアルタイムで出力を表示\n",
    "            if process.stdout:\n",
    "                for line in process.stdout:\n",
    "                    print(line, end='')\n",
    "            \n",
    "            process.wait()\n",
    "            \n",
    "            if process.returncode == 0:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"✓ Stage 2学習完了: {dataset_name}\")\n",
    "                print(f\"{'='*60}\")\n",
    "            else:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"✗ Stage 2学習に失敗: {dataset_name} (終了コード: {process.returncode})\")\n",
    "                print(f\"{'='*60}\")\n",
    "                print(f\"\\nエラーログを確認してください:\")\n",
    "                log_path = STYLETTS2_DIR / \"Models\" / f\"jvs002_{dataset_name}\" / \"train.log\"\n",
    "                if log_path.exists():\n",
    "                    print(f\"  {log_path}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n⚠️ 学習が中断されました\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ エラー: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"\\n⚠️ execute=Falseのため、実際には実行しません。\")\n",
    "        print(\"実行する場合は、execute=Trueを指定してください。\")\n",
    "        print(\"\\nまたは、以下のコマンドをターミナルで実行してください:\")\n",
    "        print(f\"  cd {STYLETTS2_DIR}\")\n",
    "        print(f\"  {' '.join(cmd)}\")\n",
    "\n",
    "print(\"✓ Stage 2学習実行関数を定義しました\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "学習実行\n",
      "============================================================\n",
      "\n",
      "実行するデータセットを選択してください:\n",
      "  - phone_min4: 最小データセット（4文、検証用）\n",
      "  - feat_top10: 中規模データセット（10文）\n",
      "  - full100: 全データセット（100文）\n",
      "\n",
      "⚠️ 注意事項:\n",
      "  - 学習には長時間かかります（数時間〜数日）\n",
      "  - Colabの場合は、セッションがタイムアウトしないよう注意してください\n",
      "  - ブラウザを閉じると学習が中断されます\n",
      "  - 進捗はTensorBoardで確認できます\n",
      "\n",
      "============================================================\n",
      "実行設定: phone_min4\n",
      "============================================================\n",
      "Stage 1実行: False\n",
      "Stage 2実行: True\n",
      "\n",
      "============================================================\n",
      "Stage 2学習を開始します: phone_min4\n",
      "============================================================\n",
      "⚠️ 注意: Stage 1が完了していることを確認してください\n",
      "\n",
      "============================================================\n",
      "Stage 2学習開始: phone_min4\n",
      "============================================================\n",
      "コマンド: python train_second.py -p Configs/config_jvs002_phone_min4.yml\n",
      "作業ディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2\n",
      "最新のStage 1チェックポイント: epoch_1st_00070.pth\n",
      "\n",
      "⚠️ 注意: 学習には長時間かかります（数時間〜数日）\n",
      "進捗は以下で確認できます:\n",
      "  - ログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4/train.log\n",
      "  - TensorBoard: tensorboard --logdir /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4\n",
      "\n",
      "学習を開始します...\n",
      "⚠️ 長時間実行されるため、ブラウザを閉じないでください\n",
      "⚠️ Colabの場合は、セッションがタイムアウトしないよう注意してください\n",
      "\n",
      "Loading the first stage model at Models/jvs002_phone_min4/first_stage.pth ...\n",
      "decoder loaded\n",
      "text_encoder loaded\n",
      "style_encoder loaded\n",
      "text_aligner loaded\n",
      "pitch_extractor loaded\n",
      "BERT AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.9, 0.99)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: True\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 1e-05\n",
      "    lr: 1e-05\n",
      "    max_lr: 2e-05\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "decoder AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.0, 0.99)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: True\n",
      "    differentiable: False\n",
      "    eps: 1e-09\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 1e-05\n",
      "    lr: 1e-05\n",
      "    max_lr: 2e-05\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 0\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "NaN detected in g_loss at epoch 0, iteration 0\n",
      "NaN detected in g_loss at epoch 0, iteration 1\n",
      "NaN detected in g_loss at epoch 0, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 1\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Saving..\n",
      "NaN detected in g_loss at epoch 1, iteration 0\n",
      "NaN detected in g_loss at epoch 1, iteration 1\n",
      "NaN detected in g_loss at epoch 1, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 2\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 2, iteration 0\n",
      "NaN detected in g_loss at epoch 2, iteration 1\n",
      "NaN detected in g_loss at epoch 2, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 3\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 3, iteration 0\n",
      "NaN detected in g_loss at epoch 3, iteration 1\n",
      "NaN detected in g_loss at epoch 3, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 4\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 4, iteration 0\n",
      "NaN detected in g_loss at epoch 4, iteration 1\n",
      "NaN detected in g_loss at epoch 4, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 5\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 5, iteration 0\n",
      "NaN detected in g_loss at epoch 5, iteration 1\n",
      "NaN detected in g_loss at epoch 5, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 6\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 6, iteration 0\n",
      "NaN detected in g_loss at epoch 6, iteration 1\n",
      "NaN detected in g_loss at epoch 6, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 7\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 7, iteration 0\n",
      "NaN detected in g_loss at epoch 7, iteration 1\n",
      "NaN detected in g_loss at epoch 7, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 8\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 8, iteration 0\n",
      "NaN detected in g_loss at epoch 8, iteration 1\n",
      "NaN detected in g_loss at epoch 8, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 9\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 9, iteration 0\n",
      "NaN detected in g_loss at epoch 9, iteration 1\n",
      "NaN detected in g_loss at epoch 9, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 10\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 10, iteration 0\n",
      "NaN detected in g_loss at epoch 10, iteration 1\n",
      "NaN detected in g_loss at epoch 10, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 11\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Saving..\n",
      "NaN detected in g_loss at epoch 11, iteration 0\n",
      "NaN detected in g_loss at epoch 11, iteration 1\n",
      "NaN detected in g_loss at epoch 11, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 12\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 12, iteration 0\n",
      "NaN detected in g_loss at epoch 12, iteration 1\n",
      "NaN detected in g_loss at epoch 12, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 13\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 13, iteration 0\n",
      "NaN detected in g_loss at epoch 13, iteration 1\n",
      "NaN detected in g_loss at epoch 13, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 14\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 14, iteration 0\n",
      "NaN detected in g_loss at epoch 14, iteration 1\n",
      "NaN detected in g_loss at epoch 14, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 15\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 15, iteration 0\n",
      "NaN detected in g_loss at epoch 15, iteration 1\n",
      "NaN detected in g_loss at epoch 15, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 16\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 16, iteration 0\n",
      "NaN detected in g_loss at epoch 16, iteration 1\n",
      "NaN detected in g_loss at epoch 16, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 17\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 17, iteration 0\n",
      "NaN detected in g_loss at epoch 17, iteration 1\n",
      "NaN detected in g_loss at epoch 17, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 18\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 18, iteration 0\n",
      "NaN detected in g_loss at epoch 18, iteration 1\n",
      "NaN detected in g_loss at epoch 18, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 19\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 19, iteration 0\n",
      "NaN detected in g_loss at epoch 19, iteration 1\n",
      "NaN detected in g_loss at epoch 19, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 20\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 20, iteration 0\n",
      "NaN detected in g_loss at epoch 20, iteration 1\n",
      "NaN detected in g_loss at epoch 20, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 21\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Saving..\n",
      "NaN detected in g_loss at epoch 21, iteration 0\n",
      "NaN detected in g_loss at epoch 21, iteration 1\n",
      "NaN detected in g_loss at epoch 21, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 22\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 22, iteration 0\n",
      "NaN detected in g_loss at epoch 22, iteration 1\n",
      "NaN detected in g_loss at epoch 22, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 23\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 23, iteration 0\n",
      "NaN detected in g_loss at epoch 23, iteration 1\n",
      "NaN detected in g_loss at epoch 23, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 24\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 24, iteration 0\n",
      "NaN detected in g_loss at epoch 24, iteration 1\n",
      "NaN detected in g_loss at epoch 24, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 25\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 25, iteration 0\n",
      "NaN detected in g_loss at epoch 25, iteration 1\n",
      "NaN detected in g_loss at epoch 25, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 26\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 26, iteration 0\n",
      "NaN detected in g_loss at epoch 26, iteration 1\n",
      "NaN detected in g_loss at epoch 26, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 27\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 27, iteration 0\n",
      "NaN detected in g_loss at epoch 27, iteration 1\n",
      "NaN detected in g_loss at epoch 27, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 28\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 28, iteration 0\n",
      "NaN detected in g_loss at epoch 28, iteration 1\n",
      "NaN detected in g_loss at epoch 28, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 29\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 29, iteration 0\n",
      "NaN detected in g_loss at epoch 29, iteration 1\n",
      "NaN detected in g_loss at epoch 29, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 30\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 30, iteration 0\n",
      "NaN detected in g_loss at epoch 30, iteration 1\n",
      "NaN detected in g_loss at epoch 30, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 31\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Saving..\n",
      "NaN detected in g_loss at epoch 31, iteration 0\n",
      "NaN detected in g_loss at epoch 31, iteration 1\n",
      "NaN detected in g_loss at epoch 31, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 32\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 32, iteration 0\n",
      "NaN detected in g_loss at epoch 32, iteration 1\n",
      "NaN detected in g_loss at epoch 32, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 33\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 33, iteration 0\n",
      "NaN detected in g_loss at epoch 33, iteration 1\n",
      "NaN detected in g_loss at epoch 33, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 34\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 34, iteration 0\n",
      "NaN detected in g_loss at epoch 34, iteration 1\n",
      "NaN detected in g_loss at epoch 34, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 35\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 35, iteration 0\n",
      "NaN detected in g_loss at epoch 35, iteration 1\n",
      "NaN detected in g_loss at epoch 35, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 36\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 36, iteration 0\n",
      "NaN detected in g_loss at epoch 36, iteration 1\n",
      "NaN detected in g_loss at epoch 36, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 37\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 37, iteration 0\n",
      "NaN detected in g_loss at epoch 37, iteration 1\n",
      "NaN detected in g_loss at epoch 37, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 38\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 38, iteration 0\n",
      "NaN detected in g_loss at epoch 38, iteration 1\n",
      "NaN detected in g_loss at epoch 38, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 39\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "NaN detected in g_loss at epoch 39, iteration 0\n",
      "NaN detected in g_loss at epoch 39, iteration 1\n",
      "NaN detected in g_loss at epoch 39, iteration 2\n",
      "run into exception The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 641, in main\n",
      "    bert_dur = model.bert(texts, attention_mask=(~text_mask).int())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py\", line 192, in forward\n",
      "    return self.module(*inputs[0], **module_kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Utils/PLBERT/util.py\", line 9, in forward\n",
      "    outputs = super().forward(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/transformers/models/albert/modeling_albert.py\", line 685, in forward\n",
      "    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Epochs: 40\n",
      "No valid validation batches processed, skipping validation logging\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to compute predictor output for reconstruction: The expanded size of the tensor (535) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 535].  Tensor sizes: [1, 512]\n",
      "Failed to generate reconstruction examples: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/train_second.py\", line 776, in main\n",
      "    F0_fake, N_fake = model.predictor.F0Ntrain(p_en, s_dur)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/models.py\", line 526, in F0Ntrain\n",
      "    x, _ = self.shared(x.transpose(-1, -2))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1104, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 1005, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/mnt/e/dev/minimal-feature-corpus-tts/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py\", line 315, in check_input\n",
      "    raise RuntimeError(\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 640, got 512\n",
      "\n",
      "============================================================\n",
      "✓ Stage 2学習完了: phone_min4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 学習実行\n",
    "# ⚠️ 注意: 実行すると長時間かかります（数時間〜数日）。各データセットごとに個別に実行してください。\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"学習実行\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n実行するデータセットを選択してください:\")\n",
    "print(\"  - phone_min4: 最小データセット（4文、検証用）\")\n",
    "print(\"  - feat_top10: 中規模データセット（10文）\")\n",
    "print(\"  - full100: 全データセット（100文）\")\n",
    "print(\"\\n⚠️ 注意事項:\")\n",
    "print(\"  - 学習には長時間かかります（数時間〜数日）\")\n",
    "print(\"  - Colabの場合は、セッションがタイムアウトしないよう注意してください\")\n",
    "print(\"  - ブラウザを閉じると学習が中断されます\")\n",
    "print(\"  - 進捗はTensorBoardで確認できます\")\n",
    "\n",
    "# 実行するデータセットを指定\n",
    "dataset_name = \"phone_min4\"  # 変更可能: \"feat_top10\", \"full100\"\n",
    "# Stage 1 Done: \"phone_min4\", \"feat_top10\"\n",
    "# Stage 2 Done: \n",
    "\n",
    "# 実行フラグ（Trueにすると実際に実行されます）\n",
    "RUN_STAGE1 = False  # Stage 1学習を実行する場合は True に変更\n",
    "RUN_STAGE2 = True  # Stage 2学習を実行する場合は True に変更（Stage 1完了後）\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"実行設定: {dataset_name}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Stage 1実行: {RUN_STAGE1}\")\n",
    "print(f\"Stage 2実行: {RUN_STAGE2}\")\n",
    "\n",
    "if RUN_STAGE1:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Stage 1学習を開始します: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    run_stage1_training(dataset_name, execute=True)\n",
    "elif RUN_STAGE2:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Stage 2学習を開始します: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"⚠️ 注意: Stage 1が完了していることを確認してください\")\n",
    "    run_stage2_training(dataset_name, execute=True)\n",
    "else:\n",
    "    print(\"\\n⚠️ 実行フラグがFalseのため、学習は実行されません。\")\n",
    "    print(\"\\n学習を実行するには:\")\n",
    "    print(\"  1. RUN_STAGE1 = True に設定してStage 1を実行\")\n",
    "    print(\"  2. Stage 1完了後、RUN_STAGE2 = True に設定してStage 2を実行\")\n",
    "    print(\"\\nまたは、以下のコマンドをターミナルで実行:\")\n",
    "    print(f\"  cd {STYLETTS2_DIR}\")\n",
    "    print(f\"  accelerate launch --mixed_precision=fp16 train_first.py -p Configs/config_jvs002_{dataset_name}.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "学習済みモデルの確認\n",
      "------------------------------------------------------------\n",
      "\n",
      "phone_min4:\n",
      "  モデルディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4\n",
      "  チェックポイント: 13ファイル\n",
      "    - epoch_1st_00000.pth\n",
      "    - epoch_1st_00010.pth\n",
      "    - epoch_1st_00020.pth\n",
      "    - epoch_1st_00030.pth\n",
      "    - epoch_1st_00040.pth\n",
      "    ... 他 8ファイル\n",
      "  TensorBoardログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_phone_min4/tensorboard\n",
      "\n",
      "feat_top10:\n",
      "  モデルディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_feat_top10\n",
      "  チェックポイント: 9ファイル\n",
      "    - epoch_1st_00000.pth\n",
      "    - epoch_1st_00010.pth\n",
      "    - epoch_1st_00020.pth\n",
      "    - epoch_1st_00030.pth\n",
      "    - epoch_1st_00040.pth\n",
      "    ... 他 4ファイル\n",
      "  TensorBoardログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_feat_top10/tensorboard\n",
      "\n",
      "full100:\n",
      "  モデルディレクトリ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_full100\n",
      "  チェックポイント: 4ファイル\n",
      "    - epoch_1st_00000.pth\n",
      "    - epoch_1st_00010.pth\n",
      "    - epoch_1st_00020.pth\n",
      "    - epoch_1st_00030.pth\n",
      "  TensorBoardログ: /mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/Models/jvs002_full100/tensorboard\n"
     ]
    }
   ],
   "source": [
    "# 学習済みモデルの確認\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"学習済みモデルの確認\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for dataset_name in DATASETS:\n",
    "    model_dir = STYLETTS2_DIR / \"Models\" / f\"jvs002_{dataset_name}\"\n",
    "    \n",
    "    if model_dir.exists():\n",
    "        print(f\"\\n{dataset_name}:\")\n",
    "        print(f\"  モデルディレクトリ: {model_dir}\")\n",
    "        \n",
    "        # チェックポイントファイルを検索\n",
    "        checkpoint_files = list(model_dir.glob(\"*.pth\"))\n",
    "        if checkpoint_files:\n",
    "            print(f\"  チェックポイント: {len(checkpoint_files)}ファイル\")\n",
    "            for cp in sorted(checkpoint_files)[:5]:  # 最初の5つを表示\n",
    "                print(f\"    - {cp.name}\")\n",
    "            if len(checkpoint_files) > 5:\n",
    "                print(f\"    ... 他 {len(checkpoint_files) - 5}ファイル\")\n",
    "        else:\n",
    "            print(f\"  チェックポイント: なし（学習未完了）\")\n",
    "        \n",
    "        # TensorBoardログの確認\n",
    "        tb_dir = model_dir / \"tensorboard\"\n",
    "        if tb_dir.exists():\n",
    "            print(f\"  TensorBoardログ: {tb_dir}\")\n",
    "    else:\n",
    "        print(f\"\\n{dataset_name}: モデルディレクトリが存在しません（学習未開始）\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習完了後の確認\n",
    "\n",
    "学習が完了したら、以下のノートブックで評価音声を生成できます:\n",
    "- `04_generate_evaluation_audio.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習時間の比較\n",
    "\n",
    "複数のデータセットの学習時間を比較できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "学習時間比較\n",
      "================================================================================\n",
      "\n",
      "データセット               総時間             平均エポック時間             エポック数      開始時刻                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "jvs002_phone_min4    7分36秒           3秒                   80         2026-01-09 01:07:39 \n",
      "jvs002_feat_top10    5時間24分14秒       3分58秒                80         2026-01-08 17:44:35 \n",
      "jvs002_full100       N/A             N/A                  31         2026-01-08 07:23:56 \n",
      "\n",
      "================================================================================\n",
      "詳細情報\n",
      "================================================================================\n",
      "\n",
      "\n",
      "jvs002_phone_min4:\n",
      "  総学習時間: 0.13時間 (7.6分)\n",
      "  平均エポック時間: 0.00時間 (0.1分)\n",
      "  エポック数: 80\n",
      "  開始時刻: 2026-01-09 01:07:39\n",
      "  終了時刻: 2026-01-09 01:15:15\n",
      "  エポック時間サンプル:\n",
      "    Epoch 1: 0.00時間 (0.1分)\n",
      "    Epoch 2: 0.00時間 (0.1分)\n",
      "    Epoch 3: 0.00時間 (0.1分)\n",
      "    ...\n",
      "    Epoch 78: 0.00時間 (0.1分)\n",
      "    Epoch 79: 0.00時間 (0.1分)\n",
      "    Epoch 80: 0.00時間 (0.1分)\n",
      "\n",
      "jvs002_feat_top10:\n",
      "  総学習時間: 5.40時間 (324.2分)\n",
      "  平均エポック時間: 0.07時間 (4.0分)\n",
      "  エポック数: 80\n",
      "  開始時刻: 2026-01-08 17:44:35\n",
      "  終了時刻: 2026-01-08 23:08:50\n",
      "  エポック時間サンプル:\n",
      "    Epoch 1: 0.00時間 (0.1分)\n",
      "    Epoch 2: 0.00時間 (0.2分)\n",
      "    Epoch 3: 0.00時間 (0.3分)\n",
      "    ...\n",
      "    Epoch 78: 0.02時間 (1.4分)\n",
      "    Epoch 79: 0.02時間 (1.5分)\n",
      "    Epoch 80: 0.02時間 (1.2分)\n",
      "\n",
      "jvs002_full100:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcompare_training_times\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare_training_times\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 学習時間を比較\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mcompare_training_times\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSTYLETTS2_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/e/dev/minimal-feature-corpus-tts/StyleTTS2/compare_training_times.py:98\u001b[39m, in \u001b[36mcompare_training_times\u001b[39m\u001b[34m(base_dir)\u001b[39m\n\u001b[32m     95\u001b[39m log = result[\u001b[33m'\u001b[39m\u001b[33mtime_log\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  総学習時間: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtotal_time_hours\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33m時間 (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog.get(\u001b[33m'\u001b[39m\u001b[33mtotal_time_seconds\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m)/\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m分)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  平均エポック時間: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog.get(\u001b[33m'\u001b[39m\u001b[33maverage_epoch_time_hours\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m時間 (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog.get(\u001b[33m'\u001b[39m\u001b[33maverage_epoch_time_seconds\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m)/\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m分)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  エポック数: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(log.get(\u001b[33m'\u001b[39m\u001b[33mepoch_times\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m[]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "# 学習時間の比較\n",
    "import sys\n",
    "sys.path.insert(0, str(STYLETTS2_DIR))\n",
    "\n",
    "from compare_training_times import compare_training_times\n",
    "\n",
    "# 学習時間を比較\n",
    "compare_training_times(str(STYLETTS2_DIR / \"Models\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
