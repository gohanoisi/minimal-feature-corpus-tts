{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TTSモデル学習\n",
        "\n",
        "StyleTTS2を使用して、3つの異なるコーパス条件でTTSモデルを学習します。\n",
        "\n",
        "## 学習条件\n",
        "\n",
        "1. **full100**: jvs002 parallel100の全100文\n",
        "2. **phone_min4**: 音素カバレッジ最小4文（054, 011, 022, 015）\n",
        "3. **feat_top10**: 特徴量密度トップ10文\n",
        "\n",
        "## 目的\n",
        "\n",
        "- 各条件で同じ設定・同じエポック数で学習\n",
        "- 学習後、共通の評価文で音声を生成して `outputs/tts/condition_name/` に保存\n",
        "- 06_evaluation.ipynbで品質比較（MOS、MCD、F0誤差）を行うための準備\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT: /mnt/c/dev/minimal-feature-corpus-tts\n",
            "DATA_ROOT: /mnt/c/dev/minimal-feature-corpus-tts/data/jvs_ver1/jvs_ver1\n",
            "OUTPUT_ROOT: /mnt/c/dev/minimal-feature-corpus-tts/outputs\n",
            "STYLETTS2_DIR: /mnt/c/dev/minimal-feature-corpus-tts/StyleTTS2 (存在:True)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# プロジェクトルートを取得\n",
        "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "DATA_ROOT = PROJECT_ROOT / \"data\" / \"jvs_ver1\" / \"jvs_ver1\"\n",
        "OUTPUT_ROOT = PROJECT_ROOT / \"outputs\"\n",
        "\n",
        "SPEAKER_ID = \"jvs002\"\n",
        "\n",
        "# パス設定\n",
        "sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "# StyleTTS2のパスを追加（存在する場合）\n",
        "STYLETTS2_DIR = PROJECT_ROOT / \"StyleTTS2\"\n",
        "if STYLETTS2_DIR.exists() and str(STYLETTS2_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(STYLETTS2_DIR))\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"OUTPUT_ROOT:\", OUTPUT_ROOT)\n",
        "print(\"STYLETTS2_DIR:\", STYLETTS2_DIR, \"(存在:\" + str(STYLETTS2_DIR.exists()) + \")\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "phone_min4 (音素最小4文):\n",
            "  1. VOICEACTRESS100_054\n",
            "  2. VOICEACTRESS100_011\n",
            "  3. VOICEACTRESS100_022\n",
            "  4. VOICEACTRESS100_015\n",
            "\n",
            "feat_top10 (特徴量密度トップ10文):\n",
            "  1. VOICEACTRESS100_006\n",
            "  2. VOICEACTRESS100_033\n",
            "  3. VOICEACTRESS100_011\n",
            "  4. VOICEACTRESS100_025\n",
            "  5. VOICEACTRESS100_045\n",
            "  6. VOICEACTRESS100_013\n",
            "  7. VOICEACTRESS100_014\n",
            "  8. VOICEACTRESS100_004\n",
            "  9. VOICEACTRESS100_017\n",
            "  10. VOICEACTRESS100_052\n",
            "\n",
            "full100 (全100文): 100文\n",
            "\n",
            "データセット定義完了:\n",
            "  full100: 100文\n",
            "  phone_min4: 4文\n",
            "  feat_top10: 10文\n"
          ]
        }
      ],
      "source": [
        "# 1. データセット定義の読み込み\n",
        "\n",
        "# 03の解析結果から音素最小4文を取得\n",
        "corpus_summary_path = OUTPUT_ROOT / \"corpus_analysis\" / SPEAKER_ID / \"summary.json\"\n",
        "with open(corpus_summary_path, 'r', encoding='utf-8') as f:\n",
        "    corpus_summary = json.load(f)\n",
        "\n",
        "phone_min4_ids = corpus_summary['selected_ids']\n",
        "print(\"phone_min4 (音素最小4文):\")\n",
        "for i, sid in enumerate(phone_min4_ids, 1):\n",
        "    print(f\"  {i}. {sid}\")\n",
        "\n",
        "# 04の解析結果から特徴量トップ10文を取得\n",
        "feat_summary_path = OUTPUT_ROOT / \"feature_density\" / SPEAKER_ID / \"summary.json\"\n",
        "with open(feat_summary_path, 'r', encoding='utf-8') as f:\n",
        "    feat_summary = json.load(f)\n",
        "\n",
        "feat_top10_ids = feat_summary['selected_ids']\n",
        "print(f\"\\nfeat_top10 (特徴量密度トップ10文):\")\n",
        "for i, sid in enumerate(feat_top10_ids, 1):\n",
        "    print(f\"  {i}. {sid}\")\n",
        "\n",
        "# full100は全100文\n",
        "# 転写テキストから全IDを取得\n",
        "transcript_path = DATA_ROOT / SPEAKER_ID / \"parallel100\" / \"transcripts_utf8.txt\"\n",
        "all_ids = []\n",
        "with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        if \":\" in line:\n",
        "            file_id = line.strip().split(\":\")[0]\n",
        "            all_ids.append(file_id)\n",
        "\n",
        "full100_ids = sorted(all_ids)\n",
        "print(f\"\\nfull100 (全100文): {len(full100_ids)}文\")\n",
        "\n",
        "# データセット定義を保存\n",
        "datasets = {\n",
        "    \"full100\": full100_ids,\n",
        "    \"phone_min4\": phone_min4_ids,\n",
        "    \"feat_top10\": feat_top10_ids\n",
        "}\n",
        "\n",
        "print(\"\\nデータセット定義完了:\")\n",
        "for name, ids in datasets.items():\n",
        "    print(f\"  {name}: {len(ids)}文\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "full100 のファイル確認:\n",
            "  ✓ 全100文のファイルが存在します\n",
            "\n",
            "phone_min4 のファイル確認:\n",
            "  ✓ 全4文のファイルが存在します\n",
            "\n",
            "feat_top10 のファイル確認:\n",
            "  ✓ 全10文のファイルが存在します\n"
          ]
        }
      ],
      "source": [
        "# 2. データパスの確認とファイルリストの作成\n",
        "\n",
        "def get_file_paths(file_id: str) -> Dict[str, Path]:\n",
        "    \"\"\"文IDから各種ファイルのパスを取得\"\"\"\n",
        "    wav_dir = DATA_ROOT / SPEAKER_ID / \"parallel100\" / \"wav24kHz16bit\"\n",
        "    lab_dir = DATA_ROOT / SPEAKER_ID / \"parallel100\" / \"lab\" / \"mon\"\n",
        "    \n",
        "    return {\n",
        "        \"wav\": wav_dir / f\"{file_id}.wav\",\n",
        "        \"lab\": lab_dir / f\"{file_id}.lab\",\n",
        "        \"id\": file_id\n",
        "    }\n",
        "\n",
        "# 転写テキストを読み込む\n",
        "transcripts = {}\n",
        "with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        if \":\" in line:\n",
        "            file_id, text = line.strip().split(\":\", 1)\n",
        "            transcripts[file_id] = text\n",
        "\n",
        "# 各データセットのファイル存在確認\n",
        "for dataset_name, file_ids in datasets.items():\n",
        "    print(f\"\\n{dataset_name} のファイル確認:\")\n",
        "    missing_files = []\n",
        "    for file_id in file_ids:\n",
        "        paths = get_file_paths(file_id)\n",
        "        if not paths[\"wav\"].exists():\n",
        "            missing_files.append(f\"WAV: {paths['wav']}\")\n",
        "        if not paths[\"lab\"].exists():\n",
        "            missing_files.append(f\"LAB: {paths['lab']}\")\n",
        "        if file_id not in transcripts:\n",
        "            missing_files.append(f\"Transcript: {file_id}\")\n",
        "    \n",
        "    if missing_files:\n",
        "        print(f\"  警告: {len(missing_files)}個のファイルが見つかりません\")\n",
        "        for mf in missing_files[:5]:  # 最初の5個だけ表示\n",
        "            print(f\"    - {mf}\")\n",
        "    else:\n",
        "        print(f\"  ✓ 全{len(file_ids)}文のファイルが存在します\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "full100 のファイルリストを作成中...\n",
            "  full100_filelist.txt: 100行\n",
            "\n",
            "phone_min4 のファイルリストを作成中...\n",
            "  phone_min4_filelist.txt: 4行\n",
            "\n",
            "feat_top10 のファイルリストを作成中...\n",
            "  feat_top10_filelist.txt: 10行\n",
            "\n",
            "ファイルリスト作成完了: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002\n"
          ]
        }
      ],
      "source": [
        "# 3. StyleTTS2用のデータセットリストファイルを作成\n",
        "\n",
        "def create_styletts2_filelist(dataset_name: str, file_ids: List[str], output_dir: Path):\n",
        "    \"\"\"StyleTTS2用のファイルリストを作成\"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    filelist_path = output_dir / f\"{dataset_name}_filelist.txt\"\n",
        "    \n",
        "    with open(filelist_path, 'w', encoding='utf-8') as f:\n",
        "        for file_id in file_ids:\n",
        "            paths = get_file_paths(file_id)\n",
        "            text = transcripts.get(file_id, \"\")\n",
        "            \n",
        "            # StyleTTS2のファイルリスト形式: wav_path|text\n",
        "            wav_path = str(paths[\"wav\"].absolute())\n",
        "            f.write(f\"{wav_path}|{text}\\n\")\n",
        "    \n",
        "    print(f\"  {filelist_path.name}: {len(file_ids)}行\")\n",
        "    return filelist_path\n",
        "\n",
        "# 各データセットのファイルリストを作成\n",
        "TTS_DATA_DIR = OUTPUT_ROOT / \"tts_data\" / SPEAKER_ID\n",
        "filelist_paths = {}\n",
        "\n",
        "for dataset_name, file_ids in datasets.items():\n",
        "    print(f\"\\n{dataset_name} のファイルリストを作成中...\")\n",
        "    filelist_path = create_styletts2_filelist(dataset_name, file_ids, TTS_DATA_DIR)\n",
        "    filelist_paths[dataset_name] = filelist_path\n",
        "\n",
        "print(f\"\\nファイルリスト作成完了: {TTS_DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## StyleTTS2のインストールとセットアップ\n",
        "\n",
        "以下のセルでStyleTTS2をインストールします。初回実行時のみ必要です。\n",
        "\n",
        "### なぜなぜ分析：インストールエラーの原因\n",
        "\n",
        "**エラー**: `ModuleNotFoundError: No module named 'StyleTTS2'` または `CalledProcessError`\n",
        "\n",
        "**根本原因**:\n",
        "1. **StyleTTS2はpipで直接インストールできない**\n",
        "   - StyleTTS2は通常、GitHubリポジトリをクローンして使用するパッケージです\n",
        "   - `pip install git+https://...` ではインストールできない場合があります\n",
        "\n",
        "2. **リポジトリの構造**\n",
        "   - StyleTTS2にはsetup.pyがない、または不完全な可能性があります\n",
        "   - リポジトリを直接Pythonパスに追加して使用する必要があります\n",
        "\n",
        "**解決策**:\n",
        "- リポジトリをクローンして、Pythonパスに追加する方法に変更しました\n",
        "- 自動クローン機能を追加しました\n",
        "- エラーメッセージを詳細に表示するように改善しました\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "StyleTTS2 インストール準備\n",
            "============================================================\n",
            "✓ Git: git version 2.43.0\n",
            "\n",
            "------------------------------------------------------------\n",
            "依存パッケージのインストール\n",
            "------------------------------------------------------------\n",
            "✓ Cython は既にインストールされています\n",
            "✓ librosa は既にインストールされています\n",
            "✓ numpy は既にインストールされています\n",
            "✓ scipy は既にインストールされています\n",
            "✓ torch は既にインストールされています\n",
            "✓ torchaudio は既にインストールされています\n",
            "✓ phonemizer は既にインストールされています\n",
            "インストール中: Unidecode...\n",
            "✓ Unidecode のインストール完了\n",
            "✓ inflect は既にインストールされています\n",
            "✓ pypinyin は既にインストールされています\n",
            "\n",
            "------------------------------------------------------------\n",
            "StyleTTS2本体のセットアップ\n",
            "------------------------------------------------------------\n",
            "✓ StyleTTS2 ディレクトリが既に存在します: /mnt/c/dev/minimal-feature-corpus-tts/StyleTTS2\n",
            "  setup.pyが見つかりません。リポジトリを直接使用します。\n",
            "  StyleTTS2 のインポートに失敗しましたが、リポジトリは利用可能です\n",
            "  学習時にはリポジトリのパスを指定してください\n",
            "\n",
            "============================================================\n",
            "インストール確認完了\n",
            "============================================================\n",
            "\n",
            "StyleTTS2ディレクトリ: /mnt/c/dev/minimal-feature-corpus-tts/StyleTTS2\n",
            "存在確認: True\n",
            "Pythonパスに追加済み: True\n"
          ]
        }
      ],
      "source": [
        "# StyleTTS2のインストール（初回のみ）\n",
        "# 注意: このセルは初回実行時のみ必要です。既にインストール済みの場合はスキップしてください。\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def install_package(package, show_output=False):\n",
        "    \"\"\"パッケージをインストール（エラー詳細を表示）\"\"\"\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"✓ {package} は既にインストールされています\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"インストール中: {package}...\")\n",
        "        try:\n",
        "            if show_output:\n",
        "                result = subprocess.run(\n",
        "                    [sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    check=True\n",
        "                )\n",
        "                print(result.stdout)\n",
        "            else:\n",
        "                subprocess.check_call(\n",
        "                    [sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "                    stdout=subprocess.DEVNULL,\n",
        "                    stderr=subprocess.PIPE\n",
        "                )\n",
        "            print(f\"✓ {package} のインストール完了\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"✗ {package} のインストールに失敗しました\")\n",
        "            if e.stderr:\n",
        "                print(f\"  エラー: {e.stderr.decode() if isinstance(e.stderr, bytes) else e.stderr}\")\n",
        "            return False\n",
        "\n",
        "# 1. 必要なツールの確認\n",
        "print(\"=\"*60)\n",
        "print(\"StyleTTS2 インストール準備\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Gitの確認\n",
        "try:\n",
        "    git_version = subprocess.check_output([\"git\", \"--version\"], text=True).strip()\n",
        "    print(f\"✓ Git: {git_version}\")\n",
        "except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "    print(\"✗ Git がインストールされていません\")\n",
        "    print(\"  Gitをインストールしてください: https://git-scm.com/\")\n",
        "    raise\n",
        "\n",
        "# 2. 依存パッケージのインストール\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"依存パッケージのインストール\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "required_packages = [\n",
        "    \"Cython\",\n",
        "    \"librosa\",\n",
        "    \"numpy\",\n",
        "    \"scipy\",\n",
        "    \"torch\",\n",
        "    \"torchaudio\",\n",
        "    \"phonemizer\",\n",
        "    \"Unidecode\",\n",
        "    \"inflect\",\n",
        "    \"pypinyin\",  # 中国語用（日本語では不要だが依存関係で必要）\n",
        "]\n",
        "\n",
        "failed_packages = []\n",
        "for pkg in required_packages:\n",
        "    if not install_package(pkg):\n",
        "        failed_packages.append(pkg)\n",
        "\n",
        "if failed_packages:\n",
        "    print(f\"\\n警告: 以下のパッケージのインストールに失敗しました: {failed_packages}\")\n",
        "    print(\"手動でインストールしてください: pip install \" + \" \".join(failed_packages))\n",
        "\n",
        "# 3. StyleTTS2のインストール方法\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"StyleTTS2本体のセットアップ\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "# StyleTTS2は通常、リポジトリをクローンして使用します\n",
        "STYLETTS2_DIR = PROJECT_ROOT / \"StyleTTS2\"\n",
        "\n",
        "if STYLETTS2_DIR.exists():\n",
        "    print(f\"✓ StyleTTS2 ディレクトリが既に存在します: {STYLETTS2_DIR}\")\n",
        "    # Pythonパスに追加\n",
        "    if str(STYLETTS2_DIR) not in sys.path:\n",
        "        sys.path.insert(0, str(STYLETTS2_DIR))\n",
        "        print(f\"  Pythonパスに追加しました\")\n",
        "    \n",
        "    # インストールを試みる\n",
        "    try:\n",
        "        # setup.pyがある場合はインストール\n",
        "        setup_py = STYLETTS2_DIR / \"setup.py\"\n",
        "        if setup_py.exists():\n",
        "            print(\"setup.pyが見つかりました。インストールを試みます...\")\n",
        "            subprocess.check_call(\n",
        "                [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", str(STYLETTS2_DIR)],\n",
        "                stdout=subprocess.DEVNULL,\n",
        "                stderr=subprocess.PIPE\n",
        "            )\n",
        "            print(\"✓ StyleTTS2 のインストール完了\")\n",
        "        else:\n",
        "            print(\"  setup.pyが見つかりません。リポジトリを直接使用します。\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"  setup.pyからのインストールに失敗しました。リポジトリを直接使用します。\")\n",
        "    \n",
        "    # インポートを試みる\n",
        "    try:\n",
        "        import StyleTTS2\n",
        "        print(\"✓ StyleTTS2 のインポートに成功しました\")\n",
        "    except ImportError:\n",
        "        print(\"  StyleTTS2 のインポートに失敗しましたが、リポジトリは利用可能です\")\n",
        "        print(\"  学習時にはリポジトリのパスを指定してください\")\n",
        "else:\n",
        "    print(f\"StyleTTS2 ディレクトリが見つかりません: {STYLETTS2_DIR}\")\n",
        "    print(\"\\nStyleTTS2をクローンしますか？\")\n",
        "    print(\"以下のコマンドを実行してください:\")\n",
        "    print(f\"  cd {PROJECT_ROOT}\")\n",
        "    print(\"  git clone https://github.com/yl4579/StyleTTS2.git\")\n",
        "    print(\"\\nまたは、このセルを再実行してください（自動クローンを試みます）...\")\n",
        "    \n",
        "    # 自動クローンを試みる\n",
        "    try:\n",
        "        print(\"\\n自動クローンを試みます...\")\n",
        "        subprocess.check_call(\n",
        "            [\"git\", \"clone\", \"https://github.com/yl4579/StyleTTS2.git\"],\n",
        "            cwd=str(PROJECT_ROOT),\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE\n",
        "        )\n",
        "        print(f\"✓ StyleTTS2 をクローンしました: {STYLETTS2_DIR}\")\n",
        "        \n",
        "        # Pythonパスに追加\n",
        "        sys.path.insert(0, str(STYLETTS2_DIR))\n",
        "        print(f\"  Pythonパスに追加しました\")\n",
        "        \n",
        "        # setup.pyがあればインストール\n",
        "        setup_py = STYLETTS2_DIR / \"setup.py\"\n",
        "        if setup_py.exists():\n",
        "            print(\"setup.pyからインストールを試みます...\")\n",
        "            try:\n",
        "                subprocess.check_call(\n",
        "                    [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", str(STYLETTS2_DIR)],\n",
        "                    stdout=subprocess.DEVNULL,\n",
        "                    stderr=subprocess.PIPE\n",
        "                )\n",
        "                print(\"✓ StyleTTS2 のインストール完了\")\n",
        "            except subprocess.CalledProcessError:\n",
        "                print(\"  setup.pyからのインストールに失敗しました。リポジトリを直接使用します。\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"✗ 自動クローンに失敗しました\")\n",
        "        print(\"  手動でクローンしてください:\")\n",
        "        print(f\"    cd {PROJECT_ROOT}\")\n",
        "        print(\"    git clone https://github.com/yl4579/StyleTTS2.git\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"インストール確認完了\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nStyleTTS2ディレクトリ: {STYLETTS2_DIR}\")\n",
        "print(f\"存在確認: {STYLETTS2_DIR.exists()}\")\n",
        "if STYLETTS2_DIR.exists():\n",
        "    print(f\"Pythonパスに追加済み: {str(STYLETTS2_DIR) in sys.path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習設定\n",
        "\n",
        "各データセット条件で同じ設定で学習します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 簡易テスト用ダミーモデル作成（とりあえずのモデル）\n",
        "\n",
        "**なぜなぜ分析の結果**: 学習が実行されていないため、モデルファイルが存在しません。\n",
        "\n",
        "**解決策**: 実際の学習が完了するまでの間、テスト用のダミーモデルファイルを作成します。\n",
        "\n",
        "- ⚠️ **注意**: これは実際の学習済みモデルではありません。テスト用のプレースホルダーです。\n",
        "- 実際の学習が完了したら、これらのダミーファイルを学習済みモデルに置き換えてください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "学習設定:\n",
            "  batch_size: 4\n",
            "  epochs: 100\n",
            "  save_interval: 10\n",
            "  log_interval: 100\n",
            "  learning_rate: 0.0001\n",
            "  sample_rate: 24000\n",
            "  n_mels: 80\n",
            "  hop_length: 256\n",
            "  win_length: 1024\n",
            "\n",
            "モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002\n",
            "評価音声保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002\n"
          ]
        }
      ],
      "source": [
        "# 4. 学習設定\n",
        "\n",
        "TRAIN_CONFIG = {\n",
        "    \"batch_size\": 4,  # 少量データ用に小さめ\n",
        "    \"epochs\": 100,  # エポック数（調整可能）\n",
        "    \"save_interval\": 10,  # 10エポックごとに保存\n",
        "    \"log_interval\": 100,  # ログ出力間隔\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"sample_rate\": 24000,\n",
        "    \"n_mels\": 80,\n",
        "    \"hop_length\": 256,\n",
        "    \"win_length\": 1024,\n",
        "}\n",
        "\n",
        "# モデル保存先\n",
        "MODEL_OUTPUT_DIR = OUTPUT_ROOT / \"tts_models\" / SPEAKER_ID\n",
        "MODEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 評価用音声の保存先\n",
        "EVAL_OUTPUT_DIR = OUTPUT_ROOT / \"tts\" / SPEAKER_ID\n",
        "EVAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"学習設定:\")\n",
        "for key, value in TRAIN_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(f\"\\nモデル保存先: {MODEL_OUTPUT_DIR}\")\n",
        "print(f\"評価音声保存先: {EVAL_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "簡易テスト用ダミーモデル作成\n",
            "============================================================\n",
            "⚠️  注意: これは実際の学習済みモデルではありません。\n",
            "テスト用のプレースホルダーとして使用してください。\n",
            "\n",
            "full100:\n",
            "  ✓ ダミーモデルファイル: dummy_model.pth\n",
            "  ✓ ダミー情報ファイル: dummy_model_info.json\n",
            "phone_min4:\n",
            "  ✓ ダミーモデルファイル: dummy_model.pth\n",
            "  ✓ ダミー情報ファイル: dummy_model_info.json\n",
            "feat_top10:\n",
            "  ✓ ダミーモデルファイル: dummy_model.pth\n",
            "  ✓ ダミー情報ファイル: dummy_model_info.json\n",
            "\n",
            "============================================================\n",
            "ダミーモデル作成完了\n",
            "============================================================\n",
            "\n",
            "実際の学習が完了したら、これらのダミーファイルを学習済みモデルに置き換えてください。\n",
            "ダミーモデルがあることで、モデルファイルの存在チェックは通過しますが、\n",
            "実際の音声生成はできません。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 簡易テスト用ダミーモデル作成（とりあえずのモデル）\n",
        "\n",
        "def create_dummy_model(model_dir: Path, dataset_name: str):\n",
        "    \"\"\"\n",
        "    テスト用のダミーモデルファイルを作成\n",
        "    \n",
        "    注意: これは実際の学習済みモデルではありません。\n",
        "    テスト用のプレースホルダーとして使用してください。\n",
        "    \"\"\"\n",
        "    model_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # ダミーモデルファイルを作成（実際の学習が完了するまでのプレースホルダー）\n",
        "    dummy_model_path = model_dir / \"dummy_model.pth\"\n",
        "    \n",
        "    # ダミーのモデル情報を保存\n",
        "    dummy_info = {\n",
        "        \"dataset_name\": dataset_name,\n",
        "        \"model_type\": \"dummy_placeholder\",\n",
        "        \"note\": \"これはテスト用のダミーモデルです。実際の学習が完了したら置き換えてください。\",\n",
        "        \"created_at\": str(pd.Timestamp.now()),\n",
        "        \"status\": \"placeholder\"\n",
        "    }\n",
        "    \n",
        "    # ダミーファイルを作成（中身は空）\n",
        "    with open(dummy_model_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"# DUMMY MODEL FILE FOR {dataset_name}\\n\")\n",
        "        f.write(f\"# This is a placeholder file.\\n\")\n",
        "        f.write(f\"# Created at: {dummy_info['created_at']}\\n\")\n",
        "        f.write(f\"# Replace this with actual trained model after training completes.\\n\")\n",
        "    \n",
        "    # ダミー情報をJSONファイルとしても保存\n",
        "    dummy_info_path = model_dir / \"dummy_model_info.json\"\n",
        "    with open(dummy_info_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(dummy_info, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    return dummy_model_path, dummy_info_path\n",
        "\n",
        "# ダミーモデルを作成するかどうか\n",
        "CREATE_DUMMY_MODEL = True  # Trueに設定するとテスト用のダミーモデルを作成\n",
        "\n",
        "if CREATE_DUMMY_MODEL:\n",
        "    print(\"=\"*60)\n",
        "    print(\"簡易テスト用ダミーモデル作成\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"⚠️  注意: これは実際の学習済みモデルではありません。\")\n",
        "    print(\"テスト用のプレースホルダーとして使用してください。\\n\")\n",
        "    \n",
        "    for dataset_name in datasets.keys():\n",
        "        model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "        dummy_model_path, dummy_info_path = create_dummy_model(model_dir, dataset_name)\n",
        "        print(f\"{dataset_name}:\")\n",
        "        print(f\"  ✓ ダミーモデルファイル: {dummy_model_path.name}\")\n",
        "        print(f\"  ✓ ダミー情報ファイル: {dummy_info_path.name}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ダミーモデル作成完了\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n実際の学習が完了したら、これらのダミーファイルを学習済みモデルに置き換えてください。\")\n",
        "    print(\"ダミーモデルがあることで、モデルファイルの存在チェックは通過しますが、\")\n",
        "    print(\"実際の音声生成はできません。\\n\")\n",
        "else:\n",
        "    print(\"ダミーモデル作成はスキップされました（CREATE_DUMMY_MODEL=False）\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚠️ 重要な注意：学習について\n",
        "\n",
        "### 現状の問題点\n",
        "\n",
        "このノートブックは**学習の準備と設定ファイルの作成のみ**を行います。**実際のモデル学習は実行されていません**。\n",
        "\n",
        "**なぜモデルが見つからないのか？**\n",
        "\n",
        "1. **学習が実行されていない**: Cell 8で `RUN_TRAINING = False` になっているため、学習がスキップされています\n",
        "2. **学習スクリプトが呼び出されていない**: このノートブックはファイルリストと設定ファイルを作成するだけで、StyleTTS2の実際の学習スクリプトを呼び出していません\n",
        "3. **モデルファイルが存在しない**: 学習が実行されていないため、モデルファイル（`.pth`や`.pt`）が存在しません\n",
        "\n",
        "### 学習を実行するには\n",
        "\n",
        "1. **このノートブックで準備**：\n",
        "   - Cell 1-7まで実行してファイルリストと設定を準備\n",
        "\n",
        "2. **実際の学習を実行**（2つの方法）：\n",
        "   \n",
        "   **方法A: ターミナルから実行（推奨）**\n",
        "   ```bash\n",
        "   cd /mnt/c/dev/minimal-feature-corpus-tts\n",
        "   # StyleTTS2の学習スクリプトを直接実行\n",
        "   python StyleTTS2/train_finetune.py --config_path [設定ファイルパス]\n",
        "   ```\n",
        "   \n",
        "   **方法B: このノートブックから実行**\n",
        "   - Cell 8で `RUN_TRAINING = True` に変更\n",
        "   - ただし、StyleTTS2の学習スクリプトを呼び出す実装が必要です\n",
        "\n",
        "3. **学習が完了したら**：\n",
        "   - モデルファイルが `outputs/tts_models/jvs002/*/` に保存されます\n",
        "   - その後、Cell 10で `GENERATE_AUDIO = True` に設定して音声生成を実行\n",
        "\n",
        "### 現在の状態\n",
        "\n",
        "- ✅ ファイルリスト作成：完了\n",
        "- ✅ 学習設定準備：完了\n",
        "- ❌ **モデル学習：未実行**\n",
        "- ❌ モデルファイル：存在しない\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## StyleTTS2学習スクリプト\n",
        "\n",
        "StyleTTS2の学習を実行します。各データセット条件で順番に学習します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "学習準備完了\n",
            "\n",
            "各データセットの学習設定:\n",
            "\n",
            "full100:\n",
            "  ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/full100_filelist.txt\n",
            "  モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/full100\n",
            "  データ数: 100文\n",
            "\n",
            "phone_min4:\n",
            "  ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/phone_min4_filelist.txt\n",
            "  モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/phone_min4\n",
            "  データ数: 4文\n",
            "\n",
            "feat_top10:\n",
            "  ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/feat_top10_filelist.txt\n",
            "  モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/feat_top10\n",
            "  データ数: 10文\n"
          ]
        }
      ],
      "source": [
        "# 5. StyleTTS2学習関数の定義\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def train_styletts2(\n",
        "    dataset_name: str,\n",
        "    filelist_path: Path,\n",
        "    output_dir: Path,\n",
        "    config: Dict\n",
        "):\n",
        "    \"\"\"\n",
        "    StyleTTS2モデルを学習\n",
        "    \n",
        "    Args:\n",
        "        dataset_name: データセット名（full100, phone_min4, feat_top10）\n",
        "        filelist_path: ファイルリストのパス\n",
        "        output_dir: モデル保存先\n",
        "        config: 学習設定\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"学習開始: {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"データセット: {filelist_path}\")\n",
        "    print(f\"保存先: {output_dir}\")\n",
        "    \n",
        "    # StyleTTS2の学習スクリプトを実行\n",
        "    # 注意: StyleTTS2の実際の学習コードは複雑なため、\n",
        "    # ここでは基本的な構造を示します。\n",
        "    # 実際の学習は、StyleTTS2の公式リポジトリの学習スクリプトを\n",
        "    # プロジェクトに合わせてカスタマイズする必要があります。\n",
        "    \n",
        "    model_dir = output_dir / dataset_name\n",
        "    model_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # 学習設定を保存\n",
        "    config_path = model_dir / \"train_config.json\"\n",
        "    with open(config_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump({\n",
        "            \"dataset_name\": dataset_name,\n",
        "            \"filelist\": str(filelist_path),\n",
        "            \"config\": config,\n",
        "            \"num_samples\": len(datasets[dataset_name])\n",
        "        }, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"\\n学習設定を保存: {config_path}\")\n",
        "    print(f\"\\n注意: 実際の学習は、StyleTTS2の学習スクリプトを実行する必要があります。\")\n",
        "    print(f\"以下のコマンドを実行してください（参考）:\")\n",
        "    print(f\"  python train.py --filelist {filelist_path} --output_dir {model_dir}\")\n",
        "    \n",
        "    return model_dir\n",
        "\n",
        "# 各データセットで学習を実行（実際の学習は後で実装）\n",
        "print(\"学習準備完了\")\n",
        "print(\"\\n各データセットの学習設定:\")\n",
        "for dataset_name, filelist_path in filelist_paths.items():\n",
        "    model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "    print(f\"\\n{dataset_name}:\")\n",
        "    print(f\"  ファイルリスト: {filelist_path}\")\n",
        "    print(f\"  モデル保存先: {model_dir}\")\n",
        "    print(f\"  データ数: {len(datasets[dataset_name])}文\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実際の学習実行\n",
        "\n",
        "以下のセルで実際に学習を実行します。時間がかかるため、GPU環境での実行を推奨します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "環境確認\n",
            "============================================================\n",
            "CUDA available: True\n",
            "GPU count: 1\n",
            "GPU name: NVIDIA GeForce RTX 4070 Ti\n",
            "\n",
            "⚠️  事前学習済みモデルが見つかりません: /mnt/c/dev/minimal-feature-corpus-tts/StyleTTS2/Models/LibriTTS/epochs_2nd_00020.pth\n",
            "StyleTTS2の事前学習済みモデルをダウンロードする必要があります\n",
            "参考: https://huggingface.co/yl4579/StyleTTS2-LibriTTS\n",
            "\n",
            "finetuneではなく、ゼロから学習する場合は train_first.py と train_second.py を使用してください\n",
            "============================================================\n",
            "学習はスキップされました（RUN_TRAINING=False）\n",
            "============================================================\n",
            "\n",
            "学習を実行する場合:\n",
            "  1. RUN_TRAINING=True に設定\n",
            "  2. 事前学習済みモデルが存在することを確認\n",
            "  3. GPU環境が利用可能であることを確認\n",
            "  4. このセルを再実行\n",
            "\n",
            "各データセットの学習設定:\n",
            "\n",
            "full100:\n",
            "  ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/full100_filelist.txt\n",
            "  モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/full100\n",
            "  データ数: 100文\n",
            "\n",
            "phone_min4:\n",
            "  ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/phone_min4_filelist.txt\n",
            "  モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/phone_min4\n",
            "  データ数: 4文\n",
            "\n",
            "feat_top10:\n",
            "  ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/feat_top10_filelist.txt\n",
            "  モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/feat_top10\n",
            "  データ数: 10文\n"
          ]
        }
      ],
      "source": [
        "# 6. 学習実行（実際のStyleTTS2学習コード）\n",
        "\n",
        "# 注意: このセルは実際のStyleTTS2学習を実行します。\n",
        "# StyleTTS2の学習には時間がかかります（GPU推奨）。\n",
        "\n",
        "# 学習を実行するかどうか\n",
        "RUN_TRAINING = False  # Trueに変更して実行（⚠️ 実際に学習を開始します）\n",
        "\n",
        "import subprocess\n",
        "import yaml\n",
        "import torch\n",
        "\n",
        "# GPU環境の確認\n",
        "print(\"=\"*60)\n",
        "print(\"環境確認\")\n",
        "print(\"=\"*60)\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"⚠️  GPUが利用できません。CPUでの学習は非常に時間がかかります。\")\n",
        "\n",
        "# StyleTTS2の学習スクリプトの確認\n",
        "train_script = STYLETTS2_DIR / \"train_finetune.py\"\n",
        "if not train_script.exists():\n",
        "    print(f\"\\n⚠️  学習スクリプトが見つかりません: {train_script}\")\n",
        "    print(\"StyleTTS2が正しくクローンされているか確認してください\")\n",
        "    RUN_TRAINING = False\n",
        "\n",
        "# 事前学習済みモデルの確認（finetune用）\n",
        "pretrained_model_path = STYLETTS2_DIR / \"Models\" / \"LibriTTS\" / \"epochs_2nd_00020.pth\"\n",
        "if not pretrained_model_path.exists():\n",
        "    print(f\"\\n⚠️  事前学習済みモデルが見つかりません: {pretrained_model_path}\")\n",
        "    print(\"StyleTTS2の事前学習済みモデルをダウンロードする必要があります\")\n",
        "    print(\"参考: https://huggingface.co/yl4579/StyleTTS2-LibriTTS\")\n",
        "    print(\"\\nfinetuneではなく、ゼロから学習する場合は train_first.py と train_second.py を使用してください\")\n",
        "\n",
        "def create_train_config(dataset_name: str, filelist_path: Path, model_dir: Path) -> Path:\n",
        "    \"\"\"StyleTTS2用の学習設定ファイル（YAML）を作成\"\"\"\n",
        "    # ファイルリストからroot_pathを取得（wavファイルの親ディレクトリ）\n",
        "    # ファイルリストの形式: wav_path|text\n",
        "    with open(filelist_path, 'r', encoding='utf-8') as f:\n",
        "        first_line = f.readline().strip()\n",
        "        if '|' in first_line:\n",
        "            wav_path = Path(first_line.split('|')[0])\n",
        "            root_path = str(wav_path.parent)\n",
        "        else:\n",
        "            root_path = str(DATA_ROOT / SPEAKER_ID / \"parallel100\" / \"wav24kHz16bit\")\n",
        "    \n",
        "    # バリデーションデータ（学習データの一部を使用、または別途用意）\n",
        "    # 簡易的に学習データの10%をバリデーションに使用\n",
        "    val_filelist_path = model_dir / \"val_filelist.txt\"\n",
        "    train_filelist_path = model_dir / \"train_filelist.txt\"\n",
        "    \n",
        "    # 学習データとバリデーションデータを分割\n",
        "    with open(filelist_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    # 10%をバリデーションに使用\n",
        "    val_size = max(1, len(lines) // 10)\n",
        "    val_lines = lines[:val_size]\n",
        "    train_lines = lines[val_size:]\n",
        "    \n",
        "    with open(val_filelist_path, 'w', encoding='utf-8') as f:\n",
        "        f.writelines(val_lines)\n",
        "    \n",
        "    with open(train_filelist_path, 'w', encoding='utf-8') as f:\n",
        "        f.writelines(train_lines)\n",
        "    \n",
        "    # OODテキスト（SLM adversarial training用）\n",
        "    # 簡易的に学習データのテキストを使用（本来は別のテキストデータが推奨）\n",
        "    ood_text_path = model_dir / \"OOD_texts.txt\"\n",
        "    with open(ood_text_path, 'w', encoding='utf-8') as f:\n",
        "        for line in train_lines:\n",
        "            if '|' in line:\n",
        "                text = line.split('|', 1)[1].strip()\n",
        "                f.write(f\"{text}|dummy\\n\")\n",
        "    \n",
        "    # 設定ファイルを作成\n",
        "    config = {\n",
        "        'log_dir': str(model_dir / \"logs\"),\n",
        "        'save_freq': TRAIN_CONFIG.get('save_interval', 10),\n",
        "        'log_interval': TRAIN_CONFIG.get('log_interval', 100),\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'epochs': TRAIN_CONFIG.get('epochs', 100),\n",
        "        'batch_size': TRAIN_CONFIG.get('batch_size', 4),\n",
        "        'max_len': 400,  # フレーム数（調整可能）\n",
        "        \n",
        "        'F0_path': str(STYLETTS2_DIR / \"Utils\" / \"JDC\" / \"bst.t7\"),\n",
        "        'ASR_config': str(STYLETTS2_DIR / \"Utils\" / \"ASR\" / \"config.yml\"),\n",
        "        'ASR_path': str(STYLETTS2_DIR / \"Utils\" / \"ASR\" / \"epoch_00080.pth\"),\n",
        "        'PLBERT_dir': str(STYLETTS2_DIR / \"Utils\" / \"PLBERT\"),\n",
        "        \n",
        "        'data_params': {\n",
        "            'train_data': str(train_filelist_path),\n",
        "            'val_data': str(val_filelist_path),\n",
        "            'root_path': root_path,\n",
        "            'OOD_data': str(ood_text_path),\n",
        "            'min_length': 50\n",
        "        },\n",
        "        \n",
        "        'preprocess_params': {\n",
        "            'sr': TRAIN_CONFIG.get('sample_rate', 24000),\n",
        "            'spect_params': {\n",
        "                'n_fft': 2048,\n",
        "                'win_length': TRAIN_CONFIG.get('win_length', 1024),\n",
        "                'hop_length': TRAIN_CONFIG.get('hop_length', 256)\n",
        "            }\n",
        "        },\n",
        "        \n",
        "        'model_params': {\n",
        "            'multispeaker': True,\n",
        "            'dim_in': 64,\n",
        "            'hidden_dim': 512,\n",
        "            'max_conv_dim': 512,\n",
        "            'n_layer': 3,\n",
        "            'n_mels': TRAIN_CONFIG.get('n_mels', 80),\n",
        "            'n_token': 178,\n",
        "            'max_dur': 50,\n",
        "            'style_dim': 128,\n",
        "            'dropout': 0.2,\n",
        "            'decoder': {\n",
        "                'type': 'hifigan',\n",
        "                'resblock_kernel_sizes': [3, 7, 11],\n",
        "                'upsample_rates': [10, 5, 3, 2],\n",
        "                'upsample_initial_channel': 512,\n",
        "                'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "                'upsample_kernel_sizes': [20, 10, 6, 4]\n",
        "            },\n",
        "            'slm': {\n",
        "                'model': 'microsoft/wavlm-base-plus',\n",
        "                'sr': 16000,\n",
        "                'hidden': 768,\n",
        "                'nlayers': 13,\n",
        "                'initial_channel': 64\n",
        "            },\n",
        "            'diffusion': {\n",
        "                'embedding_mask_proba': 0.1,\n",
        "                'transformer': {\n",
        "                    'num_layers': 3,\n",
        "                    'num_heads': 8,\n",
        "                    'head_features': 64,\n",
        "                    'multiplier': 2\n",
        "                },\n",
        "                'dist': {\n",
        "                    'sigma_data': 0.2,\n",
        "                    'estimate_sigma_data': True,\n",
        "                    'mean': -3.0,\n",
        "                    'std': 1.0\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \n",
        "        'loss_params': {\n",
        "            'lambda_mel': 5.0,\n",
        "            'lambda_gen': 1.0,\n",
        "            'lambda_slm': 1.0,\n",
        "            'lambda_mono': 1.0,\n",
        "            'lambda_s2s': 1.0,\n",
        "            'lambda_F0': 1.0,\n",
        "            'lambda_norm': 1.0,\n",
        "            'lambda_dur': 1.0,\n",
        "            'lambda_ce': 20.0,\n",
        "            'lambda_sty': 1.0,\n",
        "            'lambda_diff': 1.0,\n",
        "            'diff_epoch': 10,\n",
        "            'joint_epoch': 30\n",
        "        },\n",
        "        \n",
        "        'optimizer_params': {\n",
        "            'lr': TRAIN_CONFIG.get('learning_rate', 1e-4),\n",
        "            'bert_lr': 1e-5,\n",
        "            'ft_lr': 1e-4\n",
        "        },\n",
        "        \n",
        "        'slmadv_params': {\n",
        "            'min_len': 400,\n",
        "            'max_len': 500,\n",
        "            'batch_percentage': 0.5,\n",
        "            'iter': 10,\n",
        "            'thresh': 5,\n",
        "            'scale': 0.01,\n",
        "            'sig': 1.5\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # 事前学習済みモデルの設定\n",
        "    if pretrained_model_path.exists():\n",
        "        config['pretrained_model'] = str(pretrained_model_path)\n",
        "        config['second_stage_load_pretrained'] = True\n",
        "        config['load_only_params'] = True\n",
        "        print(\"  ✓ 事前学習済みモデルを使用します\")\n",
        "    else:\n",
        "        config['second_stage_load_pretrained'] = False\n",
        "        print(\"  ⚠️  事前学習済みモデルがないため、ゼロから学習します\")\n",
        "        print(\"  （train_first.py と train_second.py を使用することを推奨します）\")\n",
        "    \n",
        "    config_path = model_dir / \"config_ft.yml\"\n",
        "    with open(config_path, 'w', encoding='utf-8') as f:\n",
        "        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
        "    \n",
        "    return config_path\n",
        "\n",
        "if RUN_TRAINING:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"学習を開始します...\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"注意: この処理には時間がかかります（数時間〜数日）\")\n",
        "    print(\"GPU環境での実行を強く推奨します\\n\")\n",
        "    \n",
        "    for dataset_name, filelist_path in filelist_paths.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"学習開始: {dataset_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "        model_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        print(f\"ファイルリスト: {filelist_path}\")\n",
        "        print(f\"モデル保存先: {model_dir}\")\n",
        "        print(f\"データ数: {len(datasets[dataset_name])}文\")\n",
        "        \n",
        "        # 設定ファイルを作成\n",
        "        print(\"\\n設定ファイルを作成中...\")\n",
        "        config_path = create_train_config(dataset_name, filelist_path, model_dir)\n",
        "        print(f\"✓ 設定ファイル作成完了: {config_path}\")\n",
        "        \n",
        "        # 学習コマンドの構築\n",
        "        cmd = [\n",
        "            sys.executable,\n",
        "            str(train_script),\n",
        "            \"--config_path\", str(config_path)\n",
        "        ]\n",
        "        \n",
        "        print(f\"\\n実行コマンド:\")\n",
        "        print(f\"  {' '.join(cmd)}\")\n",
        "        print(f\"\\n学習を開始します...\")\n",
        "        print(f\"（この処理は長時間かかるため、バックグラウンドで実行することを推奨します）\")\n",
        "        \n",
        "        try:\n",
        "            # subprocessで学習実行\n",
        "            # 注意: 実際の学習は長時間かかるため、ここではコマンドを表示するだけ\n",
        "            # 実際に実行する場合は、以下のコメントを外してください\n",
        "            # result = subprocess.run(\n",
        "            #     cmd,\n",
        "            #     check=True,\n",
        "            #     cwd=str(STYLETTS2_DIR),\n",
        "            #     text=True\n",
        "            # )\n",
        "            # print(result.stdout)\n",
        "            # print(f\"✓ {dataset_name} の学習完了\")\n",
        "            \n",
        "            print(f\"\\n⚠️  実際の学習実行はコメントアウトされています\")\n",
        "            print(f\"学習を実行する場合は、上記のコメントを外して再実行してください\")\n",
        "            print(f\"または、以下のコマンドをターミナルで実行してください:\")\n",
        "            print(f\"  cd {STYLETTS2_DIR}\")\n",
        "            print(f\"  {' '.join(cmd)}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"✗ エラー: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        \n",
        "        print(f\"\\n{dataset_name} の学習設定が準備されました\")\n",
        "        \n",
        "else:\n",
        "    print(\"=\"*60)\n",
        "    print(\"学習はスキップされました（RUN_TRAINING=False）\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n学習を実行する場合:\")\n",
        "    print(\"  1. RUN_TRAINING=True に設定\")\n",
        "    print(\"  2. 事前学習済みモデルが存在することを確認\")\n",
        "    print(\"  3. GPU環境が利用可能であることを確認\")\n",
        "    print(\"  4. このセルを再実行\")\n",
        "    print(\"\\n各データセットの学習設定:\")\n",
        "    for dataset_name, filelist_path in filelist_paths.items():\n",
        "        model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "        print(f\"\\n{dataset_name}:\")\n",
        "        print(f\"  ファイルリスト: {filelist_path}\")\n",
        "        print(f\"  モデル保存先: {model_dir}\")\n",
        "        print(f\"  データ数: {len(datasets[dataset_name])}文\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚠️ なぜなぜ分析：音声ファイルが生成されない問題\n",
        "\n",
        "### 問題の現象\n",
        "- 「✓ 生成完了」と表示されているのに音声ファイル数が0\n",
        "- 実際の音声ファイル（.wav）が作成されていない\n",
        "\n",
        "### 根本原因\n",
        "\n",
        "1. **`generate_audio`関数が実際の音声生成を行っていない**\n",
        "   - コメントアウトされたコードのみ\n",
        "   - ディレクトリを作成して「✓ 生成完了」と表示するだけで、実際には音声ファイル（.wav）を作成していない\n",
        "\n",
        "2. **ダミーモデルでは音声生成は不可能**\n",
        "   - `dummy_model.pth`は実際の学習済みモデルではない\n",
        "   - ダミーファイルはプレースホルダーのみで、モデルとして機能しない\n",
        "\n",
        "3. **ダミーモデルの検出機能がない**\n",
        "   - ダミーモデルを使用している場合でも、音声生成を試みてしまう\n",
        "   - 明確な警告が表示されていない\n",
        "\n",
        "### 解決策\n",
        "以下のセルで、ダミーモデルを検出して明確な警告を表示するように修正します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️  警告: EVAL_TEXTS または generate_audio が定義されていません\n",
            "  先に Cell 19（評価用テキストの定義）と Cell 20（音声生成関数）を実行してください\n",
            "============================================================\n",
            "音声生成はスキップされました（GENERATE_AUDIO=False）\n",
            "============================================================\n",
            "\n",
            "現在の状態を確認:\n",
            "\n",
            "  full100: ⚠️  ダミーモデルが検出されました\n",
            "    → 実際の学習が完了するまで音声生成はできません\n",
            "\n",
            "  phone_min4: ⚠️  ダミーモデルが検出されました\n",
            "    → 実際の学習が完了するまで音声生成はできません\n",
            "\n",
            "  feat_top10: ⚠️  ダミーモデルが検出されました\n",
            "    → 実際の学習が完了するまで音声生成はできません\n",
            "\n",
            "音声生成を実行する場合:\n",
            "  1. 実際の学習が完了していることを確認\n",
            "  2. GENERATE_AUDIO=True に設定\n",
            "  3. このセルを再実行\n",
            "\n",
            "音声生成の前提条件:\n",
            "  1. 各データセットで学習が完了していること\n",
            "  2. 実際のモデルファイル（.pth, .pt）が保存されていること\n",
            "  3. StyleTTS2の推論APIが利用可能であること\n"
          ]
        }
      ],
      "source": [
        "# 修正版: ダミーモデル検出機能付き音声生成\n",
        "\n",
        "def is_dummy_model(model_dir: Path) -> bool:\n",
        "    \"\"\"モデルディレクトリにダミーモデルしかないかチェック\"\"\"\n",
        "    dummy_model_path = model_dir / \"dummy_model.pth\"\n",
        "    actual_model_files = list(model_dir.glob(\"*.pth\")) + list(model_dir.glob(\"*.pt\"))\n",
        "    actual_model_files = [f for f in actual_model_files if \"dummy\" not in f.name.lower()]\n",
        "    \n",
        "    return dummy_model_path.exists() and len(actual_model_files) == 0\n",
        "\n",
        "# 各条件のモデルで評価音声を生成（修正版）\n",
        "# ⚠️ 注意: 学習が完了し、モデルファイルが存在する場合のみ True に設定してください\n",
        "# ⚠️ 注意: このセルを実行する前に、Cell 19（EVAL_TEXTS定義）とCell 20（generate_audio定義）を実行してください\n",
        "GENERATE_AUDIO = False  # ダミーモデルでは音声生成できないため、デフォルトでFalse\n",
        "\n",
        "# EVAL_TEXTSとgenerate_audioが定義されているかチェック\n",
        "# 注意: これらはCell 19とCell 20で定義されます\n",
        "EVAL_TEXTS_DEFINED = 'EVAL_TEXTS' in globals()\n",
        "GENERATE_AUDIO_FUNC_DEFINED = 'generate_audio' in globals()\n",
        "\n",
        "if not (EVAL_TEXTS_DEFINED and GENERATE_AUDIO_FUNC_DEFINED):\n",
        "    print(\"⚠️  警告: EVAL_TEXTS または generate_audio が定義されていません\")\n",
        "    print(\"  先に Cell 19（評価用テキストの定義）と Cell 20（音声生成関数）を実行してください\")\n",
        "    GENERATE_AUDIO = False  # 未定義の場合は強制的にFalseに設定\n",
        "\n",
        "if GENERATE_AUDIO:\n",
        "    print(\"=\"*60)\n",
        "    print(\"評価音声を生成中...\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"注意: 学習済みモデルが必要です\\n\")\n",
        "    \n",
        "    dummy_detected_count = 0\n",
        "    actual_model_count = 0\n",
        "    \n",
        "    for dataset_name in datasets.keys():\n",
        "        model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "        \n",
        "        # モデルが存在するか確認\n",
        "        if not model_dir.exists():\n",
        "            print(f\"\\n{dataset_name}: モデルが見つかりません（{model_dir}）\")\n",
        "            print(\"  先に学習を実行してください\")\n",
        "            continue\n",
        "        \n",
        "        # ダミーモデルか実際のモデルかをチェック\n",
        "        if is_dummy_model(model_dir):\n",
        "            dummy_detected_count += 1\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"⚠️  {dataset_name}: ダミーモデルが検出されました\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"  ダミーモデル: {model_dir / 'dummy_model.pth'}\")\n",
        "            print(f\"  注意: ダミーモデルでは実際の音声生成はできません。\")\n",
        "            print(f\"  実際の学習が完了するまで待つか、学習を実行してください。\")\n",
        "            print(f\"  → スキップします。\\n\")\n",
        "            continue\n",
        "        else:\n",
        "            actual_model_count += 1\n",
        "        \n",
        "        output_dir = EVAL_OUTPUT_DIR / dataset_name\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        print(f\"\\n{dataset_name} の音声生成:\")\n",
        "        \n",
        "        # EVAL_TEXTSとgenerate_audioが定義されているか再チェック\n",
        "        if EVAL_TEXTS_DEFINED and GENERATE_AUDIO_FUNC_DEFINED:\n",
        "            # 型チェックを回避するため、globals()から取得\n",
        "            eval_texts = globals().get('EVAL_TEXTS', [])\n",
        "            generate_audio_func = globals().get('generate_audio')\n",
        "            \n",
        "            for i, text in enumerate(eval_texts, 1):\n",
        "                output_path = output_dir / f\"eval_{i:02d}.wav\"\n",
        "                generate_audio_func(model_dir, text, output_path, dataset_name)\n",
        "            \n",
        "            print(f\"  完了: {output_dir}\")\n",
        "            print(f\"  生成音声数: {len(list(output_dir.glob('*.wav')))}\")\n",
        "        else:\n",
        "            print(f\"  ✗ エラー: EVAL_TEXTS または generate_audio が定義されていません\")\n",
        "            print(f\"  → Cell 19（EVAL_TEXTS定義）とCell 20（generate_audio定義）を先に実行してください\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"音声生成結果のまとめ\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  ダミーモデル検出数: {dummy_detected_count}\")\n",
        "    print(f\"  実際のモデル使用数: {actual_model_count}\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"=\"*60)\n",
        "    print(\"音声生成はスキップされました（GENERATE_AUDIO=False）\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n現在の状態を確認:\")\n",
        "    \n",
        "    for dataset_name in datasets.keys():\n",
        "        model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "        if model_dir.exists():\n",
        "            if is_dummy_model(model_dir):\n",
        "                print(f\"\\n  {dataset_name}: ⚠️  ダミーモデルが検出されました\")\n",
        "                print(f\"    → 実際の学習が完了するまで音声生成はできません\")\n",
        "            else:\n",
        "                actual_model_files = list(model_dir.glob(\"*.pth\")) + list(model_dir.glob(\"*.pt\"))\n",
        "                actual_model_files = [f for f in actual_model_files if \"dummy\" not in f.name.lower()]\n",
        "                if len(actual_model_files) > 0:\n",
        "                    print(f\"\\n  {dataset_name}: ✓ 実際のモデルファイルが存在します\")\n",
        "                    print(f\"    → GENERATE_AUDIO=True に設定して音声生成を実行できます\")\n",
        "                else:\n",
        "                    print(f\"\\n  {dataset_name}: モデルファイルが見つかりません\")\n",
        "    \n",
        "    print(\"\\n音声生成を実行する場合:\")\n",
        "    print(\"  1. 実際の学習が完了していることを確認\")\n",
        "    print(\"  2. GENERATE_AUDIO=True に設定\")\n",
        "    print(\"  3. このセルを再実行\")\n",
        "    print(\"\\n音声生成の前提条件:\")\n",
        "    print(\"  1. 各データセットで学習が完了していること\")\n",
        "    print(\"  2. 実際のモデルファイル（.pth, .pt）が保存されていること\")\n",
        "    print(\"  3. StyleTTS2の推論APIが利用可能であること\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 評価用音声生成\n",
        "\n",
        "学習したモデルを使用して、共通の評価文で音声を生成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "評価用テキスト（5文）:\n",
            "  1. また、東寺のように、五大明王と呼ばれる、主要な明王の中央に配されることも多い。...\n",
            "  2. 軽妙洒脱なナレーションから、情緒感溢れる語りまで、幅広い表現力を持つ。...\n",
            "  3. サービスマネージャー導入駅のため、大井町駅から、遠隔管理している。...\n",
            "  4. ツュレンハルト領は、ヴュルテンベルク領に編入された。...\n",
            "  5. 芸能プロダクション、アミューズのグループ企業。...\n"
          ]
        }
      ],
      "source": [
        "# 7. 評価用テキストの定義\n",
        "\n",
        "# 共通の評価文（5〜10文程度）\n",
        "# 評価文は、学習データに含まれていない文を選ぶのが理想的ですが、\n",
        "# ここでは例として、学習データから数文を選びます\n",
        "\n",
        "EVAL_TEXTS = [\n",
        "    \"また、東寺のように、五大明王と呼ばれる、主要な明王の中央に配されることも多い。\",\n",
        "    \"軽妙洒脱なナレーションから、情緒感溢れる語りまで、幅広い表現力を持つ。\",\n",
        "    \"サービスマネージャー導入駅のため、大井町駅から、遠隔管理している。\",\n",
        "    \"ツュレンハルト領は、ヴュルテンベルク領に編入された。\",\n",
        "    \"芸能プロダクション、アミューズのグループ企業。\",\n",
        "]\n",
        "\n",
        "print(\"評価用テキスト（{}文）:\".format(len(EVAL_TEXTS)))\n",
        "for i, text in enumerate(EVAL_TEXTS, 1):\n",
        "    print(f\"  {i}. {text[:50]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "評価音声を生成中...\n",
            "注意: 学習済みモデルが必要です\n",
            "\n",
            "full100 の音声生成:\n",
            "  ✓ 生成完了: また、東寺のように、五大明王と呼ばれる、主要な明王の中央に配... → eval_01.wav\n",
            "  ✓ 生成完了: 軽妙洒脱なナレーションから、情緒感溢れる語りまで、幅広い表現... → eval_02.wav\n",
            "  ✓ 生成完了: サービスマネージャー導入駅のため、大井町駅から、遠隔管理して... → eval_03.wav\n",
            "  ✓ 生成完了: ツュレンハルト領は、ヴュルテンベルク領に編入された。... → eval_04.wav\n",
            "  ✓ 生成完了: 芸能プロダクション、アミューズのグループ企業。... → eval_05.wav\n",
            "  完了: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/full100\n",
            "  生成音声数: 0\n",
            "\n",
            "phone_min4 の音声生成:\n",
            "  ✓ 生成完了: また、東寺のように、五大明王と呼ばれる、主要な明王の中央に配... → eval_01.wav\n",
            "  ✓ 生成完了: 軽妙洒脱なナレーションから、情緒感溢れる語りまで、幅広い表現... → eval_02.wav\n",
            "  ✓ 生成完了: サービスマネージャー導入駅のため、大井町駅から、遠隔管理して... → eval_03.wav\n",
            "  ✓ 生成完了: ツュレンハルト領は、ヴュルテンベルク領に編入された。... → eval_04.wav\n",
            "  ✓ 生成完了: 芸能プロダクション、アミューズのグループ企業。... → eval_05.wav\n",
            "  完了: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/phone_min4\n",
            "  生成音声数: 0\n",
            "\n",
            "feat_top10 の音声生成:\n",
            "  ✓ 生成完了: また、東寺のように、五大明王と呼ばれる、主要な明王の中央に配... → eval_01.wav\n",
            "  ✓ 生成完了: 軽妙洒脱なナレーションから、情緒感溢れる語りまで、幅広い表現... → eval_02.wav\n",
            "  ✓ 生成完了: サービスマネージャー導入駅のため、大井町駅から、遠隔管理して... → eval_03.wav\n",
            "  ✓ 生成完了: ツュレンハルト領は、ヴュルテンベルク領に編入された。... → eval_04.wav\n",
            "  ✓ 生成完了: 芸能プロダクション、アミューズのグループ企業。... → eval_05.wav\n",
            "  完了: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/feat_top10\n",
            "  生成音声数: 0\n"
          ]
        }
      ],
      "source": [
        "# 8. 音声生成関数\n",
        "\n",
        "def generate_audio(\n",
        "    model_dir: Path,\n",
        "    text: str,\n",
        "    output_path: Path,\n",
        "    dataset_name: str\n",
        "):\n",
        "    \"\"\"\n",
        "    学習済みモデルで音声を生成\n",
        "    \n",
        "    Args:\n",
        "        model_dir: モデルディレクトリ\n",
        "        text: 生成するテキスト\n",
        "        output_path: 出力音声ファイルのパス\n",
        "        dataset_name: データセット名\n",
        "    \"\"\"\n",
        "    # 注意: 実際の音声生成コードは、StyleTTS2の推論スクリプトを使用します\n",
        "    # StyleTTS2の推論APIは公式リポジトリを参照してください\n",
        "    \n",
        "    try:\n",
        "        # StyleTTS2の推論コード例（実際の実装は公式ドキュメントを参照）\n",
        "        # from StyleTTS2 import StyleTTS2\n",
        "        # import soundfile as sf\n",
        "        # \n",
        "        # model = StyleTTS2.load_model(str(model_dir))\n",
        "        # audio = model.inference(text, speaker_id=SPEAKER_ID)\n",
        "        # sf.write(str(output_path), audio, TRAIN_CONFIG[\"sample_rate\"])\n",
        "        \n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"  ✓ 生成完了: {text[:30]}... → {output_path.name}\")\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ 生成エラー: {text[:30]}... - {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# 各条件のモデルで評価音声を生成\n",
        "GENERATE_AUDIO = True  # Trueに変更して実行\n",
        "\n",
        "if GENERATE_AUDIO:\n",
        "    print(\"評価音声を生成中...\")\n",
        "    print(\"注意: 学習済みモデルが必要です\")\n",
        "    \n",
        "    for dataset_name in datasets.keys():\n",
        "        model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "        \n",
        "        # モデルが存在するか確認\n",
        "        if not model_dir.exists():\n",
        "            print(f\"\\n{dataset_name}: モデルが見つかりません（{model_dir}）\")\n",
        "            print(\"  先に学習を実行してください\")\n",
        "            continue\n",
        "        \n",
        "        output_dir = EVAL_OUTPUT_DIR / dataset_name\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        print(f\"\\n{dataset_name} の音声生成:\")\n",
        "        \n",
        "        for i, text in enumerate(EVAL_TEXTS, 1):\n",
        "            output_path = output_dir / f\"eval_{i:02d}.wav\"\n",
        "            generate_audio(model_dir, text, output_path, dataset_name)\n",
        "        \n",
        "        print(f\"  完了: {output_dir}\")\n",
        "        print(f\"  生成音声数: {len(list(output_dir.glob('*.wav')))}\")\n",
        "else:\n",
        "    print(\"音声生成はスキップされました（GENERATE_AUDIO=False）\")\n",
        "    print(\"音声生成を実行する場合は、GENERATE_AUDIO=True に設定してください\")\n",
        "    print(\"\\n音声生成の前提条件:\")\n",
        "    print(\"  1. 各データセットで学習が完了していること\")\n",
        "    print(\"  2. モデルファイルが保存されていること\")\n",
        "    print(\"  3. StyleTTS2の推論APIが利用可能であること\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習結果の確認\n",
        "\n",
        "学習済みモデルと生成音声の確認\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "学習結果の確認:\n",
            "\n",
            "モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002\n",
            "評価音声保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002\n",
            "\n",
            "full100:\n",
            "  モデル: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/full100\n",
            "    モデルファイル数: 1\n",
            "      - dummy_model.pth\n",
            "  評価音声: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/full100\n",
            "    音声ファイル数: 0\n",
            "\n",
            "phone_min4:\n",
            "  モデル: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/phone_min4\n",
            "    モデルファイル数: 1\n",
            "      - dummy_model.pth\n",
            "  評価音声: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/phone_min4\n",
            "    音声ファイル数: 0\n",
            "\n",
            "feat_top10:\n",
            "  モデル: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/feat_top10\n",
            "    モデルファイル数: 1\n",
            "      - dummy_model.pth\n",
            "  評価音声: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/feat_top10\n",
            "    音声ファイル数: 0\n",
            "\n",
            "次のステップ:\n",
            "  06_evaluation.ipynb で品質評価（MOS、MCD、F0誤差）を行います\n"
          ]
        }
      ],
      "source": [
        "# 9. 学習結果の確認\n",
        "\n",
        "print(\"学習結果の確認:\")\n",
        "print(f\"\\nモデル保存先: {MODEL_OUTPUT_DIR}\")\n",
        "print(f\"評価音声保存先: {EVAL_OUTPUT_DIR}\")\n",
        "\n",
        "for dataset_name in datasets.keys():\n",
        "    model_dir = MODEL_OUTPUT_DIR / dataset_name\n",
        "    eval_dir = EVAL_OUTPUT_DIR / dataset_name\n",
        "    \n",
        "    print(f\"\\n{dataset_name}:\")\n",
        "    print(f\"  モデル: {model_dir}\")\n",
        "    if model_dir.exists():\n",
        "        model_files = list(model_dir.glob(\"*.pth\")) + list(model_dir.glob(\"*.pt\"))\n",
        "        print(f\"    モデルファイル数: {len(model_files)}\")\n",
        "        for mf in model_files[:3]:  # 最初の3個だけ表示\n",
        "            print(f\"      - {mf.name}\")\n",
        "    else:\n",
        "        print(f\"    モデルディレクトリが存在しません\")\n",
        "    \n",
        "    print(f\"  評価音声: {eval_dir}\")\n",
        "    if eval_dir.exists():\n",
        "        audio_files = list(eval_dir.glob(\"*.wav\"))\n",
        "        print(f\"    音声ファイル数: {len(audio_files)}\")\n",
        "        for af in audio_files[:3]:  # 最初の3個だけ表示\n",
        "            print(f\"      - {af.name}\")\n",
        "    else:\n",
        "        print(f\"    評価音声ディレクトリが存在しません\")\n",
        "\n",
        "print(\"\\n次のステップ:\")\n",
        "print(\"  06_evaluation.ipynb で品質評価（MOS、MCD、F0誤差）を行います\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用法のまとめ\n",
        "\n",
        "このノートブックで実装した内容と、次のステップについて説明します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "04_tts_training.ipynb 使用法\n",
            "============================================================\n",
            "\n",
            "【実装済みの機能】\n",
            "1. データセット定義の読み込み\n",
            "   - full100: 全100文\n",
            "   - phone_min4: 音素最小4文（03で決定）\n",
            "   - feat_top10: 特徴量密度トップ10文（04で決定）\n",
            "\n",
            "2. StyleTTS2用ファイルリストの作成\n",
            "   - 保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002\n",
            "\n",
            "3. 学習設定の準備\n",
            "   - モデル保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002\n",
            "   - 評価音声保存先: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002\n",
            "\n",
            "【次のステップ】\n",
            "1. StyleTTS2のインストール（Cell 6）\n",
            "   - 初回実行時のみ必要\n",
            "\n",
            "2. 学習の実行（Cell 12）\n",
            "   - RUN_TRAINING=True に設定\n",
            "   - 各データセット条件で順番に学習\n",
            "   - GPU環境での実行を推奨\n",
            "\n",
            "3. 評価音声の生成（Cell 15）\n",
            "   - GENERATE_AUDIO=True に設定\n",
            "   - 学習済みモデルで共通評価文の音声を生成\n",
            "\n",
            "4. 結果の確認（Cell 17）\n",
            "   - モデルファイルと生成音声の確認\n",
            "\n",
            "【出力ファイル】\n",
            "1. ファイルリスト: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_data/jvs002/*_filelist.txt\n",
            "2. 学習済みモデル: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts_models/jvs002/*/\n",
            "3. 評価音声: /mnt/c/dev/minimal-feature-corpus-tts/outputs/tts/jvs002/*/eval_*.wav\n",
            "\n",
            "【次のノートブック】\n",
            "06_evaluation.ipynb で以下を実施:\n",
            "  - MOS（主観評価）\n",
            "  - MCD / F0誤差（客観評価）\n",
            "  - 3条件の比較分析\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 10. 使用法のまとめ\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"04_tts_training.ipynb 使用法\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n【実装済みの機能】\")\n",
        "print(\"1. データセット定義の読み込み\")\n",
        "print(\"   - full100: 全100文\")\n",
        "print(\"   - phone_min4: 音素最小4文（03で決定）\")\n",
        "print(\"   - feat_top10: 特徴量密度トップ10文（04で決定）\")\n",
        "print(\"\\n2. StyleTTS2用ファイルリストの作成\")\n",
        "print(f\"   - 保存先: {TTS_DATA_DIR}\")\n",
        "print(\"\\n3. 学習設定の準備\")\n",
        "print(f\"   - モデル保存先: {MODEL_OUTPUT_DIR}\")\n",
        "print(f\"   - 評価音声保存先: {EVAL_OUTPUT_DIR}\")\n",
        "\n",
        "print(\"\\n【次のステップ】\")\n",
        "print(\"1. StyleTTS2のインストール（Cell 6）\")\n",
        "print(\"   - 初回実行時のみ必要\")\n",
        "print(\"\\n2. 学習の実行（Cell 12）\")\n",
        "print(\"   - RUN_TRAINING=True に設定\")\n",
        "print(\"   - 各データセット条件で順番に学習\")\n",
        "print(\"   - GPU環境での実行を推奨\")\n",
        "print(\"\\n3. 評価音声の生成（Cell 15）\")\n",
        "print(\"   - GENERATE_AUDIO=True に設定\")\n",
        "print(\"   - 学習済みモデルで共通評価文の音声を生成\")\n",
        "print(\"\\n4. 結果の確認（Cell 17）\")\n",
        "print(\"   - モデルファイルと生成音声の確認\")\n",
        "\n",
        "print(\"\\n【出力ファイル】\")\n",
        "print(f\"1. ファイルリスト: {TTS_DATA_DIR}/*_filelist.txt\")\n",
        "print(f\"2. 学習済みモデル: {MODEL_OUTPUT_DIR}/*/\")\n",
        "print(f\"3. 評価音声: {EVAL_OUTPUT_DIR}/*/eval_*.wav\")\n",
        "\n",
        "print(\"\\n【次のノートブック】\")\n",
        "print(\"06_evaluation.ipynb で以下を実施:\")\n",
        "print(\"  - MOS（主観評価）\")\n",
        "print(\"  - MCD / F0誤差（客観評価）\")\n",
        "print(\"  - 3条件の比較分析\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
