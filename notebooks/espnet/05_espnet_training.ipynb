{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPNet TTSãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "\n",
    "ESPNetã‚’ä½¿ç”¨ã—ã¦ã€3ã¤ã®ç•°ãªã‚‹ã‚³ãƒ¼ãƒ‘ã‚¹æ¡ä»¶ã§TTSãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚\n",
    "\n",
    "## å­¦ç¿’æ¡ä»¶\n",
    "\n",
    "1. **full100**: jvs002 parallel100ã®å…¨100æ–‡\n",
    "2. **phone_min4**: éŸ³ç´ ã‚«ãƒãƒ¬ãƒƒã‚¸æœ€å°4æ–‡ï¼ˆ054, 011, 022, 015ï¼‰\n",
    "3. **feat_top10**: ç‰¹å¾´é‡å¯†åº¦ãƒˆãƒƒãƒ—10æ–‡\n",
    "\n",
    "## ç›®çš„\n",
    "\n",
    "- ESPNetã®VITSãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨\n",
    "- JSUTã§äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰Fine-tuning\n",
    "- å„æ¡ä»¶ã§åŒã˜è¨­å®šãƒ»åŒã˜ã‚¨ãƒãƒƒã‚¯æ•°ã§å­¦ç¿’\n",
    "- å­¦ç¿’å¾Œã€å…±é€šã®è©•ä¾¡æ–‡ã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ `outputs/espnet/condition_name/` ã«ä¿å­˜\n",
    "- 06_evaluation.ipynbã§å“è³ªæ¯”è¼ƒï¼ˆMOSã€MCDã€F0èª¤å·®ï¼‰ã‚’è¡Œã†ãŸã‚ã®æº–å‚™\n",
    "\n",
    "## å‚è€ƒè¨˜äº‹\n",
    "\n",
    "- [ESPNetã§æ—¥æœ¬èªTTSãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹æ–¹æ³•](https://qiita.com/niwatiki/items/c2fca0307c8718bf3c61)\n",
    "- [ãƒ„ã‚¯ãƒ¨ãƒŸã¡ã‚ƒã‚“ã®å£°ã§ESPNet-VITSã‚’Fine-tuning](https://qiita.com/RRR_troisR/items/6288b9bdc6e725aa8440)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /mnt/c/dev/minimal-feature-corpus-tts\n",
      "DATA_ROOT: /mnt/c/dev/minimal-feature-corpus-tts/data/jvs_ver1/jvs_ver1\n",
      "OUTPUT_ROOT: /mnt/c/dev/minimal-feature-corpus-tts/outputs\n",
      "ESPNET_ROOT: /mnt/c/dev/minimal-feature-corpus-tts/espnet\n",
      "ESPNET_DATA_ROOT: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’å–å¾—\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\" / \"jvs_ver1\" / \"jvs_ver1\"\n",
    "OUTPUT_ROOT = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "SPEAKER_ID = \"jvs002\"\n",
    "ESPNET_ROOT = PROJECT_ROOT / \"espnet\"\n",
    "ESPNET_DATA_ROOT = PROJECT_ROOT / \"espnet_data\"\n",
    "\n",
    "# ãƒ‘ã‚¹è¨­å®š\n",
    "sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"OUTPUT_ROOT:\", OUTPUT_ROOT)\n",
    "print(\"ESPNET_ROOT:\", ESPNET_ROOT)\n",
    "print(\"ESPNET_DATA_ROOT:\", ESPNET_DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone_min4 (éŸ³ç´ æœ€å°4æ–‡):\n",
      "  1. VOICEACTRESS100_054\n",
      "  2. VOICEACTRESS100_011\n",
      "  3. VOICEACTRESS100_022\n",
      "  4. VOICEACTRESS100_015\n",
      "\n",
      "feat_top10 (ç‰¹å¾´é‡å¯†åº¦ãƒˆãƒƒãƒ—10æ–‡):\n",
      "  1. VOICEACTRESS100_006\n",
      "  2. VOICEACTRESS100_033\n",
      "  3. VOICEACTRESS100_011\n",
      "  4. VOICEACTRESS100_025\n",
      "  5. VOICEACTRESS100_045\n",
      "  6. VOICEACTRESS100_013\n",
      "  7. VOICEACTRESS100_014\n",
      "  8. VOICEACTRESS100_004\n",
      "  9. VOICEACTRESS100_017\n",
      "  10. VOICEACTRESS100_052\n",
      "\n",
      "full100 (å…¨100æ–‡): 100æ–‡\n",
      "\n",
      "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©å®Œäº†:\n",
      "  full100: 100æ–‡\n",
      "  phone_min4: 4æ–‡\n",
      "  feat_top10: 10æ–‡\n"
     ]
    }
   ],
   "source": [
    "# 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©ã®èª­ã¿è¾¼ã¿\n",
    "\n",
    "# 03ã®è§£æçµæœã‹ã‚‰éŸ³ç´ æœ€å°4æ–‡ã‚’å–å¾—\n",
    "corpus_summary_path = OUTPUT_ROOT / \"corpus_analysis\" / SPEAKER_ID / \"summary.json\"\n",
    "with open(corpus_summary_path, 'r', encoding='utf-8') as f:\n",
    "    corpus_summary = json.load(f)\n",
    "\n",
    "phone_min4_ids = corpus_summary['selected_ids']\n",
    "print(\"phone_min4 (éŸ³ç´ æœ€å°4æ–‡):\")\n",
    "for i, sid in enumerate(phone_min4_ids, 1):\n",
    "    print(f\"  {i}. {sid}\")\n",
    "\n",
    "# 04ã®è§£æçµæœã‹ã‚‰ç‰¹å¾´é‡ãƒˆãƒƒãƒ—10æ–‡ã‚’å–å¾—\n",
    "feat_summary_path = OUTPUT_ROOT / \"feature_density\" / SPEAKER_ID / \"summary.json\"\n",
    "with open(feat_summary_path, 'r', encoding='utf-8') as f:\n",
    "    feat_summary = json.load(f)\n",
    "\n",
    "feat_top10_ids = feat_summary['selected_ids']\n",
    "print(f\"\\nfeat_top10 (ç‰¹å¾´é‡å¯†åº¦ãƒˆãƒƒãƒ—10æ–‡):\")\n",
    "for i, sid in enumerate(feat_top10_ids, 1):\n",
    "    print(f\"  {i}. {sid}\")\n",
    "\n",
    "# full100ã¯å…¨100æ–‡\n",
    "# è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…¨IDã‚’å–å¾—\n",
    "transcript_path = DATA_ROOT / SPEAKER_ID / \"parallel100\" / \"transcripts_utf8.txt\"\n",
    "all_ids = []\n",
    "with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if \":\" in line:\n",
    "            file_id = line.strip().split(\":\")[0]\n",
    "            all_ids.append(file_id)\n",
    "\n",
    "full100_ids = sorted(all_ids)\n",
    "print(f\"\\nfull100 (å…¨100æ–‡): {len(full100_ids)}æ–‡\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©ã‚’ä¿å­˜\n",
    "datasets = {\n",
    "    \"full100\": full100_ids,\n",
    "    \"phone_min4\": phone_min4_ids,\n",
    "    \"feat_top10\": feat_top10_ids\n",
    "}\n",
    "\n",
    "print(\"\\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©å®Œäº†:\")\n",
    "for name, ids in datasets.items():\n",
    "    print(f\"  {name}: {len(ids)}æ–‡\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: ESPNetç’°å¢ƒæ§‹ç¯‰\n",
    "\n",
    "ESPNetã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¦ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
    "\n",
    "**æ³¨æ„**: ã“ã®ã‚»ãƒ«ã¯åˆå›å®Ÿè¡Œæ™‚ã®ã¿å¿…è¦ã§ã™ã€‚æ—¢ã«ESPNetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã§ãã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPNetã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet\n",
      "ä»®æƒ³ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/tools/venv\n",
      "\n",
      "ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã«ã¯:\n",
      "  source /mnt/c/dev/minimal-feature-corpus-tts/espnet/tools/venv/bin/activate\n"
     ]
    }
   ],
   "source": [
    "# ESPNetã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèªã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "if not ESPNET_ROOT.exists():\n",
    "    print(\"ESPNetãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    print(\"ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\")\n",
    "    print(\"  cd /mnt/c/dev/minimal-feature-corpus-tts\")\n",
    "    print(\"  git clone https://github.com/espnet/espnet.git\")\n",
    "    print(\"  cd espnet/tools\")\n",
    "    print(\"  ./setup_anaconda.sh venv espnet 3.9\")\n",
    "    print(\"  source venv/bin/activate\")\n",
    "    print(\"  make\")\n",
    "    print(\"  pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118  # GPUä½¿ç”¨æ™‚\")\n",
    "else:\n",
    "    print(f\"ESPNetã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {ESPNET_ROOT}\")\n",
    "    \n",
    "    # ç’°å¢ƒã®ç¢ºèª\n",
    "    venv_path = ESPNET_ROOT / \"tools\" / \"venv\"\n",
    "    if venv_path.exists():\n",
    "        print(f\"ä»®æƒ³ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {venv_path}\")\n",
    "        print(\"\\nä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã«ã¯:\")\n",
    "        print(f\"  source {venv_path}/bin/activate\")\n",
    "    else:\n",
    "        print(\"ä»®æƒ³ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: ESPNetå½¢å¼ã¸ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›\n",
    "\n",
    "JVSã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ESPNetã®Recipeã§ä½¿ç”¨ã§ãã‚‹å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "# ESPNetç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›é–¢æ•°\n",
    "\n",
    "def create_espnet_dataset(dataset_name: str, file_ids: List[str], speaker_id: str = \"jvs002\") -> Path:\n",
    "    \"\"\"\n",
    "    ESPNetç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "    \n",
    "    æ§‹é€ :\n",
    "    espnet_data/{dataset_name}/\n",
    "    â”œâ”€â”€ voice_text.txt  # JVS002001:ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼\n",
    "    â””â”€â”€ voice/\n",
    "        â”œâ”€â”€ JVS002_001.wav\n",
    "        â”œâ”€â”€ JVS002_002.wav\n",
    "        ...\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå (full100, phone_min4, feat_top10)\n",
    "        file_ids: ãƒ•ã‚¡ã‚¤ãƒ«IDã®ãƒªã‚¹ãƒˆ\n",
    "        speaker_id: è©±è€…ID\n",
    "    \n",
    "    Returns:\n",
    "        ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹\n",
    "    \"\"\"\n",
    "    output_dir = ESPNET_DATA_ROOT / dataset_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    voice_dir = output_dir / \"voice\"\n",
    "    voice_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€\n",
    "    transcript_path = DATA_ROOT / speaker_id / \"parallel100\" / \"transcripts_utf8.txt\"\n",
    "    transcripts = {}\n",
    "    with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ':' in line:\n",
    "                file_id, text = line.strip().split(':', 1)\n",
    "                transcripts[file_id] = text.strip()\n",
    "    \n",
    "    # voice_text.txtã‚’ä½œæˆ\n",
    "    text_file = output_dir / \"voice_text.txt\"\n",
    "    with open(text_file, 'w', encoding='utf-8') as f:\n",
    "        for i, file_id in enumerate(file_ids, 1):\n",
    "            # ESPNetå½¢å¼: JVS002001:ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "            espnet_id = f\"{speaker_id.upper()}{i:03d}\"\n",
    "            text = transcripts.get(file_id, \"\")\n",
    "            if text:\n",
    "                f.write(f\"{espnet_id}:{text}\\n\")\n",
    "            \n",
    "            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆåå‰å¤‰æ›´ï¼‰\n",
    "            src_wav = DATA_ROOT / speaker_id / \"parallel100\" / \"wav24kHz16bit\" / f\"{file_id}.wav\"\n",
    "            dst_wav = voice_dir / f\"{speaker_id.upper()}_{i:03d}.wav\"\n",
    "            if src_wav.exists():\n",
    "                shutil.copy(src_wav, dst_wav)\n",
    "                if (i - 1) % 10 == 0:\n",
    "                    print(f\"  {i}/{len(file_ids)}: {file_id} -> {dst_wav.name}\")\n",
    "            else:\n",
    "                print(f\"  è­¦å‘Š: {src_wav} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    print(f\"\\nâœ“ ESPNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {output_dir}\")\n",
    "    print(f\"  - ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {text_file}\")\n",
    "    print(f\"  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(list(voice_dir.glob('*.wav')))}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "print(\"ESPNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›: full100 (100æ–‡)\n",
      "============================================================\n",
      "  1/100: VOICEACTRESS100_001 -> JVS002_001.wav\n",
      "  11/100: VOICEACTRESS100_011 -> JVS002_011.wav\n",
      "  21/100: VOICEACTRESS100_021 -> JVS002_021.wav\n",
      "  31/100: VOICEACTRESS100_031 -> JVS002_031.wav\n",
      "  41/100: VOICEACTRESS100_041 -> JVS002_041.wav\n",
      "  51/100: VOICEACTRESS100_051 -> JVS002_051.wav\n",
      "  61/100: VOICEACTRESS100_061 -> JVS002_061.wav\n",
      "  71/100: VOICEACTRESS100_071 -> JVS002_071.wav\n",
      "  81/100: VOICEACTRESS100_081 -> JVS002_081.wav\n",
      "  91/100: VOICEACTRESS100_091 -> JVS002_091.wav\n",
      "\n",
      "âœ“ ESPNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/full100\n",
      "  - ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/full100/voice_text.txt\n",
      "  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 100\n",
      "\n",
      "============================================================\n",
      "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›: phone_min4 (4æ–‡)\n",
      "============================================================\n",
      "  1/4: VOICEACTRESS100_054 -> JVS002_001.wav\n",
      "\n",
      "âœ“ ESPNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/phone_min4\n",
      "  - ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/phone_min4/voice_text.txt\n",
      "  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 4\n",
      "\n",
      "============================================================\n",
      "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›: feat_top10 (10æ–‡)\n",
      "============================================================\n",
      "  1/10: VOICEACTRESS100_006 -> JVS002_001.wav\n",
      "\n",
      "âœ“ ESPNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/feat_top10\n",
      "  - ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/feat_top10/voice_text.txt\n",
      "  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 10\n",
      "\n",
      "============================================================\n",
      "å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›å®Œäº†\n",
      "============================================================\n",
      "  full100: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/full100\n",
      "  phone_min4: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/phone_min4\n",
      "  feat_top10: /mnt/c/dev/minimal-feature-corpus-tts/espnet_data/feat_top10\n"
     ]
    }
   ],
   "source": [
    "# å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ESPNetå½¢å¼ã«å¤‰æ›\n",
    "\n",
    "espnet_datasets = {}\n",
    "\n",
    "for name, ids in datasets.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›: {name} ({len(ids)}æ–‡)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    espnet_datasets[name] = create_espnet_dataset(name, ids, SPEAKER_ID)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›å®Œäº†\")\n",
    "print(\"=\"*60)\n",
    "for name, path in espnet_datasets.items():\n",
    "    print(f\"  {name}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: ESPNet Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã”ã¨ã«ESPNetã®Recipeã‚’ä½œæˆã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "# Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "def setup_recipe(dataset_name: str, espnet_data_dir: Path) -> Path:\n",
    "    \"\"\"\n",
    "    ESPNetã®Recipeã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå\n",
    "        espnet_data_dir: ESPNetå½¢å¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    \n",
    "    Returns:\n",
    "        Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: ESPNetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ\n",
    "    \"\"\"\n",
    "    # ESPNetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "    if not ESPNET_ROOT.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"\\n{'='*60}\\n\"\n",
    "            f\"âŒ ESPNetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼\\n\"\n",
    "            f\"{'='*60}\\n\\n\"\n",
    "            f\"ESPNetãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ESPNET_ROOT}\\n\\n\"\n",
    "            f\"ğŸ“¦ ESPNetã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\\n\\n\"\n",
    "            f\"  cd {PROJECT_ROOT}\\n\"\n",
    "            f\"  git clone https://github.com/espnet/espnet.git\\n\"\n",
    "            f\"  cd espnet/tools\\n\"\n",
    "            f\"  ./setup_anaconda.sh venv espnet 3.9\\n\"\n",
    "            f\"  source venv/bin/activate\\n\"\n",
    "            f\"  make\\n\"\n",
    "            f\"  pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118  # GPUä½¿ç”¨æ™‚\\n\\n\"\n",
    "            f\"è©³ç´°ã¯ã‚»ãƒ«4ï¼ˆPhase 1: ESPNetç’°å¢ƒæ§‹ç¯‰ï¼‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\\n\"\n",
    "            f\"{'='*60}\"\n",
    "        )\n",
    "    \n",
    "    recipe_dir = ESPNET_ROOT / \"egs2\" / f\"{SPEAKER_ID}_{dataset_name}\" / \"tts1\"\n",
    "    \n",
    "    # RecipeãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ä½œæˆ\n",
    "    if not recipe_dir.exists():\n",
    "        print(f\"Recipeã‚’ä½œæˆä¸­: {recipe_dir}\")\n",
    "        template_dir = ESPNET_ROOT / \"egs2\" / \"TEMPLATE\" / \"tts1\"\n",
    "        \n",
    "        if not template_dir.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"\\n{'='*60}\\n\"\n",
    "                f\"âŒ ESPNetãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼\\n\"\n",
    "                f\"{'='*60}\\n\\n\"\n",
    "                f\"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {template_dir}\\n\"\n",
    "                f\"ESPNetãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {ESPNET_ROOT}\\n\\n\"\n",
    "                f\"ESPNetãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n",
    "                f\"ESPNetã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’å®Œäº†ã—ã¦ãã ã•ã„ï¼ˆã‚»ãƒ«4ã‚’å‚ç…§ï¼‰ã€‚\\n\"\n",
    "                f\"{'='*60}\"\n",
    "            )\n",
    "        \n",
    "        # setup.shã‚’å®Ÿè¡Œ\n",
    "        import os\n",
    "        os.chdir(template_dir)\n",
    "        result = subprocess.run(\n",
    "            [\"./setup.sh\", str(recipe_dir)],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: {result.stderr}\")\n",
    "            raise RuntimeError(f\"Recipeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "        \n",
    "        print(f\"âœ“ Recipeä½œæˆå®Œäº†: {recipe_dir}\")\n",
    "    else:\n",
    "        print(f\"Recipeã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {recipe_dir}\")\n",
    "    \n",
    "    return recipe_dir\n",
    "\n",
    "print(\"Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db.shä½œæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "# db.shãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹ã‚’å®šç¾©ï¼‰\n",
    "\n",
    "def create_db_sh(recipe_dir: Path, espnet_data_dir: Path):\n",
    "    \"\"\"db.shãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ/æ›´æ–°\"\"\"\n",
    "    db_sh_path = recipe_dir / \"db.sh\"\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ•°ã‚’è¿½åŠ \n",
    "    content = f\"\"\"# JVS002 {espnet_data_dir.name} dataset\n",
    "JVS002_{espnet_data_dir.name.upper()}={espnet_data_dir}\n",
    "\"\"\"\n",
    "    \n",
    "    # æ—¢å­˜ã®db.shãŒã‚ã‚‹å ´åˆã¯è¿½è¨˜ã€ãªã„å ´åˆã¯æ–°è¦ä½œæˆ\n",
    "    if db_sh_path.exists():\n",
    "        with open(db_sh_path, 'r', encoding='utf-8') as f:\n",
    "            existing = f.read()\n",
    "        if espnet_data_dir.name not in existing:\n",
    "            with open(db_sh_path, 'a', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            print(f\"âœ“ db.shã«è¿½åŠ : {db_sh_path}\")\n",
    "        else:\n",
    "            print(f\"db.shã«ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿ã§ã™: {db_sh_path}\")\n",
    "    else:\n",
    "        with open(db_sh_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"âœ“ db.shã‚’ä½œæˆ: {db_sh_path}\")\n",
    "    \n",
    "    return db_sh_path\n",
    "\n",
    "print(\"db.shä½œæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "# local/data.sh ã¨ local/data_prep.sh ã®ä½œæˆ\n",
    "\n",
    "def create_data_scripts(recipe_dir: Path, dataset_name: str, espnet_data_dir: Path):\n",
    "    \"\"\"ãƒ‡ãƒ¼ã‚¿æº–å‚™ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ\"\"\"\n",
    "    local_dir = recipe_dir / \"local\"\n",
    "    local_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # data.sh: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹ã®è¨­å®š\n",
    "    data_sh_path = local_dir / \"data.sh\"\n",
    "    data_sh_content = f\"\"\"#!/bin/bash\n",
    "# Data paths for {dataset_name}\n",
    "\n",
    "# ESPNet data directory\n",
    "data_dir={espnet_data_dir}\n",
    "\n",
    "# Output directory for processed data\n",
    "dumpdir=dump/24k\n",
    "\n",
    "# Speaker ID\n",
    "spk=jvs002\n",
    "\n",
    "# Dataset name\n",
    "dset={dataset_name}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(data_sh_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(data_sh_content)\n",
    "    data_sh_path.chmod(0o755)\n",
    "    print(f\"âœ“ local/data.shã‚’ä½œæˆ: {data_sh_path}\")\n",
    "    \n",
    "    # data_prep.sh: ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆQiitaè¨˜äº‹ã‚’å‚è€ƒï¼‰\n",
    "    data_prep_sh_path = local_dir / \"data_prep.sh\"\n",
    "    data_prep_content = f\"\"\"#!/bin/bash\n",
    "# Data preparation script for {dataset_name}\n",
    "\n",
    "set -euo pipefail\n",
    "\n",
    ". ./path.sh || exit 1;\n",
    ". ./cmd.sh || exit 1;\n",
    ". ./db.sh || exit 1;\n",
    "\n",
    "data_dir={espnet_data_dir}\n",
    "dumpdir=dump/24k\n",
    "\n",
    "train_set=\"tr_no_dev\"\n",
    "dev_set=\"dev\"\n",
    "eval_set=\"eval\"\n",
    "\n",
    "# Text file path\n",
    "text_file=\"${{data_dir}}/voice_text.txt\"\n",
    "wav_dir=\"${{data_dir}}/voice\"\n",
    "\n",
    "# Create output directories\n",
    "mkdir -p \"${{dumpdir}}\"\n",
    "train_dumpdir=\"${{dumpdir}}/${{train_set}}\"\n",
    "dev_dumpdir=\"${{dumpdir}}/${{dev_set}}\"\n",
    "eval_dumpdir=\"${{dumpdir}}/${{eval_set}}\"\n",
    "mkdir -p \"${{train_dumpdir}}\" \"${{dev_dumpdir}}\" \"${{eval_dumpdir}}\"\n",
    "\n",
    "# Split data (80% train, 10% dev, 10% eval)\n",
    "total_lines=$(wc -l < \"${{text_file}}\")\n",
    "train_lines=$((total_lines * 8 / 10))\n",
    "dev_lines=$((total_lines * 9 / 10))\n",
    "\n",
    "head -n \"${{train_lines}}\" \"${{text_file}}\" > \"${{dumpdir}}/train_text.txt\"\n",
    "sed -n \"$((train_lines+1)),${{dev_lines}}p\" \"${{text_file}}\" > \"${{dumpdir}}/dev_text.txt\"\n",
    "tail -n +$((dev_lines+1)) \"${{text_file}}\" > \"${{dumpdir}}/eval_text.txt\"\n",
    "\n",
    "echo \"Data preparation completed.\"\n",
    "echo \"Train: ${{train_lines}} lines\"\n",
    "echo \"Dev: $((dev_lines - train_lines)) lines\"\n",
    "echo \"Eval: $((total_lines - dev_lines)) lines\"\n",
    "\"\"\"\n",
    "    \n",
    "    with open(data_prep_sh_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(data_prep_content)\n",
    "    data_prep_sh_path.chmod(0o755)\n",
    "    print(f\"âœ“ local/data_prep.shã‚’ä½œæˆ: {data_prep_sh_path}\")\n",
    "    \n",
    "    return data_sh_path, data_prep_sh_path\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: full100\n",
      "============================================================\n",
      "Recipeã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "db.shã«ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿ã§ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1/db.sh\n",
      "âœ“ local/data.shã‚’ä½œæˆ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1/local/data.sh\n",
      "âœ“ local/data_prep.shã‚’ä½œæˆ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1/local/data_prep.sh\n",
      "\n",
      "============================================================\n",
      "Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: phone_min4\n",
      "============================================================\n",
      "Recipeã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "db.shã«ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿ã§ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1/db.sh\n",
      "âœ“ local/data.shã‚’ä½œæˆ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1/local/data.sh\n",
      "âœ“ local/data_prep.shã‚’ä½œæˆ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1/local/data_prep.sh\n",
      "\n",
      "============================================================\n",
      "Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: feat_top10\n",
      "============================================================\n",
      "Recipeã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "db.shã«ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿ã§ã™: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1/db.sh\n",
      "âœ“ local/data.shã‚’ä½œæˆ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1/local/data.sh\n",
      "âœ“ local/data_prep.shã‚’ä½œæˆ: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1/local/data_prep.sh\n",
      "\n",
      "============================================================\n",
      "Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\n",
      "============================================================\n",
      "  full100: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "  phone_min4: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "  feat_top10: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n"
     ]
    }
   ],
   "source": [
    "# å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã®Recipeã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "recipe_dirs = {}\n",
    "\n",
    "# ESPNetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹äº‹å‰ã«ç¢ºèª\n",
    "if not ESPNET_ROOT.exists():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"âš ï¸  ESPNetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nESPNetãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ESPNET_ROOT}\")\n",
    "    print(\"\\nã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ä»¥ä¸‹ã®æ‰‹é †ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:\")\n",
    "    print(\"\\n1. ã‚»ãƒ«4ï¼ˆPhase 1: ESPNetç’°å¢ƒæ§‹ç¯‰ï¼‰ã‚’ç¢ºèª\")\n",
    "    print(\"2. ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ESPNetã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:\")\n",
    "    print(f\"   cd {PROJECT_ROOT}\")\n",
    "    print(\"   git clone https://github.com/espnet/espnet.git\")\n",
    "    print(\"   cd espnet/tools\")\n",
    "    print(\"   ./setup_anaconda.sh venv espnet 3.9\")\n",
    "    print(\"   source venv/bin/activate\")\n",
    "    print(\"   make\")\n",
    "    print(\"\\nESPNetã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸå¾Œã€ã“ã®ã‚»ãƒ«ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    for dataset_name, espnet_data_dir in espnet_datasets.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: {dataset_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Recipeä½œæˆ\n",
    "            recipe_dir = setup_recipe(dataset_name, espnet_data_dir)\n",
    "            recipe_dirs[dataset_name] = recipe_dir\n",
    "            \n",
    "            # db.shä½œæˆ\n",
    "            create_db_sh(recipe_dir, espnet_data_dir)\n",
    "            \n",
    "            # ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ\n",
    "            create_data_scripts(recipe_dir, dataset_name, espnet_data_dir)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"\\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\")\n",
    "            print(str(e))\n",
    "            print(f\"\\n{dataset_name}ã®Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            print(f\"{dataset_name}ã®Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            continue\n",
    "\n",
    "    if recipe_dirs:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "        print(\"=\"*60)\n",
    "        for name, path in recipe_dirs.items():\n",
    "            print(f\"  {name}: {path}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  ã™ã¹ã¦ã®Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "        print(\"ESPNetã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰\n",
    "\n",
    "ESPNetã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã®æ®µéšã§ã¯ç‰¹å¾´é‡æŠ½å‡ºã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãªã©ãŒè¡Œã‚ã‚Œã¾ã™ã€‚\n",
    "\n",
    "**æ³¨æ„**: ã“ã®ã‚»ãƒ«ã¯ESPNetã®ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã—ãŸçŠ¶æ…‹ã§å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚³ãƒãƒ³ãƒ‰ï¼ˆStage 1-5ï¼‰:\n",
      "============================================================\n",
      "\n",
      "ã€full100ã€‘\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "./run.sh \\\n",
      "  --stage 1 \\\n",
      "  --stop-stage 5 \\\n",
      "  --g2p pyopenjtalk_accent_with_pause \\\n",
      "  --min_wav_duration 0.38 \\\n",
      "  --fs 24000 \\\n",
      "  --n_fft 1024 \\\n",
      "  --n_shift 256 \\\n",
      "  --dumpdir dump/24k \\\n",
      "  --win_length null \\\n",
      "  --tts_task gan_tts \\\n",
      "  --feats_extract linear_spectrogram \\\n",
      "  --feats_normalize none \\\n",
      "  --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "  --nj 4\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ã€phone_min4ã€‘\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "./run.sh \\\n",
      "  --stage 1 \\\n",
      "  --stop-stage 5 \\\n",
      "  --g2p pyopenjtalk_accent_with_pause \\\n",
      "  --min_wav_duration 0.38 \\\n",
      "  --fs 24000 \\\n",
      "  --n_fft 1024 \\\n",
      "  --n_shift 256 \\\n",
      "  --dumpdir dump/24k \\\n",
      "  --win_length null \\\n",
      "  --tts_task gan_tts \\\n",
      "  --feats_extract linear_spectrogram \\\n",
      "  --feats_normalize none \\\n",
      "  --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "  --nj 4\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ã€feat_top10ã€‘\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "./run.sh \\\n",
      "  --stage 1 \\\n",
      "  --stop-stage 5 \\\n",
      "  --g2p pyopenjtalk_accent_with_pause \\\n",
      "  --min_wav_duration 0.38 \\\n",
      "  --fs 24000 \\\n",
      "  --n_fft 1024 \\\n",
      "  --n_shift 256 \\\n",
      "  --dumpdir dump/24k \\\n",
      "  --win_length null \\\n",
      "  --tts_task gan_tts \\\n",
      "  --feats_extract linear_spectrogram \\\n",
      "  --feats_normalize none \\\n",
      "  --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "  --nj 4\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Ÿè¡Œç”¨ã®ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "\n",
    "def generate_data_prep_command(recipe_dir: Path, dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Qiitaè¨˜äº‹ã®è¨­å®šã‚’å‚è€ƒ:\n",
    "    - g2p: pyopenjtalk_accent_with_pause\n",
    "    - fs: 24000\n",
    "    - n_fft: 1024\n",
    "    - n_shift: 256\n",
    "    - tts_task: gan_tts (VITS)\n",
    "    \"\"\"\n",
    "    cmd = f\"\"\"cd {recipe_dir}\n",
    "./run.sh \\\\\n",
    "  --stage 1 \\\\\n",
    "  --stop-stage 5 \\\\\n",
    "  --g2p pyopenjtalk_accent_with_pause \\\\\n",
    "  --min_wav_duration 0.38 \\\\\n",
    "  --fs 24000 \\\\\n",
    "  --n_fft 1024 \\\\\n",
    "  --n_shift 256 \\\\\n",
    "  --dumpdir dump/24k \\\\\n",
    "  --win_length null \\\\\n",
    "  --tts_task gan_tts \\\\\n",
    "  --feats_extract linear_spectrogram \\\\\n",
    "  --feats_normalize none \\\\\n",
    "  --train_config ./conf/tuning/finetune_vits.yaml \\\\\n",
    "  --nj 4\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "# å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆ\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚³ãƒãƒ³ãƒ‰ï¼ˆStage 1-5ï¼‰:\")\n",
    "print(\"=\"*60)\n",
    "for dataset_name, recipe_dir in recipe_dirs.items():\n",
    "    cmd = generate_data_prep_command(recipe_dir, dataset_name)\n",
    "    print(f\"\\nã€{dataset_name}ã€‘\")\n",
    "    print(cmd)\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Fine-tuningè¨­å®šï¼ˆJSUTäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼‰\n",
    "\n",
    "JSUTã§äº‹å‰å­¦ç¿’æ¸ˆã¿ã®VITSãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Fine-tuningã®æº–å‚™ã‚’ã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuningè¨­å®šã‚³ãƒãƒ³ãƒ‰:\n",
      "============================================================\n",
      "\n",
      "ã€full100ã€‘\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "espnet_model_zoo_download --unpack true --cachedir downloads \\\n",
      "  kan-bayashi/jsut_vits_accent_with_pause\n",
      "\n",
      "\n",
      "--- ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆæº–å‚™ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "pyscripts/utils/make_token_list_from_config.py \\\n",
      "  downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/config.yaml\n",
      "\n",
      "\n",
      "--- ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "mv dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\n",
      "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt.bak 2>/dev/null || true\n",
      "ln -s $(pwd)/downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\n",
      "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt\n",
      "\n",
      "\n",
      "ã€phone_min4ã€‘\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "espnet_model_zoo_download --unpack true --cachedir downloads \\\n",
      "  kan-bayashi/jsut_vits_accent_with_pause\n",
      "\n",
      "\n",
      "--- ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆæº–å‚™ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "pyscripts/utils/make_token_list_from_config.py \\\n",
      "  downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/config.yaml\n",
      "\n",
      "\n",
      "--- ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "mv dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\n",
      "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt.bak 2>/dev/null || true\n",
      "ln -s $(pwd)/downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\n",
      "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt\n",
      "\n",
      "\n",
      "ã€feat_top10ã€‘\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "espnet_model_zoo_download --unpack true --cachedir downloads \\\n",
      "  kan-bayashi/jsut_vits_accent_with_pause\n",
      "\n",
      "\n",
      "--- ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆæº–å‚™ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "pyscripts/utils/make_token_list_from_config.py \\\n",
      "  downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/config.yaml\n",
      "\n",
      "\n",
      "--- ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ ---\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "mv dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\n",
      "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt.bak 2>/dev/null || true\n",
      "ln -s $(pwd)/downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\n",
      "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSUTäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¨­å®šç”¨ã‚³ãƒãƒ³ãƒ‰\n",
    "\n",
    "def generate_finetune_setup_commands(recipe_dir: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Fine-tuningè¨­å®šç”¨ã®ã‚³ãƒãƒ³ãƒ‰ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ\n",
    "    \n",
    "    1. JSUTäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    2. ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆã®æº–å‚™\n",
    "    3. ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã®ä½œæˆ\n",
    "    \"\"\"\n",
    "    commands = []\n",
    "    \n",
    "    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    download_cmd = f\"\"\"cd {recipe_dir}\n",
    "source ../../../tools/venv/bin/activate\n",
    "espnet_model_zoo_download --unpack true --cachedir downloads \\\\\n",
    "  kan-bayashi/jsut_vits_accent_with_pause\n",
    "\"\"\"\n",
    "    commands.append((\"ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\", download_cmd))\n",
    "    \n",
    "    # 2. ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆæº–å‚™\n",
    "    token_cmd = f\"\"\"cd {recipe_dir}\n",
    "source ../../../tools/venv/bin/activate\n",
    "pyscripts/utils/make_token_list_from_config.py \\\\\n",
    "  downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/config.yaml\n",
    "\"\"\"\n",
    "    commands.append((\"ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆæº–å‚™\", token_cmd))\n",
    "    \n",
    "    # 3. ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ\n",
    "    link_cmd = f\"\"\"cd {recipe_dir}\n",
    "mv dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\\\n",
    "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt.bak 2>/dev/null || true\n",
    "ln -s $(pwd)/downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt \\\\\n",
    "  dump/24k/token_list/phn_jaconv_pyopenjtalk_accent_with_pause/tokens.txt\n",
    "\"\"\"\n",
    "    commands.append((\"ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ\", link_cmd))\n",
    "    \n",
    "    return commands\n",
    "\n",
    "print(\"Fine-tuningè¨­å®šã‚³ãƒãƒ³ãƒ‰:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for dataset_name, recipe_dir in recipe_dirs.items():\n",
    "    print(f\"\\nã€{dataset_name}ã€‘\")\n",
    "    print(\"-\"*60)\n",
    "    commands = generate_finetune_setup_commands(recipe_dir)\n",
    "    for step_name, cmd in commands:\n",
    "        print(f\"\\n--- {step_name} ---\")\n",
    "        print(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰\n",
    "\n",
    "Fine-tuningå­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã®æ®µéšã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆæ•°æ™‚é–“ã€œæ•°åæ™‚é–“ï¼‰ã€‚\n",
    "\n",
    "**å®Ÿè¡Œå‰ã«ç¢ºèª:**\n",
    "- ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨\n",
    "- JSUTäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨\n",
    "- ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆã®è¨­å®šãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å­¦ç¿’å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ï¼ˆStage 6ï¼‰:\n",
      "============================================================\n",
      "\n",
      "ã€full100ã€‘\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "./run.sh \\\n",
      "  --stage 6 \\\n",
      "  --g2p pyopenjtalk_accent_with_pause \\\n",
      "  --min_wav_duration 0.38 \\\n",
      "  --fs 24000 \\\n",
      "  --n_fft 1024 \\\n",
      "  --n_shift 256 \\\n",
      "  --dumpdir dump/24k \\\n",
      "  --win_length null \\\n",
      "  --tts_task gan_tts \\\n",
      "  --feats_extract linear_spectrogram \\\n",
      "  --feats_normalize none \\\n",
      "  --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "  --train_args \"--init_param downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth:tts:tts\" \\\n",
      "  --tag finetune_vits_jvs002_full100\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ã€phone_min4ã€‘\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "./run.sh \\\n",
      "  --stage 6 \\\n",
      "  --g2p pyopenjtalk_accent_with_pause \\\n",
      "  --min_wav_duration 0.38 \\\n",
      "  --fs 24000 \\\n",
      "  --n_fft 1024 \\\n",
      "  --n_shift 256 \\\n",
      "  --dumpdir dump/24k \\\n",
      "  --win_length null \\\n",
      "  --tts_task gan_tts \\\n",
      "  --feats_extract linear_spectrogram \\\n",
      "  --feats_normalize none \\\n",
      "  --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "  --train_args \"--init_param downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth:tts:tts\" \\\n",
      "  --tag finetune_vits_jvs002_phone_min4\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ã€feat_top10ã€‘\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "./run.sh \\\n",
      "  --stage 6 \\\n",
      "  --g2p pyopenjtalk_accent_with_pause \\\n",
      "  --min_wav_duration 0.38 \\\n",
      "  --fs 24000 \\\n",
      "  --n_fft 1024 \\\n",
      "  --n_shift 256 \\\n",
      "  --dumpdir dump/24k \\\n",
      "  --win_length null \\\n",
      "  --tts_task gan_tts \\\n",
      "  --feats_extract linear_spectrogram \\\n",
      "  --feats_normalize none \\\n",
      "  --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "  --train_args \"--init_param downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth:tts:tts\" \\\n",
      "  --tag finetune_vits_jvs002_feat_top10\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰ç”¨ã®ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "\n",
    "def generate_training_command(recipe_dir: Path, dataset_name: str, tag_suffix: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Fine-tuningå­¦ç¿’ï¼ˆStage 6ï¼‰ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Args:\n",
    "        recipe_dir: Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹\n",
    "        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå\n",
    "        tag_suffix: ã‚¿ã‚°ã®ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "    \"\"\"\n",
    "    tag = f\"finetune_vits_{SPEAKER_ID}_{dataset_name}\"\n",
    "    if tag_suffix:\n",
    "        tag += f\"_{tag_suffix}\"\n",
    "    \n",
    "    cmd = f\"\"\"cd {recipe_dir}\n",
    "./run.sh \\\\\n",
    "  --stage 6 \\\\\n",
    "  --g2p pyopenjtalk_accent_with_pause \\\\\n",
    "  --min_wav_duration 0.38 \\\\\n",
    "  --fs 24000 \\\\\n",
    "  --n_fft 1024 \\\\\n",
    "  --n_shift 256 \\\\\n",
    "  --dumpdir dump/24k \\\\\n",
    "  --win_length null \\\\\n",
    "  --tts_task gan_tts \\\\\n",
    "  --feats_extract linear_spectrogram \\\\\n",
    "  --feats_normalize none \\\\\n",
    "  --train_config ./conf/tuning/finetune_vits.yaml \\\\\n",
    "  --train_args \"--init_param downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth:tts:tts\" \\\\\n",
    "  --tag {tag}\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "print(\"å­¦ç¿’å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ï¼ˆStage 6ï¼‰:\")\n",
    "print(\"=\"*60)\n",
    "for dataset_name, recipe_dir in recipe_dirs.items():\n",
    "    cmd = generate_training_command(recipe_dir, dataset_name)\n",
    "    print(f\"\\nã€{dataset_name}ã€‘\")\n",
    "    print(cmd)\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®Ÿè¡Œæ‰‹é †ã¾ã¨ã‚\n",
    "\n",
    "### 1. ç’°å¢ƒæ§‹ç¯‰ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œ:\n",
    "\n",
    "```bash\n",
    "cd /mnt/c/dev/minimal-feature-corpus-tts\n",
    "git clone https://github.com/espnet/espnet.git\n",
    "cd espnet/tools\n",
    "./setup_anaconda.sh venv espnet 3.9\n",
    "source venv/bin/activate\n",
    "make\n",
    "# GPUä½¿ç”¨æ™‚\n",
    "pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "\n",
    "### 2. ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é †ç•ªã«å®Ÿè¡Œ:\n",
    "- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›ï¼ˆã‚»ãƒ«7ã¾ã§ï¼‰\n",
    "- Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚»ãƒ«12ã¾ã§ï¼‰\n",
    "\n",
    "### 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã”ã¨ï¼‰\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œï¼ˆESPNetç’°å¢ƒã‚’æœ‰åŠ¹åŒ–å¾Œï¼‰:\n",
    "\n",
    "```bash\n",
    "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
    "source ../../../tools/venv/bin/activate\n",
    "# ã‚»ãƒ«14ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "```\n",
    "\n",
    "### 4. Fine-tuningè¨­å®šï¼ˆå„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã”ã¨ï¼‰\n",
    "\n",
    "```bash\n",
    "# ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "```\n",
    "\n",
    "### 5. å­¦ç¿’å®Ÿè¡Œï¼ˆå„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã”ã¨ï¼‰\n",
    "\n",
    "```bash\n",
    "# ã‚»ãƒ«18ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œæ¨å¥¨: nohup ./run.sh ... > train.log 2>&1 &\n",
    "```\n",
    "\n",
    "### å­¦ç¿’æ™‚é–“ã®ç›®å®‰\n",
    "\n",
    "- **full100**: 18-22æ™‚é–“ï¼ˆQiitaå®Ÿç¸¾ã‚ˆã‚Šï¼‰\n",
    "- **phone_min4**: 2-4æ™‚é–“ï¼ˆãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ãŸã‚ï¼‰\n",
    "- **feat_top10**: 4-6æ™‚é–“\n",
    "\n",
    "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "å­¦ç¿’ãŒå®Œäº†ã—ãŸã‚‰:\n",
    "1. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ç”Ÿæˆ\n",
    "2. `outputs/espnet/{condition_name}/` ã«è©•ä¾¡ç”¨éŸ³å£°ã‚’ä¿å­˜\n",
    "3. `06_evaluation.ipynb` ã§å“è³ªè©•ä¾¡ã‚’å®Ÿæ–½\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7: éŸ³å£°ç”Ÿæˆã¨è©•ä¾¡\n",
    "\n",
    "å­¦ç¿’ãŒå®Œäº†ã—ãŸã‚‰ã€è©•ä¾¡ç”¨ã®éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è©•ä¾¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt\n",
      "\n",
      "è©•ä¾¡æ–‡æ•°: 5\n",
      "  1. ã¾ãŸã€æ±å¯ºã®ã‚ˆã†ã«ã€äº”å¤§æ˜ç‹ã¨å‘¼ã°ã‚Œã‚‹ã€ä¸»è¦ãªæ˜ç‹ã®ä¸­å¤®ã«é…ã•ã‚Œã‚‹ã“ã¨ã‚‚å¤šã„ã€‚...\n",
      "  2. ãƒ‹ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰é¢¨ã¯ã€ç‰›ä¹³ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸã€ç™½ã„ã‚¯ãƒªãƒ¼ãƒ ã‚¹ãƒ¼ãƒ—ã§ã‚ã‚Šã€ãƒœã‚¹ãƒˆãƒ³ã‚¯ãƒ©ãƒ ãƒãƒ£ã‚¦ãƒ€ãƒ¼ã¨ã‚‚å‘¼...\n",
      "  3. ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å°å…¥é§…ã®ãŸã‚ã€å¤§äº•ç”ºé§…ã‹ã‚‰ã€é éš”ç®¡ç†ã—ã¦ã„ã‚‹ã€‚...\n",
      "  4. æ™‚é–“é ˜åŸŸã¨ã€ç©ºé–“é ˜åŸŸã§å…±é€šã™ã‚‹å‡¦ç†æ‰‹æ³•ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã€å…¥åŠ›ä¿¡å·ã®å¼·åŒ–ã§ã‚ã‚‹ã€‚...\n",
      "  5. ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‹ã‚‰ã€ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ã‚©ãƒ³ã¾ã§ã€ãƒãƒ«ãƒãƒ‡ãƒã‚¤ã‚¹ã«å¯¾å¿œã€‚...\n"
     ]
    }
   ],
   "source": [
    "# è©•ä¾¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆã®æº–å‚™ï¼ˆå…±é€šè©•ä¾¡æ–‡ï¼‰\n",
    "\n",
    "# è©•ä¾¡ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "# éŸ³ç´ ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒé«˜ã„ã€å¤šæ§˜ãªéŸ³ç´ ã‚’å«ã‚€æ–‡ã‚’é¸æŠ\n",
    "eval_texts = [\n",
    "    \"ã¾ãŸã€æ±å¯ºã®ã‚ˆã†ã«ã€äº”å¤§æ˜ç‹ã¨å‘¼ã°ã‚Œã‚‹ã€ä¸»è¦ãªæ˜ç‹ã®ä¸­å¤®ã«é…ã•ã‚Œã‚‹ã“ã¨ã‚‚å¤šã„ã€‚\",\n",
    "    \"ãƒ‹ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰é¢¨ã¯ã€ç‰›ä¹³ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸã€ç™½ã„ã‚¯ãƒªãƒ¼ãƒ ã‚¹ãƒ¼ãƒ—ã§ã‚ã‚Šã€ãƒœã‚¹ãƒˆãƒ³ã‚¯ãƒ©ãƒ ãƒãƒ£ã‚¦ãƒ€ãƒ¼ã¨ã‚‚å‘¼ã°ã‚Œã‚‹ã€‚\",\n",
    "    \"ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å°å…¥é§…ã®ãŸã‚ã€å¤§äº•ç”ºé§…ã‹ã‚‰ã€é éš”ç®¡ç†ã—ã¦ã„ã‚‹ã€‚\",\n",
    "    \"æ™‚é–“é ˜åŸŸã¨ã€ç©ºé–“é ˜åŸŸã§å…±é€šã™ã‚‹å‡¦ç†æ‰‹æ³•ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã€å…¥åŠ›ä¿¡å·ã®å¼·åŒ–ã§ã‚ã‚‹ã€‚\",\n",
    "    \"ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‹ã‚‰ã€ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ã‚©ãƒ³ã¾ã§ã€ãƒãƒ«ãƒãƒ‡ãƒã‚¤ã‚¹ã«å¯¾å¿œã€‚\",\n",
    "]\n",
    "\n",
    "# è©•ä¾¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜\n",
    "eval_text_path = OUTPUT_ROOT / \"espnet\" / \"eval_texts.txt\"\n",
    "eval_text_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(eval_text_path, 'w', encoding='utf-8') as f:\n",
    "    for i, text in enumerate(eval_texts, 1):\n",
    "        f.write(f\"eval_{i:03d}:{text}\\n\")\n",
    "\n",
    "print(f\"è©•ä¾¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {eval_text_path}\")\n",
    "print(f\"\\nè©•ä¾¡æ–‡æ•°: {len(eval_texts)}\")\n",
    "for i, text in enumerate(eval_texts, 1):\n",
    "    print(f\"  {i}. {text[:50]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "éŸ³å£°ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰:\n",
      "============================================================\n",
      "\n",
      "ã€full100ã€‘\n",
      "# éŸ³å£°ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰ï¼ˆå­¦ç¿’å®Œäº†å¾Œï¼‰\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "\n",
      "# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆ\n",
      "espnet2_tts_inference \\\n",
      "  --train_config exp/finetune_vits_jvs002_full100/config.yaml \\\n",
      "  --model_file exp/finetune_vits_jvs002_full100/train.total_count.ave.pth \\\n",
      "  --vocoder_file downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth \\\n",
      "  --inference_args \"--use_teacher_forcing true\" \\\n",
      "  --text_list /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt \\\n",
      "  --output_dir /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/full100\n",
      "\n",
      "# ã¾ãŸã¯ã€run.shã®Stage 7ã‚’ä½¿ç”¨\n",
      "# ./run.sh \\\n",
      "#   --stage 7 \\\n",
      "#   --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "#   --model_file exp/finetune_vits_jvs002_full100/train.total_count.ave.pth \\\n",
      "#   --text_list /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt \\\n",
      "#   --output_dir /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/full100\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ã€phone_min4ã€‘\n",
      "# éŸ³å£°ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰ï¼ˆå­¦ç¿’å®Œäº†å¾Œï¼‰\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "\n",
      "# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆ\n",
      "espnet2_tts_inference \\\n",
      "  --train_config exp/finetune_vits_jvs002_phone_min4/config.yaml \\\n",
      "  --model_file exp/finetune_vits_jvs002_phone_min4/train.total_count.ave.pth \\\n",
      "  --vocoder_file downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth \\\n",
      "  --inference_args \"--use_teacher_forcing true\" \\\n",
      "  --text_list /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt \\\n",
      "  --output_dir /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/phone_min4\n",
      "\n",
      "# ã¾ãŸã¯ã€run.shã®Stage 7ã‚’ä½¿ç”¨\n",
      "# ./run.sh \\\n",
      "#   --stage 7 \\\n",
      "#   --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "#   --model_file exp/finetune_vits_jvs002_phone_min4/train.total_count.ave.pth \\\n",
      "#   --text_list /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt \\\n",
      "#   --output_dir /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/phone_min4\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ã€feat_top10ã€‘\n",
      "# éŸ³å£°ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰ï¼ˆå­¦ç¿’å®Œäº†å¾Œï¼‰\n",
      "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "source ../../../tools/venv/bin/activate\n",
      "\n",
      "# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆ\n",
      "espnet2_tts_inference \\\n",
      "  --train_config exp/finetune_vits_jvs002_feat_top10/config.yaml \\\n",
      "  --model_file exp/finetune_vits_jvs002_feat_top10/train.total_count.ave.pth \\\n",
      "  --vocoder_file downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth \\\n",
      "  --inference_args \"--use_teacher_forcing true\" \\\n",
      "  --text_list /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt \\\n",
      "  --output_dir /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/feat_top10\n",
      "\n",
      "# ã¾ãŸã¯ã€run.shã®Stage 7ã‚’ä½¿ç”¨\n",
      "# ./run.sh \\\n",
      "#   --stage 7 \\\n",
      "#   --train_config ./conf/tuning/finetune_vits.yaml \\\n",
      "#   --model_file exp/finetune_vits_jvs002_feat_top10/train.total_count.ave.pth \\\n",
      "#   --text_list /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/eval_texts.txt \\\n",
      "#   --output_dir /mnt/c/dev/minimal-feature-corpus-tts/outputs/espnet/feat_top10\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# éŸ³å£°ç”Ÿæˆç”¨ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "\n",
    "def generate_inference_command(recipe_dir: Path, dataset_name: str, eval_text_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆã‚’è¡Œã†ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Args:\n",
    "        recipe_dir: Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå\n",
    "        eval_text_path: è©•ä¾¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
    "    \"\"\"\n",
    "    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    output_dir = OUTPUT_ROOT / \"espnet\" / dataset_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆå­¦ç¿’ãŒå®Œäº†ã—ãŸå ´åˆï¼‰\n",
    "    model_path = recipe_dir / \"exp\" / f\"finetune_vits_{SPEAKER_ID}_{dataset_name}\" / \"train.total_count.ave.pth\"\n",
    "    \n",
    "    cmd = f\"\"\"# éŸ³å£°ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰ï¼ˆå­¦ç¿’å®Œäº†å¾Œï¼‰\n",
    "cd {recipe_dir}\n",
    "source ../../../tools/venv/bin/activate\n",
    "\n",
    "# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆ\n",
    "espnet2_tts_inference \\\\\n",
    "  --train_config exp/finetune_vits_{SPEAKER_ID}_{dataset_name}/config.yaml \\\\\n",
    "  --model_file exp/finetune_vits_{SPEAKER_ID}_{dataset_name}/train.total_count.ave.pth \\\\\n",
    "  --vocoder_file downloads/*/exp/tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause/train.total_count.ave_10best.pth \\\\\n",
    "  --inference_args \"--use_teacher_forcing true\" \\\\\n",
    "  --text_list {eval_text_path} \\\\\n",
    "  --output_dir {output_dir}\n",
    "\n",
    "# ã¾ãŸã¯ã€run.shã®Stage 7ã‚’ä½¿ç”¨\n",
    "# ./run.sh \\\\\n",
    "#   --stage 7 \\\\\n",
    "#   --train_config ./conf/tuning/finetune_vits.yaml \\\\\n",
    "#   --model_file exp/finetune_vits_{SPEAKER_ID}_{dataset_name}/train.total_count.ave.pth \\\\\n",
    "#   --text_list {eval_text_path} \\\\\n",
    "#   --output_dir {output_dir}\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "print(\"éŸ³å£°ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰:\")\n",
    "print(\"=\"*60)\n",
    "for dataset_name, recipe_dir in recipe_dirs.items():\n",
    "    cmd = generate_inference_command(recipe_dir, dataset_name, eval_text_path)\n",
    "    print(f\"\\nã€{dataset_name}ã€‘\")\n",
    "    print(cmd)\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å­¦ç¿’çŠ¶æ³ã®ç¢ºèª\n",
    "\n",
    "å­¦ç¿’ä¸­ã®ãƒ­ã‚°ã‚„é€²æ—ã‚’ç¢ºèªã™ã‚‹æ–¹æ³•ã€‚\n",
    "\n",
    "### ãªãœãªãœåˆ†æ\n",
    "\n",
    "**å•é¡Œ**: å­¦ç¿’ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„\n",
    "\n",
    "**ãªãœãªãœåˆ†æ**:\n",
    "\n",
    "1. **ãªãœå­¦ç¿’ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„ã®ã‹ï¼Ÿ**\n",
    "   â†’ å­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„ã‹ã‚‰\n",
    "\n",
    "2. **ãªãœå­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„ã®ã‹ï¼Ÿ**\n",
    "   â†’ å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ï¼ˆPhase 6ï¼‰ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã‹ã‚‰\n",
    "\n",
    "3. **ãªãœå­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã®ã‹ï¼Ÿ**\n",
    "   â†’ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã‚³ãƒãƒ³ãƒ‰ã‚’**ç”Ÿæˆã™ã‚‹ã ã‘**ã§ã€å®Ÿéš›ã®å®Ÿè¡Œã¯**ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ‰‹å‹•å®Ÿè¡Œ**ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰\n",
    "\n",
    "4. **ãªãœå­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã®ã‹ï¼Ÿ**\n",
    "   â†’ å­¦ç¿’å‰ã®æº–å‚™ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿æº–å‚™ã€Fine-tuningè¨­å®šï¼‰ãŒæœªå®Œäº†ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ã‚‰\n",
    "\n",
    "**æ ¹æœ¬åŸå› **:\n",
    "- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã ã‘ã§ã€è‡ªå‹•å®Ÿè¡Œã¯è¡Œã‚ãªã„\n",
    "- å­¦ç¿’å‰ã®æº–å‚™ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPhase 4, 5ï¼‰ãŒæœªå®Œäº†\n",
    "- å­¦ç¿’çŠ¶æ³ç¢ºèªãŒä¸ååˆ†ã§ã€ã©ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªå®Œäº†ã‹åˆ†ã‹ã‚‰ãªã„\n",
    "\n",
    "**è§£æ±ºç­–**:\n",
    "- å­¦ç¿’çŠ¶æ³ç¢ºèªé–¢æ•°ã‚’æ”¹å–„ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Œäº†çŠ¶æ³ã‚’è©³ç´°ã«ç¢ºèªï¼‰\n",
    "- æœªå®Œäº†ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜ç¢ºã«è¡¨ç¤º\n",
    "- æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…·ä½“çš„ã«ç¤ºã™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ã€full100ã€‘å­¦ç¿’çŠ¶æ³ãƒã‚§ãƒƒã‚¯\n",
      "============================================================\n",
      "âœ“ Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
      "âŒ ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdump/24kãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n",
      "  â†’ ã‚»ãƒ«14ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "  â†’ Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ã‚’å‚ç…§\n",
      "âŒ Fine-tuningè¨­å®šãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdownloadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n",
      "  â†’ ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "  â†’ Phase 5: Fine-tuningè¨­å®šã‚’å‚ç…§\n",
      "\n",
      "âŒ å­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆexpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰\n",
      "\n",
      "ğŸ“‹ å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹å‰ã«ä»¥ä¸‹ã‚’ç¢ºèª:\n",
      "  âš  ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªå®Œäº†ã§ã™:\n",
      "     - Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰\n",
      "     - Phase 5: Fine-tuningè¨­å®š\n",
      "\n",
      "  â†’ ã¾ãšä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†ã—ã¦ã‹ã‚‰ã€Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "\n",
      "ã€phone_min4ã€‘å­¦ç¿’çŠ¶æ³ãƒã‚§ãƒƒã‚¯\n",
      "============================================================\n",
      "âœ“ Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_phone_min4/tts1\n",
      "âŒ ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdump/24kãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n",
      "  â†’ ã‚»ãƒ«14ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "  â†’ Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ã‚’å‚ç…§\n",
      "âŒ Fine-tuningè¨­å®šãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdownloadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n",
      "  â†’ ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "  â†’ Phase 5: Fine-tuningè¨­å®šã‚’å‚ç…§\n",
      "\n",
      "âŒ å­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆexpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰\n",
      "\n",
      "ğŸ“‹ å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹å‰ã«ä»¥ä¸‹ã‚’ç¢ºèª:\n",
      "  âš  ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªå®Œäº†ã§ã™:\n",
      "     - Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰\n",
      "     - Phase 5: Fine-tuningè¨­å®š\n",
      "\n",
      "  â†’ ã¾ãšä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†ã—ã¦ã‹ã‚‰ã€Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "\n",
      "ã€feat_top10ã€‘å­¦ç¿’çŠ¶æ³ãƒã‚§ãƒƒã‚¯\n",
      "============================================================\n",
      "âœ“ Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_feat_top10/tts1\n",
      "âŒ ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdump/24kãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n",
      "  â†’ ã‚»ãƒ«14ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "  â†’ Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ã‚’å‚ç…§\n",
      "âŒ Fine-tuningè¨­å®šãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdownloadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\n",
      "  â†’ ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
      "  â†’ Phase 5: Fine-tuningè¨­å®šã‚’å‚ç…§\n",
      "\n",
      "âŒ å­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆexpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰\n",
      "\n",
      "ğŸ“‹ å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹å‰ã«ä»¥ä¸‹ã‚’ç¢ºèª:\n",
      "  âš  ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªå®Œäº†ã§ã™:\n",
      "     - Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰\n",
      "     - Phase 5: Fine-tuningè¨­å®š\n",
      "\n",
      "  â†’ ã¾ãšä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†ã—ã¦ã‹ã‚‰ã€Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\n"
     ]
    }
   ],
   "source": [
    "# å­¦ç¿’çŠ¶æ³ç¢ºèªç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆæ”¹å–„ç‰ˆï¼šãªãœãªãœåˆ†æå¯¾å¿œï¼‰\n",
    "\n",
    "def check_training_status(recipe_dir: Path, dataset_name: str):\n",
    "    \"\"\"\n",
    "    å­¦ç¿’çŠ¶æ³ã‚’è©³ç´°ã«ç¢ºèªï¼ˆãªãœãªãœåˆ†æå¯¾å¿œï¼‰\n",
    "    \n",
    "    ç¢ºèªé …ç›®:\n",
    "    1. Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨\n",
    "    2. ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆdumpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã®çŠ¶æ³\n",
    "    3. Fine-tuningè¨­å®šï¼ˆdownloadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã®çŠ¶æ³\n",
    "    4. å­¦ç¿’ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆexpï¼‰ã®çŠ¶æ³\n",
    "    5. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®çŠ¶æ³\n",
    "    \"\"\"\n",
    "    print(f\"\\nã€{dataset_name}ã€‘å­¦ç¿’çŠ¶æ³ãƒã‚§ãƒƒã‚¯\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª\n",
    "    if not recipe_dir.exists():\n",
    "        print(f\"âŒ Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {recipe_dir}\")\n",
    "        print(\"  â†’ ã‚»ãƒ«12ï¼ˆPhase 3: Recipeã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"âœ“ Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {recipe_dir}\")\n",
    "    \n",
    "    # 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ã®ç¢ºèª\n",
    "    dump_dir = recipe_dir / \"dump\" / \"24k\"\n",
    "    if not dump_dir.exists():\n",
    "        print(f\"âŒ ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdump/24kãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\")\n",
    "        print(\"  â†’ ã‚»ãƒ«14ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "        print(\"  â†’ Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰ã‚’å‚ç…§\")\n",
    "    else:\n",
    "        train_dump = dump_dir / \"tr_no_dev\"\n",
    "        if train_dump.exists():\n",
    "            num_files = len(list(train_dump.glob(\"*.npy\"))) if train_dump.exists() else 0\n",
    "            print(f\"âœ“ ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†ï¼ˆdump/24k/tr_no_dev ã« {num_files} ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰\")\n",
    "        else:\n",
    "            print(f\"âš  ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒä¸å®Œå…¨ã®å¯èƒ½æ€§ï¼ˆtr_no_devãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\")\n",
    "    \n",
    "    # 3. Fine-tuningè¨­å®šã®ç¢ºèª\n",
    "    downloads_dir = recipe_dir / \"downloads\"\n",
    "    jsut_model_dir = None\n",
    "    if downloads_dir.exists():\n",
    "        # JSUTãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™\n",
    "        for item in downloads_dir.iterdir():\n",
    "            if item.is_dir() and \"jsut\" in item.name.lower():\n",
    "                exp_dir_check = item / \"exp\" / \"tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with_pause\"\n",
    "                if exp_dir_check.exists():\n",
    "                    jsut_model_dir = exp_dir_check\n",
    "                    break\n",
    "        \n",
    "        if jsut_model_dir:\n",
    "            model_file = jsut_model_dir / \"train.total_count.ave_10best.pth\"\n",
    "            if model_file.exists():\n",
    "                print(f\"âœ“ JSUTäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿\")\n",
    "            else:\n",
    "                print(f\"âš  JSUTãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_file}\")\n",
    "        else:\n",
    "            print(f\"âš  JSUTäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            print(\"  â†’ ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "            print(\"  â†’ Phase 5: Fine-tuningè¨­å®šã‚’å‚ç…§\")\n",
    "    else:\n",
    "        print(f\"âŒ Fine-tuningè¨­å®šãŒæœªå®Ÿè¡Œã§ã™ï¼ˆdownloadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰\")\n",
    "        print(\"  â†’ ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "        print(\"  â†’ Phase 5: Fine-tuningè¨­å®šã‚’å‚ç…§\")\n",
    "    \n",
    "    # 4. å­¦ç¿’ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª\n",
    "    exp_dir = recipe_dir / \"exp\" / f\"finetune_vits_{SPEAKER_ID}_{dataset_name}\"\n",
    "    \n",
    "    if not exp_dir.exists():\n",
    "        print(f\"\\nâŒ å­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆexpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰\")\n",
    "        print(\"\\nğŸ“‹ å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹å‰ã«ä»¥ä¸‹ã‚’ç¢ºèª:\")\n",
    "        \n",
    "        missing_steps = []\n",
    "        if not dump_dir.exists():\n",
    "            missing_steps.append(\"Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰\")\n",
    "        if not downloads_dir.exists() or not jsut_model_dir:\n",
    "            missing_steps.append(\"Phase 5: Fine-tuningè¨­å®š\")\n",
    "        \n",
    "        if missing_steps:\n",
    "            print(f\"  âš  ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªå®Œäº†ã§ã™:\")\n",
    "            for step in missing_steps:\n",
    "                print(f\"     - {step}\")\n",
    "            print(f\"\\n  â†’ ã¾ãšä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†ã—ã¦ã‹ã‚‰ã€Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "        else:\n",
    "            print(f\"  âœ“ æº–å‚™ã¯å®Œäº†ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™\")\n",
    "            print(f\"  â†’ ã‚»ãƒ«18ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¦ãã ã•ã„\")\n",
    "            print(f\"  â†’ Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰ã‚’å‚ç…§\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ“ å­¦ç¿’ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {exp_dir}\")\n",
    "    \n",
    "    # 5. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
    "    checkpoint_file = exp_dir / \"train.total_count.ave.pth\"\n",
    "    if checkpoint_file.exists():\n",
    "        file_size = checkpoint_file.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"âœ“ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "        print(f\"  ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {checkpoint_file}\")\n",
    "        print(f\"  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"âš  å­¦ç¿’ä¸­ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "        # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¢ã™\n",
    "        checkpoints = list(exp_dir.glob(\"*.pth\"))\n",
    "        if checkpoints:\n",
    "            latest = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
    "            file_size = latest.stat().st_size / (1024 * 1024)  # MB\n",
    "            mtime = latest.stat().st_mtime\n",
    "            from datetime import datetime\n",
    "            mtime_str = datetime.fromtimestamp(mtime).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"  æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {latest.name}\")\n",
    "            print(f\"  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB\")\n",
    "            print(f\"  æ›´æ–°æ—¥æ™‚: {mtime_str}\")\n",
    "        else:\n",
    "            print(\"  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            print(\"  å­¦ç¿’ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "    \n",
    "    # 6. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
    "    log_files = list(exp_dir.glob(\"*.log\")) + list(exp_dir.glob(\"train.log\"))\n",
    "    if log_files:\n",
    "        log_file = log_files[0]\n",
    "        print(f\"\\nâœ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_file.name}\")\n",
    "        # ãƒ­ã‚°ã®æœ€å¾Œã®æ•°è¡Œã‚’è¡¨ç¤º\n",
    "        try:\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    print(f\"  ãƒ­ã‚°ã®æœ€å¾Œã®5è¡Œ:\")\n",
    "                    for line in lines[-5:]:\n",
    "                        line = line.rstrip()\n",
    "                        if line:\n",
    "                            print(f\"    {line}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    else:\n",
    "        # run.shã®ãƒ­ã‚°ã‚’æ¢ã™\n",
    "        run_log = recipe_dir / \"train.log\"\n",
    "        if run_log.exists():\n",
    "            print(f\"\\nâœ“ å­¦ç¿’ãƒ­ã‚°: {run_log}\")\n",
    "        else:\n",
    "            print(\"\\nâš  ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ã®å­¦ç¿’çŠ¶æ³ã‚’ç¢ºèª\n",
    "for dataset_name, recipe_dir in recipe_dirs.items():\n",
    "    check_training_status(recipe_dir, dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ è§£æ±ºç­–ã¾ã¨ã‚ï¼šå­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®æ‰‹é †\n",
    "\n",
    "### ç¾åœ¨ã®çŠ¶æ³\n",
    "\n",
    "å­¦ç¿’ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„ = **å­¦ç¿’ãŒã¾ã é–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“**\n",
    "\n",
    "ã“ã‚Œã¯æ­£å¸¸ã§ã™ã€‚ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã ã‘ã§ã€å®Ÿéš›ã®å®Ÿè¡Œã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ‰‹å‹•å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "### å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®æ‰‹é †\n",
    "\n",
    "#### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆPhase 4ï¼‰ã‚’å®Ÿè¡Œ âš ï¸ æœªå®Œäº†\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆã‚»ãƒ«14ã‚’å‚ç…§ï¼‰:\n",
    "\n",
    "```bash\n",
    "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
    "source ../../../tools/venv/bin/activate\n",
    "./run.sh --stage 1 --stop-stage 5 [ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³...]\n",
    "```\n",
    "\n",
    "#### ã‚¹ãƒ†ãƒƒãƒ—2: Fine-tuningè¨­å®šï¼ˆPhase 5ï¼‰ã‚’å®Ÿè¡Œ âš ï¸ æœªå®Œäº†\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆã‚»ãƒ«16ã‚’å‚ç…§ï¼‰:\n",
    "\n",
    "```bash\n",
    "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
    "source ../../../tools/venv/bin/activate\n",
    "espnet_model_zoo_download --unpack true --cachedir downloads kan-bayashi/jsut_vits_accent_with_pause\n",
    "```\n",
    "\n",
    "#### ã‚¹ãƒ†ãƒƒãƒ—3: å­¦ç¿’å®Ÿè¡Œï¼ˆPhase 6ï¼‰ã‚’å®Ÿè¡Œ âš ï¸ æœªå®Œäº†\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆã‚»ãƒ«18ã‚’å‚ç…§ï¼‰:\n",
    "\n",
    "```bash\n",
    "cd /mnt/c/dev/minimal-feature-corpus-tts/espnet/egs2/jvs002_full100/tts1\n",
    "source ../../../tools/venv/bin/activate\n",
    "nohup ./run.sh --stage 6 [ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³...] > train.log 2>&1 &\n",
    "```\n",
    "\n",
    "#### ã‚¹ãƒ†ãƒƒãƒ—4: å­¦ç¿’çŠ¶æ³ã‚’å†ç¢ºèª\n",
    "\n",
    "å­¦ç¿’ã‚’é–‹å§‹ã—ãŸå¾Œã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®**ã‚»ãƒ«24ã‚’å†å®Ÿè¡Œ**ã—ã¦ã€è©³ç´°ãªå­¦ç¿’çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ\n",
    "\n",
    "- âœ… **Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ä½œæˆæ¸ˆã¿**ï¼ˆã‚»ãƒ«12ã§å®Œäº†ï¼‰\n",
    "- âŒ **ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒæœªå®Ÿè¡Œ**ï¼ˆPhase 4ãŒå¿…è¦ï¼‰\n",
    "- âŒ **Fine-tuningè¨­å®šãŒæœªå®Ÿè¡Œ**ï¼ˆPhase 5ãŒå¿…è¦ï¼‰\n",
    "- âŒ **å­¦ç¿’ãŒæœªé–‹å§‹**ï¼ˆPhase 6ãŒå¿…è¦ï¼‰\n",
    "\n",
    "å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¡ä»¶ï¼ˆfull100, phone_min4, feat_top10ï¼‰ã”ã¨ã«ã€ä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç¹°ã‚Šè¿”ã—ã¦ãã ã•ã„ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n",
    "\n",
    "ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… æ­£å¸¸ãªçŠ¶æ…‹ã§ã™ï¼\n",
    "\n",
    "### ğŸ“Š ç¾åœ¨ã®çŠ¶æ³\n",
    "\n",
    "**ã“ã‚Œã¯ã‚¨ãƒ©ãƒ¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼** å­¦ç¿’ã®æº–å‚™æ®µéšãŒæ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "#### âœ… å®Œäº†ã—ã¦ã„ã‚‹ã“ã¨\n",
    "\n",
    "1. âœ… **Recipeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå®Œäº†**\n",
    "   - full100, phone_min4, feat_top10 ã®3ã¤ã®RecipeãŒä½œæˆæ¸ˆã¿\n",
    "\n",
    "2. âœ… **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›å®Œäº†**\n",
    "   - espnet_data/ã«3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæº–å‚™æ¸ˆã¿\n",
    "\n",
    "3. âœ… **ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆå®Œäº†**\n",
    "   - Phase 4, 5, 6 ã®ã‚³ãƒãƒ³ãƒ‰ãŒç”Ÿæˆæ¸ˆã¿\n",
    "\n",
    "#### â³ ã“ã‚Œã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã“ã¨ï¼ˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ‰‹å‹•å®Ÿè¡Œï¼‰\n",
    "\n",
    "ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯**ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã ã‘**ã§ã™ã€‚å®Ÿéš›ã®å®Ÿè¡Œã¯**ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ‰‹å‹•**ã§è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "1. â³ **Phase 4: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStage 1-5ï¼‰**\n",
    "   - ã‚»ãƒ«14ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œ\n",
    "\n",
    "2. â³ **Phase 5: Fine-tuningè¨­å®š**\n",
    "   - ã‚»ãƒ«16ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œ\n",
    "\n",
    "3. â³ **Phase 6: å­¦ç¿’å®Ÿè¡Œï¼ˆStage 6ï¼‰**\n",
    "   - ã‚»ãƒ«18ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œ\n",
    "\n",
    "### ğŸ¯ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
    "\n",
    "ã¾ãšã¯**full100ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**ã§è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š\n",
    "\n",
    "1. **ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ã**\n",
    "2. **Phase 4ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ**ï¼ˆã‚»ãƒ«14ã‚’å‚ç…§ï¼‰\n",
    "3. **Phase 5ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ**ï¼ˆã‚»ãƒ«16ã‚’å‚ç…§ï¼‰\n",
    "4. **Phase 6ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ**ï¼ˆã‚»ãƒ«18ã‚’å‚ç…§ï¼‰\n",
    "\n",
    "å„ã‚¹ãƒ†ãƒƒãƒ—ãŒå®Œäº†ã—ãŸã‚‰ã€**ã‚»ãƒ«24ã‚’å†å®Ÿè¡Œ**ã—ã¦é€²æ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚ˆãã‚ã‚‹å•é¡Œ\n",
    "\n",
    "1. **ã‚¨ãƒ©ãƒ¼: RecipeãŒè¦‹ã¤ã‹ã‚‰ãªã„**\n",
    "   - ESPNetã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
    "   - `espnet/egs2/TEMPLATE/tts1` ãŒå­˜åœ¨ã™ã‚‹ã“ã¨\n",
    "\n",
    "2. **ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹ãŒä¸æ­£**\n",
    "   - `db.sh` ã¨ `local/data.sh` ã®ãƒ‘ã‚¹ã‚’ç¢ºèª\n",
    "   - ESPNetå½¢å¼ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "\n",
    "3. **ã‚¨ãƒ©ãƒ¼: ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„**\n",
    "   - Fine-tuningè¨­å®šï¼ˆPhase 5ï¼‰ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "   - ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ãŒæ­£ã—ãä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "\n",
    "4. **å­¦ç¿’ãŒé€”ä¸­ã§æ­¢ã¾ã‚‹**\n",
    "   - GPUãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§\n",
    "   - `train_config` ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹\n",
    "   - CPUã§å­¦ç¿’ã™ã‚‹å ´åˆã€æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™\n",
    "\n",
    "5. **éŸ³å£°ç”ŸæˆãŒã§ããªã„**\n",
    "   - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
    "   - ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèª\n",
    "\n",
    "### å‚è€ƒãƒªãƒ³ã‚¯\n",
    "\n",
    "- [ESPNetå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://espnet.github.io/espnet/)\n",
    "- [ESPNet GitHub Issues](https://github.com/espnet/espnet/issues)\n",
    "- [Qiitaè¨˜äº‹1](https://qiita.com/niwatiki/items/c2fca0307c8718bf3c61)\n",
    "- [Qiitaè¨˜äº‹2](https://qiita.com/RRR_troisR/items/6288b9bdc6e725aa8440)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}